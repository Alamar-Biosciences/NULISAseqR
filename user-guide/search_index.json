[["index.html", "NULISAseqR User Guide Welcome What is NULISAseqR? Installation Getting Help", " NULISAseqR User Guide Welcome This guide will walk you through analysis of NULISAseq proteomic data using R. If you have limited experience with R or prefer a graphical user interface, consider using the NULISA Analysis Software (NAS) — a cloud-based platform designed for intuitive data processing, visualization, and analysis. What is NULISAseqR? NULISAseqR is an R package designed specifically for working with NULISAseq proteomic data. It provides: Data Import: Read XML files from NULISAseq multiplex proteomic panels Quality Control: Automated QC metrics and reporting Visualization: Heatmaps, PCA plots, volcano plots, boxplots, etc. Statistical Analysis: Differential abundance testing and longitudinal analysis Outcome Modeling: Linear models using single-protein abundance to predict an outcome Installation New to R? If you haven’t installed R and RStudio yet, see the Installing R and RStudio guide in the Additional Resources page. macOS Users Important: Before installing NULISAseqR on macOS, you need to install Xcode Command Line Tools: Install Xcode from the App Store (if not already installed) Open Terminal and run this code to accept the Xcode license agreement: sudo xcodebuild -license accept Windows Users Important: Before installing NULISAseqR on Windows, you need to install Rtools which provides compilers and utilities to build packages from source: Go to https://cran.r-project.org/bin/windows/Rtools/ Download and install the appropriate Rtools version for your R installation Follow the installation instructions on the website Installation Steps Follow these steps to install NULISAseqR and its dependencies: # 1. Install devtools if (!requireNamespace(&quot;devtools&quot;, quietly = TRUE)) install.packages(&quot;devtools&quot;) # 2. Install BiocManager for Bioconductor packages if (!requireNamespace(&quot;BiocManager&quot;, quietly = TRUE)) install.packages(&quot;BiocManager&quot;) # 3. Install ComplexHeatmap from Bioconductor BiocManager::install(&quot;ComplexHeatmap&quot;) # 4. Install ggalt from CRAN snapshot install.packages(&#39;ggalt&#39;, repos = &quot;http://packagemanager.posit.co/cran/2025-08-02&quot;) # 5. Install PCAtools (Alamar fork) devtools::install_github(&#39;Alamar-Biosciences/PCAtools&#39;) # 6. Install NULISAseqR devtools::install_github(&#39;Alamar-Biosciences/NULISAseqR&#39;) # 7. Install additional packages for data analysis install.packages(&quot;tidyverse&quot;) install.packages(&quot;table1&quot;) install.packages(&quot;pROC&quot;) Note: If you encounter issues installing packages from source, you may need to restart R (Cmd/Ctrl + Shift + F10 in RStudio) between major installation steps. Load the packages: library(NULISAseqR) library(tidyverse) Getting Help Function help: Type ?function_name in the R console GitHub Issues: Report bugs or request features © 2026 Alamar Biosciences Bioinformatics Team Generated with NULISAseqR version 1.4.2 Last updated: February 15, 2026 "],["understanding-nulisaseq-data.html", "Understanding NULISAseq Data What is NULISA™ Technology? Data Normalization NPQ vs Fold Change Working with NPQ Values Data Analysis FAQ", " Understanding NULISAseq Data Before diving into data analysis, it’s important to understand how NULISAseq technology works and how the data is generated and normalized. What is NULISA™ Technology? NULISA (NUcleic acid-Linked Immuno-Sandwich Assay) is a highly sensitive protein quantification platform that combines immunoassay specificity with next-generation sequencing readout. The NULISAseq platform uses a proprietary dual selection proximity ligation approach to obtain high sensitivity and high signal-to-noise ratio for multiplexed protein detection: Key Components: Verified antigen-specific antibody pairs - Two antibodies that bind different epitopes on the target protein Antibody-specific barcodes - Unique DNA sequences attached to each antibody Bridging oligos - Connect the barcodes only when both antibodies bind the same target PolyA-tailed oligos - Enable sequential capture on beads (Capture 1 step) Biotinylated oligos - Enable sequential capture on beads (Capture 2 step) Technical Workflow The assay follows these steps: This dual selection removes assay background and drastically improves signal-to-noise ratio. Learn More About NULISA™ Technology For a comprehensive understanding of the NULISA™ platform, we recommend: NULISA™ Publication Feng, W., Beer, J.C., Hao, Q. et al. (2023). “NULISA: a proteomic liquid biopsy platform with attomolar sensitivity and high multiplexing.” Nature Communications 14, 7238. Read the full article NULISA™ Platform Overview Watch the NULISATM Platform Video for a visual explanation of the technology and workflow. Technical Documentation For detailed technical notes on assay design, normalization methods, and quality control: See Technical Documentation in the Additional Resources chapter. Available NULISAseq Panels Alamar Biosciences offers several curated panels for disease-specific research, including: Inflammation Panel: 250+ immune response markers including 120+ cytokines and chemokines CNS Disease Panel: 120+ neuro-specific and neuro inflammation-related proteins Mouse Panel: 120+ inflammation, neuro-degeneration and oncogenesis proteins specific to mouse model Custom assays: Develop your own biomarker assays with the NULISAqpcr Custom Assay Development Kit Explore Current Panels: For detailed panel specifications, target lists, and custom assay options, visit the Alamar Biosciences website. Data Normalization NULISAseq uses a multi-step normalization process to make protein measurements comparable across samples and plates. Raw Data: Sequencing Counts The output from the sequencer is read counts for each target protein in each sample: Each protein has a unique barcode (target-specific molecular identifier, TMI) Each sample also has a unique barcode (sample-specific molecular identifier, SMI) More reads = more protein present Raw counts range from 0 to millions Step 1: Internal Control (IC) Normalization Purpose: Correct for sample-to-sample technical variation Method: Each sample includes an internal control spike-in Divide each target’s read count by the sample’s IC count Formula: \\[ \\text{IC-normalized count} = \\text{Raw count} / \\text{IC count} \\] Step 2: Inter-Plate Control (IPC) Normalization Purpose: Correct for plate-to-plate technical variation Method: Calculate target-specific median IC-normalized counts across 3 inter-plate controls (IPCs) Divide IC-normalized counts by these IPC target-specific medians Rescale by multiplying by 10⁴ Formula: \\[ \\text{IPC-normalized count} = (\\text{IC-normalized count} / \\text{IPC median}) × 10⁴ \\] Step 3: Log2 Transformation Purpose: Create NULISA Protein Quantification (NPQ) values in log2 scale Method: Add 1 to all values (avoid log(0)) Take log2 transformation Formula: \\[ \\text{NPQ} = log_2(\\text{IPC-normalized count} + 1) \\] Special normalization for high-abundance targets Most targets in NULISAseq panels are measured at their lower limit of detection. However, certain targets have exceptionally high endogenous levels that would saturate standard detection: High-abundance targets: Inflammation Panel: CRP and KNG1 in human plasma and serum samples CNS Panel: APOE and CRP in human plasma and serum samples Mouse Panel: Crp in mouse plasma and serum samples Special tuning strategy: To accommodate both high-abundance and low-abundance targets in the same panel, these targets use a special algorithm during normalization. This transformation is applied before the log2 transformation step. Key Note: The listed LOD for these targets represents the upper limit of detection NPQ values are valid and comparable for downstream analysis NPQ values for these targets are interpreted in the usual way (one unit increase = doubling of abundance) Detectability is not a concern given the naturally high levels of these proteins For novel sample types beyond validated matrices, the algorithm may not apply if abundance levels differ significantly, and NPQ may not be reported Why Log Transform? Using log2-scale NPQ instead of linear normalized counts has many advantages: ✅ Stabilizes variance - Makes data more homoscedastic ✅ Reduces skewness - Data becomes more normally distributed ✅ Linearizes relationships - Easier to model ✅ Improves interpretability - Differences = fold changes ✅ Compresses range - Large values don’t dominate ✅ Reveals clearer patterns - Easier to see biological signals NPQ vs Fold Change Understanding the Relationship Fold Change is calculated as: \\[ \\text{Fold Change} = 2^{(\\text{Difference in NPQ})} \\] Example: Sample ΔNPQ Fold Change 1 2.3 5 2 4.1 17 3 5.7 53 4 7.3 161 5 8.9 485 6 10.5 1457 Key Point: In biological systems, protein abundance typically varies over several orders of magnitude and changes multiplicatively. Log2 transformation accounts for this by converting fold changes to linear differences, making the data more suitable for statistical analysis. Working with NPQ Values While you cannot directly compare abundances across targets using NPQ, it is possible to calculate fold changes between individuals or groups for the same target and for target ratios. Calculating Fold Changes from NPQ If you need to derive fold change from difference in NPQ for interpretation: # Given NPQ values npq_disease &lt;- 7.0 npq_healthy &lt;- 4.0 # Calculate difference delta_npq &lt;- npq_disease - npq_healthy # 3.0 # Convert to fold change fold_change &lt;- 2^delta_npq # 2^3 = 8 Interpretation: Protein is 8 times higher in the disease group compared to healthy. Calculating Fold Changes in Target Ratios While NPQ values cannot be directly compared between targets, you can calculate ratios between targets and compare these ratios across individuals or groups. As with single-target NPQ values, these ratios are not absolute quantities — only the fold changes between ratios are meaningful. Calculating Protein NPQ Ratios Since NPQ values are log2-transformed, calculating NPQ ratios is straightforward: subtract the NPQ values. The formula for calculating NPQ target ratios uses the quotient property of logarithms: \\[ log_2(A/B) = log_2(A) - log_2(B) \\] \\[ \\text{NPQ}_{A/B} = \\text{NPQ}_A - \\text{NPQ}_B \\] Example use case: Aβ42/Aβ40 ratio for Alzheimer’s diagnosis Sample Target NPQ Sample A (Healthy) Aβ42 9.00 Sample A (Healthy) Aβ40 6.00 Sample B (Alzheimer’s) Aβ42 8.20 Sample B (Alzheimer’s) Aβ40 5.52 Calculations: For Sample A (Healthy control): \\(NPQ_{Aβ42} = 9\\) \\(NPQ_{Aβ40} = 6\\) \\(NPQ_{Aβ42/Aβ40} = 9 - 6 = 3\\) For Sample B (Alzheimer’s patient): \\(NPQ_{Aβ42} = 8.20\\) \\(NPQ_{Aβ40} = 5.52\\) \\(NPQ_{Aβ42/Aβ40} = 8.20 - 5.52 = 2.68\\) Calculate relative change in Aβ42/Aβ40 ratio: \\(ΔNPQ_{Ratio} = \\text{Sample B Ratio} - \\text{Sample A Ratio}\\) \\(ΔNPQ_{Ratio} = 2.68 - 3 = -0.32\\) Fold change = \\(2^{-0.32} = 0.8\\) Interpretation: The Aβ42/Aβ40 ratio in the Alzheimer’s patient is 0.8 times (or 20% lower than) that of the healthy control, which is consistent with clinical observations in plasma. The Aβ42/Aβ40 ratio reflects amyloid pathology, making it a powerful biomarker for Alzheimer’s disease diagnosis and monitoring. Data Analysis FAQ 1. How is the limit of detection (LOD) defined for NULISAseq? Why do some targets have LOD of 0? LOD is calculated separately for each target using the negative control (NC) samples. LOD is first calculated on the normalized count (normCount) scale and then one is added and log2-transformation is applied to get LOD on the NPQ scale. For NULISAseq, the LOD is defined as follows: Formula: \\[ \\text{LOD}_{normCount} = mean(\\text{NC}_{normCount}) + 3 \\cdot sd(\\text{NC}_{normCount}) \\] \\[ \\text{LOD}_{NPQ} = 2^{\\text{LOD}_{normCount} + 1} \\] LOD = 0 occurs when negative controls show no detectable signal (zero reads) at the current sequencing depth. 2. Should I exclude samples below LOD? We don’t recommend excluding individual values below LOD or replacing NPQ values with LOD. Why not? Excluding or replacing values creates non-normal distributions Non-normal distributions can violate model assumptions for analysis Values below LOD may lack precision but still carry information about the sample – we know the value is low Excluding reduces statistical power Instead, we recommend using a detectability cutoff to exclude targets with low detectability. 3. How do I calculate coefficient of variation (CV) for samples? IMPORTANT: Unlog NPQ values before calculating CV. NPQ values are on a log2 scale, but CV is only meaningful on the linear scale (normalized counts). Step-by-step process: Back-transform NPQ to linear scale: \\[ \\text{Linear value} = 2^{\\text{NPQ}} - 1 \\] Calculate mean and standard deviation on linear scale: \\[ \\text{Mean}_{\\text{linear}} = \\text{mean(linear values)} \\] \\[ \\text{SD}_{\\text{linear}} = \\text{sd(linear values)} \\] Calculate CV: \\[ \\text{CV} = \\frac{\\text{SD}_{\\text{linear}}}{\\text{Mean}_{\\text{linear}}} \\times 100\\% \\] Example in R: # For replicate samples of a single target npq_values &lt;- c(8.5, 8.7, 8.3) # NPQ values (log2 scale) # Back-transform to linear scale linear_values &lt;- 2^npq_values - 1 # Calculate CV mean_linear &lt;- mean(linear_values) sd_linear &lt;- sd(linear_values) cv_percent &lt;- (sd_linear / mean_linear) * 100 print(paste0(&quot;CV = &quot;, round(cv_percent, 2), &quot;%&quot;)) #&gt; [1] &quot;CV = 13.87%&quot; 4. Can I compare data across different runs? Yes! IPC normalization is designed to make data comparable across runs. Quality metrics supporting cross-run comparability include: Across-target mean and median sample control (SC) CVs typically &lt;10% High inter-sample correlations (inter-run Pearson correlation \\(r = 0.95\\)) In some cases intensity normalization or bridge samples (at least 6-8 samples per batch) can be used for further normalization. This enables long-term longitudinal studies. 5. How do you assess correlation between NPQ and absolute quantification data from other platforms? Transform datasets from other platforms to log2 scale first! Recommended approach: Convert absolute quantification values (e.g., pg/mL) to log2 scale Compare log2-transformed values against NPQ values using correlation Visualize with scatterplots before choosing correlation method Choosing the appropriate correlation method: ✅ Use Pearson correlation (r) when: Scatterplot shows approximately linear relationship No extreme outliers present Data appears normally distributed ✅ Use non-parametric methods (Spearman ρ or Kendall τ) when: Scatterplot shows nonlinear trend Extreme outliers present Very small sample size Data far from normal distribution Note: For non-parametric methods, the specific data transformation is less critical, but log2 transformation still helps with visualization and interpretability. Continue to: Chapter 1: Data Import "],["data-import.html", "Chapter 1 Data Import 1.1 The importNULISAseq() Function 1.2 Understanding the Data Structure 1.3 Working with Your Own Data 1.4 Loading Metadata 1.5 Merging Data with Metadata 1.6 Filtering Samples 1.7 Complete Import Workflow 1.8 Tips and Best Practices", " Chapter 1 Data Import This chapter covers importing NULISAseq data from XML files and understanding the data structure. 1.1 The importNULISAseq() Function NULISAseq data is typically stored in XML files, with one file per plate. The importNULISAseq() function reads these files and organizes the data into a structured format. # Path to example XML files included with the package data_dir &lt;- system.file(&quot;extdata&quot;, package = &quot;NULISAseqR&quot;) # Specify which XML files to import (usually multiple plates) xml_files &lt;- file.path( data_dir, c(&quot;INF_Panel_V1_detectability_study_plate01.xml&quot;, &quot;INF_Panel_V1_detectability_study_plate02.xml&quot;) ) # Import XML files data &lt;- importNULISAseq(files = xml_files) 1.2 Understanding the Data Structure The imported data object is a list containing multiple components: # View the top-level structure names(data) #&gt; [1] &quot;runs&quot; &quot;merged&quot; # The merged component contains combined data from all plates names(data$merged) #&gt; [1] &quot;plateID&quot; &quot;fileNames&quot; &quot;ExecutionDetails&quot; &quot;IC&quot; #&gt; [5] &quot;targets&quot; &quot;samples&quot; &quot;qcSample&quot; &quot;qcPlate&quot; #&gt; [9] &quot;detectability&quot; &quot;IPC&quot; &quot;SC&quot; &quot;NC&quot; #&gt; [13] &quot;SampleNames&quot; &quot;match_matrix&quot; &quot;Data_raw&quot; &quot;aboveLOD&quot; #&gt; [17] &quot;Data_NPQ_long&quot; &quot;Data_NPQ&quot; 1.2.1 Key Components The most important components are: 1.2.1.1 Wide-Format Matrix: data$merged$Data_NPQ This is a matrix where: Rows = protein targets Columns = samples Values = NULISA Protein Quantification (NPQ), a normalized, log2-scale measure of relative protein abundance Note that control samples (IPC: inter-plate control, SC: sample control, NC: negative control) are included # Check dimensions of the wide-format matrix dim(data$merged$Data_NPQ) #&gt; [1] 206 192 # Number of proteins: nrow(data$merged$Data_NPQ) #&gt; [1] 206 # Number of samples: ncol(data$merged$Data_NPQ) #&gt; [1] 192 #&gt; Preview of NPQ matrix (first 10 proteins × 10 samples, rounded to 3 digits): 1.2.1.2 Long-Format Data Frame: data$merged$Data_NPQ_long This is a “tidy” format where: One row per protein-sample combination Easier for plotting with ggplot2 Note that control samples are included in this data frame as well and can be filtered using the SampleType column #&gt; Preview of NPQ long data frame (first 20 rows): # Check Long-format dimensions # Total rows nrow(data$merged$Data_NPQ_long) #&gt; [1] 39552 # Total columns ncol(data$merged$Data_NPQ_long) #&gt; [1] 26 # Show column information str(data$merged$Data_NPQ_long) #&gt; tibble [39,552 × 26] (S3: tbl_df/tbl/data.frame) #&gt; $ Panel : Factor w/ 1 level &quot;NULISAseq&quot;: 1 1 1 1 1 1 1 1 1 1 ... #&gt; $ PlateID : Factor w/ 2 levels &quot;Plate_01&quot;,&quot;Plate_02&quot;: 1 1 1 1 1 1 1 1 1 1 ... #&gt; $ SampleName : chr [1:39552] &quot;SMI_A1_Donor01_Plate_01&quot; &quot;SMI_A2_Donor02_Plate_01&quot; &quot;SMI_A3_Donor03_Plate_01&quot; &quot;SMI_A4_Donor04_Plate_01&quot; ... #&gt; $ SampleType : Factor w/ 4 levels &quot;IPC&quot;,&quot;NC&quot;,&quot;Sample&quot;,..: 3 3 3 3 3 3 3 3 3 3 ... #&gt; $ Target : Factor w/ 207 levels &quot;Activin AB&quot;,&quot;AGER&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... #&gt; $ AlamarTargetID : logi [1:39552] NA NA NA NA NA NA ... #&gt; $ LOD : num [1:39552] 12.3 12.3 12.3 12.3 12.3 ... #&gt; $ UnnormalizedCount : int [1:39552] 139 168 130 149 166 236 134 138 175 153 ... #&gt; $ NPQ : num [1:39552] 12.4 12.4 12.1 12.5 12.5 ... #&gt; $ Sample_QC_Status : chr [1:39552] &quot;PASS&quot; &quot;PASS&quot; &quot;PASS&quot; &quot;PASS&quot; ... #&gt; $ Sample_QC_IC_Median : num [1:39552] -0.15102 0.02814 -0.00272 -0.11912 -0.03445 ... #&gt; $ Sample_QC_Detectability : num [1:39552] 0.937 0.956 0.903 0.961 0.922 ... #&gt; $ Sample_QC_ICReads : num [1:39552] 4843 5865 5689 5025 5508 ... #&gt; $ Sample_QC_NumReads : num [1:39552] 1375151 2527201 1363189 1590171 853532 ... #&gt; $ Sample_QC_IC_Median_Status : chr [1:39552] &quot;PASS&quot; &quot;PASS&quot; &quot;PASS&quot; &quot;PASS&quot; ... #&gt; $ Sample_QC_Detectability_Status: chr [1:39552] &quot;PASS&quot; &quot;PASS&quot; &quot;PASS&quot; &quot;PASS&quot; ... #&gt; $ Sample_QC_ICReads_Status : chr [1:39552] &quot;PASS&quot; &quot;PASS&quot; &quot;PASS&quot; &quot;PASS&quot; ... #&gt; $ Sample_QC_NumReads_Status : chr [1:39552] &quot;PASS&quot; &quot;PASS&quot; &quot;PASS&quot; &quot;PASS&quot; ... #&gt; $ sampleBarcode : Factor w/ 96 levels &quot;285582&quot;,&quot;434032&quot;,..: 1 2 3 4 5 6 7 8 9 10 ... #&gt; $ sampleName_original : Factor w/ 97 levels &quot;SMI_A1_Donor01&quot;,..: 1 5 6 7 8 9 10 11 12 2 ... #&gt; $ wellRow : Factor w/ 8 levels &quot;A&quot;,&quot;B&quot;,&quot;C&quot;,&quot;D&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... #&gt; $ wellCol : int [1:39552] 1 2 3 4 5 6 7 8 9 10 ... #&gt; $ matching : int [1:39552] 1375151 2527201 1363189 1590171 853532 1491973 1088088 1860179 4295345 1363789 ... #&gt; $ non-matching : int [1:39552] 809490 889801 896515 808401 764198 960013 749406 946096 909565 740015 ... #&gt; $ SAMPLE_MATRIX : Factor w/ 2 levels &quot;PLASMA&quot;,&quot;CONTROL&quot;: 1 1 1 1 1 1 1 1 1 1 ... #&gt; $ sampleID : Factor w/ 192 levels &quot;SMI_A1_Donor01_Plate_01&quot;,..: 1 9 11 13 15 17 19 21 23 3 ... 1.2.1.3 Samples Metadata Data Frame: data$merged$samples This is a “tidy” format where: One row per sample sampleName column corresponds to column names of wide data data$merged$Data_NPQ and SampleName column of long data data$merged$Data_NPQ_long Control samples are included and can be identified using the sampleType column #&gt; Preview of sample data frame (first 20 samples): # Show column information str(data$merged$samples) #&gt; tibble [192 × 12] (S3: tbl_df/tbl/data.frame) #&gt; $ plateID : Factor w/ 2 levels &quot;Plate_01&quot;,&quot;Plate_02&quot;: 1 1 1 1 1 1 1 1 1 1 ... #&gt; $ plateGUID : Factor w/ 1 level &quot;Plate_1&quot;: 1 1 1 1 1 1 1 1 1 1 ... #&gt; $ sampleType : Factor w/ 4 levels &quot;IPC&quot;,&quot;NC&quot;,&quot;Sample&quot;,..: 3 3 3 3 3 3 3 3 3 3 ... #&gt; $ sampleBarcode : Factor w/ 96 levels &quot;285582&quot;,&quot;434032&quot;,..: 1 2 3 4 5 6 7 8 9 10 ... #&gt; $ sampleName : chr [1:192] &quot;SMI_A1_Donor01_Plate_01&quot; &quot;SMI_A2_Donor02_Plate_01&quot; &quot;SMI_A3_Donor03_Plate_01&quot; &quot;SMI_A4_Donor04_Plate_01&quot; ... #&gt; $ sampleName_original: chr [1:192] &quot;SMI_A1_Donor01&quot; &quot;SMI_A2_Donor02&quot; &quot;SMI_A3_Donor03&quot; &quot;SMI_A4_Donor04&quot; ... #&gt; $ wellRow : Factor w/ 8 levels &quot;A&quot;,&quot;B&quot;,&quot;C&quot;,&quot;D&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... #&gt; $ wellCol : num [1:192] 1 2 3 4 5 6 7 8 9 10 ... #&gt; $ matching : num [1:192] 1375151 2527201 1363189 1590171 853532 ... #&gt; $ non-matching : num [1:192] 809490 889801 896515 808401 764198 ... #&gt; $ SAMPLE_MATRIX : Factor w/ 2 levels &quot;PLASMA&quot;,&quot;CONTROL&quot;: 1 1 1 1 1 1 1 1 1 1 ... #&gt; $ sampleID : chr [1:192] &quot;SMI_A1_Donor01_Plate_01&quot; &quot;SMI_A2_Donor02_Plate_01&quot; &quot;SMI_A3_Donor03_Plate_01&quot; &quot;SMI_A4_Donor04_Plate_01&quot; ... # Tabulate sample type to see control sample numbers # Typically each run will have 3 IPC, 3 SC, and 4 NC # These runs are missing some IPC and SC table(data$merged$samples$sampleType) #&gt; #&gt; IPC NC Sample SC #&gt; 4 8 176 4 1.2.1.4 Targets Metadata Data Frame: data$merged$targets This is a data frame where: One row per target targetName column corresponds to row names of wide data data$merged$Data_NPQ and Target column of long data data$merged$Data_NPQ_long Targets data frame also includes a row for the internal control spike-in target(s) (internal controls are removed from Data_NPQ matrices) #&gt; Preview of targets data frame (first 20 targets): # Show column information str(data$merged$targets) #&gt; &#39;data.frame&#39;: 414 obs. of 13 variables: #&gt; $ targetBarcode : chr &quot;7189027_7569675&quot; &quot;1625168_1625168&quot; &quot;1902917_1902917&quot; &quot;14763184_14763184&quot; ... #&gt; $ targetName : chr &quot;Activin AB&quot; &quot;AGER&quot; &quot;AGRP&quot; &quot;ANGPT1&quot; ... #&gt; $ Curve_Quant : chr &quot;F&quot; &quot;F&quot; &quot;F&quot; &quot;F&quot; ... #&gt; $ targetType : chr &quot;target&quot; &quot;target&quot; &quot;target&quot; &quot;target&quot; ... #&gt; $ modifiers : logi NA NA NA NA NA NA ... #&gt; $ hide : logi FALSE FALSE FALSE FALSE FALSE FALSE ... #&gt; $ noDetectability : logi FALSE FALSE FALSE FALSE FALSE FALSE ... #&gt; $ AlamarTargetID : logi NA NA NA NA NA NA ... #&gt; $ targetDetectability: num 64.8 100 100 100 78.4 ... #&gt; $ targetLOD : num 5037.2 0 72.8 260.3 1745.6 ... #&gt; $ logged_LOD : num 12.3 0 6.21 8.03 10.77 ... #&gt; $ rev_logged_LOD : num 12.3 0 6.21 8.03 10.77 ... #&gt; $ plateID : Factor w/ 2 levels &quot;Plate_01&quot;,&quot;Plate_02&quot;: 1 1 1 1 1 1 1 1 1 1 ... # Show internal control target rows using targetType data$merged$targets[data$merged$targets$targetType==&#39;control&#39;,] #&gt; targetBarcode targetName Curve_Quant targetType modifiers hide #&gt; 143 12867621_12867621 mCherry F control NA FALSE #&gt; 350 12867621_12867621 mCherry F control NA FALSE #&gt; noDetectability AlamarTargetID targetDetectability targetLOD logged_LOD #&gt; 143 FALSE NA NA NA NA #&gt; 350 FALSE NA NA NA NA #&gt; rev_logged_LOD plateID #&gt; 143 NA Plate_01 #&gt; 350 NA Plate_02 1.2.1.5 Need More Details? For complete function documentation and additional options of importNULISAseq(), use: ?importNULISAseq This will show: All available parameters Detailed descriptions Return value structure Usage examples 1.2.2 Summary Statistics Get a quick overview of your data: # NPQ value distribution summary(data$merged$Data_NPQ_long$NPQ) #&gt; Min. 1st Qu. Median Mean 3rd Qu. Max. #&gt; 0.00 12.83 13.42 13.24 14.10 29.11 # Count missing values n_missing &lt;- sum(is.na(data$merged$Data_NPQ_long$NPQ)) n_total &lt;- nrow(data$merged$Data_NPQ_long) #&gt; #&gt; Missing values: 0 out of 39552 ( 0 %) #&gt; #&gt; Data summary: #&gt; Unique proteins: 206 #&gt; Unique samples: 192 #&gt; Unique plates: 2 1.3 Working with Your Own Data When working with your own XML files: # Option 1: Specify full paths my_xml_files &lt;- c( &quot;/path/to/plate01.xml&quot;, &quot;/path/to/plate02.xml&quot; ) my_data &lt;- importNULISAseq(files = my_xml_files) # Option 2: Import all XML files in a directory data_dir &lt;- &quot;/path/to/my/data/&quot; xml_files &lt;- list.files(data_dir, pattern = &quot;\\\\.xml$&quot;, full.names = TRUE) my_data &lt;- importNULISAseq(files = xml_files) 1.4 Loading Metadata Metadata provides critical information about your samples (disease status, demographics, experimental conditions, etc.). # Read metadata from CSV metadata &lt;- read_csv( system.file(&quot;extdata&quot;, &quot;Alamar_NULISAseq_Detectability_metadata.csv&quot;, package = &quot;NULISAseqR&quot;) ) # Prepare metadata with proper factor levels metadata &lt;- metadata %&gt;% mutate( # Set factor levels in meaningful order (reference group first) disease_type = factor( disease_type, levels = c(&quot;normal&quot;, &quot;inflam&quot;, &quot;cancer&quot;, &quot;kidney&quot;, &quot;metab&quot;, &quot;neuro&quot;) ), # Ensure numeric variables are properly typed age = as.numeric(age) ) 1.4.1 Metadata Structure Your metadata should contain: Sample identifiers: Must match SampleName column in the XML data data$merged$Data_NPQ_long or data$merged$samples Experimental variables: Disease type, treatment, etc. Covariates: Age, sex, batch, etc. Optional: Sample matrix type, collection date, etc. #&gt; Preview of metadata (first 20 rows): # Check variable types str(metadata) #&gt; tibble [167 × 7] (S3: tbl_df/tbl/data.frame) #&gt; $ PlateID : chr [1:167] &quot;Plate_01&quot; &quot;Plate_01&quot; &quot;Plate_01&quot; &quot;Plate_01&quot; ... #&gt; $ SampleID : chr [1:167] &quot;SMI_A1_Donor01&quot; &quot;SMI_A2_Donor02&quot; &quot;SMI_A3_Donor03&quot; &quot;SMI_A5_Donor05&quot; ... #&gt; $ SampleMatrix: chr [1:167] &quot;Plasma&quot; &quot;Plasma&quot; &quot;Plasma&quot; &quot;Plasma&quot; ... #&gt; $ sex : chr [1:167] &quot;Male&quot; &quot;Male&quot; &quot;Male&quot; &quot;Female&quot; ... #&gt; $ age : num [1:167] 38 54 52 46 70 37 80 52 60 57 ... #&gt; $ disease_type: Factor w/ 6 levels &quot;normal&quot;,&quot;inflam&quot;,..: 1 3 1 1 3 1 2 1 1 5 ... #&gt; $ SampleName : chr [1:167] &quot;SMI_A1_Donor01_Plate_01&quot; &quot;SMI_A2_Donor02_Plate_01&quot; &quot;SMI_A3_Donor03_Plate_01&quot; &quot;SMI_A5_Donor05_Plate_01&quot; ... # Summary of key variables table(metadata$disease_type, useNA=&#39;always&#39;) Example output: disease_type normal inflam cancer kidney metab neuro 79 21 32 4 9 6 # Cross-tabulation of disease type by sex table(metadata$disease_type, metadata$sex, useNA=&#39;always&#39;) Example output: F M normal 34 45 inflam 18 3 cancer 11 21 kidney 2 2 metab 8 1 neuro 3 3 1.5 Merging Data with Metadata Combining expression data with metadata enables integrated analysis: 1.5.1 Understanding Sample Names When importing multi-plate data, NULISAseqR processes sample names to ensure uniqueness: sampleName_original: The original sample name as it appears in the XML file, preserved exactly as input by the user SampleName: The processed sample name used throughout the analysis, which may be modified to: Rename control samples for consistency across plates (e.g., IPC_1, IPC_2, etc.) Resolve duplicate sample names when combining multiple plates (e.g., Sample_A becomes Sample_A_P1, Sample_A_P2) 1.5.2 Merging Options Option 1: Merge using processed SampleName (recommended for most cases) Use this when your metadata uses the standardized sample names: # Merge using processed SampleName data_long &lt;- data$merged$Data_NPQ_long %&gt;% left_join(metadata, by = c(&quot;SampleName&quot;, &quot;PlateID&quot;)) Option 2: Merge using original sample names Use this when your metadata contains the original sample names as they appeared in the XML files: # Merge using original sample names from XML data_long &lt;- data$merged$Data_NPQ_long %&gt;% left_join(metadata, by = c(&quot;sampleName_original&quot; = &quot;YourOriginalNameColumn&quot;, &quot;PlateID&quot;)) #&gt; First 20 rows of merged data: # Verify the merge # Original NPQ data rows: nrow(data$merged$Data_NPQ_long) #&gt; [1] 39552 # Merged data rows nrow(data_long) #&gt; [1] 39552 cat(&quot; Match:&quot;, nrow(data_long) == nrow(data$merged$Data_NPQ_long), &quot;\\n\\n&quot;) #&gt; Match: TRUE # Show what metadata columns were added new_cols &lt;- setdiff(names(data_long), names(data$merged$Data_NPQ_long)) # Metadata columns added paste(new_cols, collapse = &quot;, &quot;) #&gt; [1] &quot;SampleID, SampleMatrix, sex, age, disease_type&quot; # Check for any unmatched samples unmatched_data &lt;- anti_join( data$merged$Data_NPQ_long, metadata, by = c(&quot;SampleName&quot;, &quot;PlateID&quot;) ) unmatched_meta &lt;- anti_join( metadata, data$merged$Data_NPQ_long, by = c(&quot;SampleName&quot;, &quot;PlateID&quot;) ) # Merge quality check # Samples in data but not in metadata: length(unique(unmatched_data$SampleName)) #&gt; [1] 25 # Samples in metadata but not in data: length(unique(unmatched_meta$SampleName)) #&gt; [1] 0 if (length(unique(unmatched_data$SampleName)) &gt; 0) { cat(&quot;\\n⚠ Warning: Some samples lack metadata:\\n&quot;) print(unique(unmatched_data$SampleName)) } #&gt; #&gt; ⚠ Warning: Some samples lack metadata: #&gt; [1] &quot;SMI_A4_Donor04_Plate_01&quot; &quot;SMI_A10_Donor10_Plate_01&quot; #&gt; [3] &quot;SMI_A12_IPC_rep01_Plate_01&quot; &quot;SMI_B12_IPC_rep02_Plate_01&quot; #&gt; [5] &quot;SMI_C6_Donor26_Plate_01&quot; &quot;SMI_C12_SPC_rep03&quot; #&gt; [7] &quot;SMI_D12_SC_rep04_Plate_01&quot; &quot;SMI_E10_Donor50_Plate_01&quot; #&gt; [9] &quot;SMI_E12_NTC_rep01_Plate_01&quot; &quot;SMI_F12_NTC_rep02_Plate_01&quot; #&gt; [11] &quot;SMI_G5_Donor65_Plate_01&quot; &quot;SMI_G12_NTC_rep03_Plate_01&quot; #&gt; [13] &quot;SMI_H6_Donor76_Plate_01&quot; &quot;SMI_H12_NTC_rep04_Plate_01&quot; #&gt; [15] &quot;SMI_A12_IPC_rep01_Plate_02&quot; &quot;SMI_B1_Donor11_Plate_02&quot; #&gt; [17] &quot;SMI_B12_IPC_rep02_Plate_02&quot; &quot;SMI_C1_Donor21_Plate_02&quot; #&gt; [19] &quot;SMI_C12_SC_rep03&quot; &quot;SMI_D12_SC_rep04_Plate_02&quot; #&gt; [21] &quot;SMI_E12_NTC_rep01_Plate_02&quot; &quot;SMI_F10_Donor60_Plate_02&quot; #&gt; [23] &quot;SMI_F12_NTC_rep02_Plate_02&quot; &quot;SMI_G12_NTC_rep03_Plate_02&quot; #&gt; [25] &quot;SMI_H12_NTC_rep04_Plate_02&quot; Sample Controls were not included in metadata. Also, some samples in the XML data did not have corresponding metadata entries. Ensure all samples of interest are included in the metadata. 1.6 Filtering Samples Often you’ll want to analyze a subset of samples: # Example: Filter for plasma samples only sample_list &lt;- metadata %&gt;% filter(SampleMatrix == &quot;Plasma&quot;) %&gt;% pull(SampleName) # Number of plasma samples length(sample_list) #&gt; [1] 151 # Subset the expression matrix data_plasma &lt;- data$merged$Data_NPQ[, sample_list] dim(data_plasma) #&gt; [1] 206 151 1.7 Complete Import Workflow Here’s a complete example putting it all together: # Load libraries library(NULISAseqR) library(tidyverse) # 1. Import XML data data_dir &lt;- system.file(&quot;extdata&quot;, package = &quot;NULISAseqR&quot;) xml_files &lt;- file.path( data_dir, c(&quot;INF_Panel_V1_detectability_study_plate01.xml&quot;, &quot;INF_Panel_V1_detectability_study_plate02.xml&quot;) ) data &lt;- importNULISAseq(files = xml_files) # 2. Load metadata metadata &lt;- read_csv( system.file(&quot;extdata&quot;, &quot;Alamar_NULISAseq_Detectability_metadata.csv&quot;, package = &quot;NULISAseqR&quot;) ) metadata &lt;- metadata %&gt;% mutate( # Set factor levels in meaningful order (reference group first) disease_type = factor( disease_type, levels = c(&quot;normal&quot;, &quot;inflam&quot;, &quot;cancer&quot;, &quot;kidney&quot;, &quot;metab&quot;, &quot;neuro&quot;) ), # Ensure numeric variables are properly typed age = as.numeric(age) ) # 3. Merge data with metadata data_long &lt;- data$merged$Data_NPQ_long %&gt;% left_join(metadata, by = c(&quot;SampleName&quot;, &quot;PlateID&quot;)) # 4. Filter to samples of interest sample_list &lt;- metadata %&gt;% filter(SampleMatrix == &quot;Plasma&quot;) %&gt;% pull(SampleName) ## Ready for analysis! nrow(data$merged$Data_NPQ) length(sample_list) 1.8 Tips and Best Practices File Organization Keep XML files in a dedicated directory Use consistent naming conventions Document which files correspond to which experiments Metadata Management Store metadata in CSV format for easy editing Include all relevant variables from the start Use meaningful, consistent variable names Set factor levels explicitly (don’t rely on alphabetical order) Quality Checks Verify sample names match between XML and metadata Check for missing values Confirm data dimensions make sense Common Issues Mismatched names: Ensure sample names in XML match metadata exactly Factor levels: Always set reference level first for interpretable results Missing metadata: Filter out samples without metadata before analysis Continue to: Chapter 2: Quality Control "],["quality-control.html", "Chapter 2 Quality Control 2.1 Why Quality Control Matters 2.2 Automated QC Report 2.3 QC Report Structure 2.4 Summary of QC Thresholds 2.5 Manual QC Checks 2.6 Best Practices 2.7 Complete QC Workflow", " Chapter 2 Quality Control Quality control is essential before proceeding with statistical analysis. This chapter covers generating QC reports and interpreting quality control metrics at the plate, run, sample, and target levels. 2.1 Why Quality Control Matters Quality control helps identify: Technical issues with sample processing Outlier samples Problems with specific protein targets Batch effects Overall data quality and reliability Always perform QC before analysis! Problems caught early save time and ensure valid results. 2.2 Automated QC Report NULISAseqR includes a built-in QC report template that generates comprehensive quality metrics across multiple levels: plate/run, sample, and target. # Specify output directory out_dir &lt;- tempdir() # Or use your preferred directory ## See Chapter 1 for loading data # # data_dir &lt;- system.file(&quot;extdata&quot;, package = &quot;NULISAseqR&quot;) # # xml_files &lt;- file.path( # data_dir, # c(&quot;INF_Panel_V1_detectability_study_plate01.xml&quot;, # &quot;INF_Panel_V1_detectability_study_plate02.xml&quot;) # ) render_QC_report( output_filename = &quot;Detectability_Study_NULISAseq_QC_report.html&quot;, output_dir = out_dir, study_name = &quot;NULISAseq QC Report - Detectability Study&quot;, assayName = &quot;Inflammation Panel 250&quot;, dataDir = data_dir, xml_files = basename(xml_files), report_type = &quot;webApp&quot; ) # View the report browseURL(file.path(out_dir, &quot;Detectability_Study_NULISAseq_QC_report.html&quot;)) 2.3 QC Report Structure The automated QC report is organized into several key sections: 2.3.1 Plate Layout Visual representation of sample placement on 96-well plates showing: Sample positions and identifiers Control sample locations (NC, IPC, SC) Plate ID assignment and verification 2.3.2 Run Summary The report provides detailed summaries for overall reads and each type of control sample: 2.3.2.1 Interal Controls (IC) The IC is an exogenous reporter protein added to each well for well-to-well normalization and assessing the uniformity of the assay run. 2.3.2.2 Inter-Plate Controls (IPC) IPCs are pooled plasma controls used for normalization between plates. 2.3.2.3 Sample Controls (SC) SCs are pooled plasma controls sourced independently from IPCs, and are used to assess intra-plate and inter-plate coefficient of variation (CV). 2.3.2.4 Negative Controls (NC) NC wells contain assay buffer. For each plate, NCs are used to determine Limit of Detection (LOD) and give a measure of assay background for each target. Quality Control Metrics The QC report evaluates quality at three levels: Run QC Sample QC Target Detectability 2.3.3 Plate/Run QC Run-level QC metrics assess the overall quality of each assay plate/run. These are evaluated on both unnormalized (raw) and IPC-normalized data. Run-level QC metrics assess the overall quality of each assay run. These are evaluated on both unnormalized (raw) and IPC-normalized data. Run QC Criteria 1. IC CV (Internal Control Coefficient of Variation) Definition: CV of internal control Parseable Matching reads across all wells Threshold: Maximum 25% Purpose: Assesses technical variability within a plate Interpretation: ✓ CV ≤ 25%: Good technical reproducibility ✗ CV &gt; 25%: High technical variation, investigate plate processing 2. IPC CV (Inter-Plate Control CV) Definition: CV of total sum of Parseable Matching reads across all IPC samples Threshold: Maximum 25% Purpose: Evaluates consistency of control samples Interpretation: ✓ CV ≤ 25%: IPCs performing consistently ✗ CV &gt; 25%: IPC variability too high, may affect normalization 3. IPC Target CV Definition: Median intra-plate CV of IC-IPC normalized reads for all IPC targets across replicates Threshold: Maximum 10% Purpose: Assesses reproducibility at the protein target level Interpretation: ✓ Median CV ≤ 10%: Excellent target-level precision ✗ Median CV &gt; 10%: Some targets showing poor precision 4. Run Detectability Definition: Percentage of targets that are detectable (&gt; 50% of samples above LOD) Threshold: Minimum 90% Purpose: Overall assessment of assay sensitivity Interpretation: ✓ Detectability ≥ 90%: Most targets detecting well ✗ Detectability &lt; 90%: Poor overall detection, check sample quality or assay conditions 5. Reads (Total Parseable Matching Reads) Definition: Minimum number of reads required per plate Threshold: Minimum 100,000,000 reads Purpose: Ensures sufficient sequencing depth Interpretation: ✓ Reads ≥ 100M: Adequate sequencing coverage ✗ Reads &lt; 100M: Insufficient depth, may need re-sequencing 2.3.4 Sample QC Sample-level QC identifies individual samples that may have quality issues. Sample QC Criteria 1. Sample Detectability Definition: Percentage of targets with reads above LOD for each sample Thresholds (vary by sample type): Plasma: Minimum 90% Serum: Minimum 90% CSF: Minimum 70% Urine: Minimum 65% Cell culture: Minimum 30% NHP plasma: Minimum 55% NHP serum: Minimum 55% NHP CSF: Minimum 35% Dried blood spot: Minimum 75% Control: Minimum 90% Other: Minimum 0% Purpose: Identifies samples with low overall protein detection Interpretation: ✓ Detectability above threshold: Sample has adequate protein levels ✗ Detectability below threshold: Sample may be degraded, diluted, or have insufficient protein 2. IC Median (Internal Control Median) Definition: Sample IC reads relative to the plate median Threshold: Within ±40% of plate median Purpose: Identifies samples with abnormal internal control performance Interpretation: ✓ IC Median within ±40%: Sample processed normally ✗ IC Median outside ±40%: Potential pipetting error, reagent issue, or sample quality problem 3. IC Reads per Sample Definition: Minimum number of reads required per sample for internal control Threshold: Minimum 1000 reads Purpose: Ensures adequate internal control signal Interpretation: ✓ Reads ≥ 1000: Sample has adequate IC signal ✗ Reads &lt; 1000: Sample has insufficient IC signal, may affect normalization 4. Total Reads per Sample Definition: Minimum number of reads required per sample Threshold: Minimum 500,000 reads Purpose: Ensures sufficient sequencing depth per sample Interpretation: ✓ Reads ≥ 500K: Sample has adequate sequencing coverage ✗ Reads &lt; 500K: Sample has low signal, may need re-sequencing Sample QC Plots The QC report includes several plots for sample assessment: Detectability Plot: Shows the percentage of targets detected for each sample (Figures 2.1 and 2.2) IC Median Plot: Displays internal control performance relative to plate median (Figures 2.1 and 2.2) Reads Distribution: Shows the distribution of total reads across samples (Figures 2.1 and 2.2) Sample Boxplots: Display normalized expression distributions for each sample (Figures 2.3 and 2.4) Sample Correlation Plots: Shows clustered heatmap of sample correlation matrix. Samples with high correlation will cluster together into blocks on the diagonal, which can be helpful for identifying sample replicates or multiple samples from the same individuals at different time points. Sample and Target Clustering: Shows clustered heatmap of scaled NPQ matrix by sample and target Sample PCA: Helpful for identifying outlier samples and batch effects These visualizations help identify: Samples with low protein detection Samples with abnormal internal control performance Outlier samples requiring further investigation Overall quality and consistency within and between plates Figure 2.1: Sample QC plots for Plate_01 Figure 2.2: Sample QC plots for Plate_02 Sample Boxplots Before and After Normalization show the distribution of protein expression across samples before and after normalization with internal controls: Figure 2.3: Sample boxplots for Plate_01 after normalization Figure 2.4: Sample boxplots for Plate_02 after normalization Interpreting Sample Boxplots: After IC normalization, sample boxplots should show similar median values and distributions. Outlier samples with shifted or compressed distributions may indicate quality issues. For example, in Plate_01, sample SMI_G05_Donor65 shows a high IC value before normalization (left), and after normalization this sample shows a lower distribution relative to other samples (right), indicating that IC normalization was too aggressive (Figure 2.3). 2.3.5 Target QC Target-level QC assesses the performance of individual protein markers. Key Target QC Metrics 1. Target Detectability Definition: Percentage of samples in which a target is detected (above LOD) Recommendation: Targets with &lt; 50% detectability should be carefully evaluated Purpose: Identifies poorly performing or low-abundance targets 2. Limit of Detection (LOD) Definition: Minimum signal level that can be reliably distinguished from background Calculation: Calculated from negative control (NC) samples, mean + 3 standard deviations of normalized counts of NCs Usage: Values below LOD should be excluded from CV calculations Consider filtering targets with high proportion of values below LOD for differential analysis Visualized in target detectability boxplots relative to LOD LOD of specific targets: Most LODs for the targets in the panel represent the lower limit of detection. There are some exception: High-abundance targets: Inflammation Panel: CRP and KNG1 in Human plasma and serum samples CNS Panel: APOE and CRP in Human plasma and serum samples Mouse Panel: Crp in Mouse plasma and serum samples These targets have very high endogenous levels in the samples. In order to accommodate these targets into our panel together with other lower abundance targets, we use special tuning strategies and algorithms to perform sample measurements. As a result, the listed LOD values for these targets are the upper limit of detection. Detectability is not a concern given the high level of these targets and the NPQ values can still be used for secondary data analysis. For novel sample types other than listed sample matrices, however, the algorithm may not be applicable depending on the abundance levels of the analyte, and the NPQ will not be reported. 2.3.6 Coefficient of Variation (CV) CV analysis assesses assay precision within and between plates: 2.3.6.1 Intra-Plate CV Measures variability within a single plate using control samples: Key features: CV calculated for SC and IPC samples within each plate Separate analysis for unnormalized and IC-normalized data Excludes values below LOD 2.3.6.2 Inter-Plate CV Measures variability across multiple plates, assessing batch effects: The inter-plate CV plot demonstrates: Effectiveness of normalization strategies Reduction in CV after IC normalization Additional benefit of IPC normalization 2.3.7 Batch Effect Assessment Batch effects occur when systematic technical variation between assay plates affect the measured protein abundance, potentially confounding biological signals. The batch effect assessment uses statistical methods to quantify how much variability in each target’s measurements can be attributed to plate, helping identify targets that may require additional batch normalization, adjustment for Plate ID in downstream models, or careful interpretation in downstream analyses. 2.3.7.1 Batch Effect QC Summary The plate-level assessment evaluates whether each plate shows systematic bias across multiple targets: Interpreting plate-level results: Pass: Plate shows acceptable consistency with other plates Warning: Plate may have systematic technical issues affecting multiple targets Plates with warnings should be investigated for pre-analytical or technical issues 2.3.7.2 Batch Effects Target QC The table reports batch effect targets with the following metrics: run ICC &gt; 10% significant F-test (unadjusted p &lt; 0.01) significant pairwise test for at least one run (Tukey-adjusted p &lt; 0.01) 2.3.7.3 Batch Effect ICC Analysis The Intra-Class Correlation (ICC) quantifies the proportion of total variance attributable to batch effects for each target: The ICC is calculated using a linear mixed-effects model with plate ID as a random effect: \\[ICC = \\frac{\\sigma^2_{plate}}{\\sigma^2_{plate} + \\sigma^2_{residual}} \\times 100\\] Interpreting ICC values: ICC &gt; 10% (highlighted in red): Substantial batch effect that may require normalization or statistical adjustment ICC &lt; 10%: Batch effects are minimal and unlikely to confound biological interpretation Targets with high batch effect ICC should be interpreted cautiously in downstream analyses Common causes of batch effects: Batch-to-batch reagent variation Temporal drift in instrument performance Environmental conditions during sample processing Sample-to-plate assignment that correlates with biological variables When batch effects are detected, consider including plate as a covariate in statistical models or using batch correction methods before downstream analysis. It is best practice to always randomize samples to plates so that technical run-related variation can be distinguished from biological variation. Please refer to Tech Note - NULISATM multiplex normalization &amp; quality control for advice on sample randomization. See Technical Documentation in the Additional Resources chapter. 2.4 Summary of QC Thresholds Table 2.1: Summary of NULISAseq QC thresholds and their purposes Level Metric Threshold Purpose Plate/Run IC CV ≤ 25% Technical reproducibility Plate/Run IPC CV ≤ 25% Control precision Plate/Run IPC Target CV ≤ 10% Target-level precision Plate/Run Run Detectability ≥ 90% Overall sensitivity Plate/Run Total Reads ≥ 100M Sequencing depth Sample Detectability (plasma/serum) ≥ 90% Sample protein levels Sample Detectability (CSF) ≥ 70% Sample protein levels Sample IC Median ±40% of plate median Processing precision Target Detectability &gt; 50% samples Target performance Target Intra-plate CV &lt; 10% median Within-plate precision Target Inter-plate CV &lt; 15% median Cross-plate precision Note: Thresholds may be adjusted based on specific study requirements and sample types. Always document any deviations from standard thresholds. 2.5 Manual QC Checks In addition to the automated report, performing manual QC checks provides deeper insights into your data quality and helps you make informed decisions about filtering strategies. 2.5.1 Check for Missing Data Missing data for high-abundance targets: Certain targets use specialized normalization algorithms optimized for specific sample types. NPQ values for these targets may be missing in non-validated sample matrices: Inflammation Panel: CRP and KNG1 are only reported for human plasma and serum samples CNS Panel: APOE and CRP are only reported for human plasma and serum samples Mouse Panel: Crp is only reported for mouse plasma and serum samples These proteins have exceptionally high endogenous levels that require matrix-specific tuning. If you’re analyzing novel sample types (e.g., tissue lysates, saliva, urine), the normalization algorithm may not be applicable, and NPQ values will not be generated for these specific targets. # Count missing values missing_by_sample &lt;- colSums(is.na(data$merged$Data_NPQ)) missing_by_protein &lt;- rowSums(is.na(data$merged$Data_NPQ)) # Samples with high missingness high_missing_samples &lt;- names(missing_by_sample[missing_by_sample &gt; 0.1 * nrow(data$merged$Data_NPQ)]) cat(&quot;Samples with &gt;10% missing:&quot;, length(high_missing_samples), &quot;\\n&quot;) # Proteins with high missingness high_missing_proteins &lt;- names(missing_by_protein[missing_by_protein &gt; 0.1 * ncol(data$merged$Data_NPQ)]) cat(&quot;Proteins with &gt;10% missing:&quot;, length(high_missing_proteins), &quot;\\n&quot;) 2.5.2 Low Detectability Targets Why filter by detectability? Low-detectability targets present several analytical challenges: Non-normal distributions: In typical sample types, targets with &lt; 50% detectability often have bimodal or highly skewed distributions due to a mixture of detected values and below-LOD measurements Heteroscedasticity: Low-detectability targets may violate homoscedasticity assumptions for statistical methods that assume equal variance between groups Statistical power and false positives: Proteins detected in only a minority of samples provide limited power for detecting biological differences, or they could generate false positive findings if distributional assumptions are violated Biological interpretation: Proteins rarely detected may be below biologically relevant concentrations or unstable in the sample type Recommended detectability thresholds: For standard sample matrices (plasma, serum, CSF), we recommend: &gt; 50% detectability: Minimum threshold for robust statistical analysis Ensures data has approximate normal distribution after log-transformation Provides adequate power for differential abundance analysis For exploratory analyses or novel sample types: All targets (0% threshold): Acceptable for initial data exploration or when you’re specifically interested in low-abundance proteins &gt; 0% detectability: Removes only targets with zero detection, useful for maximizing coverage in discovery studies Sample-type specific: Urine (≥ 65%), cell culture (≥ 30%), dried blood spots (≥ 75%) — see Section Sample Detectability for full list # Remove targets below 50% detectability cutoff target_passed_detect &lt;- data$merged$detectability %&gt;% filter(`plasma (n = 176)` &gt; 50) %&gt;% pull(Target) data_filtered &lt;- data$merged$Data_NPQ_long %&gt;% filter(Target %in% target_passed_detect) cat(&quot;Removed&quot;, nrow(data$merged$Data_NPQ) - length(target_passed_detect), &quot;proteins\\n&quot;) 2.5.3 Calculate Targets Detectability by Subgroups In studies with diverse sample types or conditions, consider calculating detectability within relevant subgroups. The easiest way to do this is to use the sample_group_covar parameter of the importNULISAseq function (see Automated Subgroup Detectability Calculation with XML below). However, this assumes that the subgroup variable is already embedded in the xml files. If that is not the case, you may use code such as the following: # Example: Calculate detectability by disease status detectability_by_disease &lt;- data_long %&gt;% filter(SampleType == &quot;Sample&quot;, !is.na(disease_type)) %&gt;% mutate(above_LOD = if_else(Target %in% c(&quot;CRP&quot;, &quot;KNG1&quot;), # High-abundance targets !is.na(NPQ), # For CRP/KNG1: TRUE if NPQ is not NA NPQ &gt; LOD) # For others: TRUE if NPQ &gt; LOD ) %&gt;% group_by(disease_type) %&gt;% mutate(matrix_treatment_count = n_distinct(SampleName)) %&gt;% ungroup() %&gt;% group_by(Target, disease_type, matrix_treatment_count) %&gt;% summarize( detectability = round(sum(above_LOD, na.rm = TRUE) / n() * 100, 1), .groups = &quot;drop&quot; ) %&gt;% mutate( Disease_Type = paste0(disease_type, &quot; (n = &quot;, matrix_treatment_count, &quot;)&quot;) ) %&gt;% # Convert to wide format select(Target, Disease_Type, detectability) %&gt;% pivot_wider( names_from = Disease_Type, values_from = detectability, values_fill = NA ) Interpreting the table: Each column represents a different subgroup with its sample size. Values show the detectability of each disease type subgroup (percentage of samples within that subgroup where each target was detected above its LOD). 2.5.3.0.1 Automated Subgroup Detectability Calculation with XML The importNULISAseq() function can automatically calculate detectability by subgroups during data import using the sample_group_var parameter. This parameter specifies a column name in the samples data matrix that defines subgroups for detectability calculations. Note that this column must already exist in the XML file provided to the function. See ?importNULISAseq for more details. Usage: data_list &lt;- importNULISAseq( sample_group_var = &quot;SAMPLE_MATRIX&quot; # Default value ) The function will: Calculate detectability separately for each subgroup defined in the specified column Calculate overall detectability across all samples This automated approach is particularly useful when metadata information was available in XML file, as it provides subgroup-specific detectability metrics without requiring additional post-processing steps. 2.5.4 Batch Effect Correction If batch effects are present, consider: Intensity normalization Using bridge samples for normalization For additional information on normalization strategies, please refer to Tech Note - NULISATM multiplex normalization &amp; quality control. See Technical Documentation in the Additional Resources chapter. Future releases of NULISAseqR will include expanded functions for implementing advanced normalization steps. If additional guidance is needed, please reach out to Alamar Biosciences support at support@alamarbio.com. 2.6 Best Practices Documentation Save QC reports with date stamps for traceability Document all filtering decisions: Which samples/targets were removed and why Keep notes on QC thresholds: Record any deviations from standard thresholds Track re-runs: If plates are re-processed, document reasons and outcomes Consistency Apply same QC criteria across studies for comparability Pre-define QC thresholds before analysis to avoid bias Document SOP: Standard operating procedure for QC decisions Collaboration Consult wet lab team: Especially for borderline samples or unusual patterns Review control samples: IPC and SC performance can indicate systematic issues Discuss batch effects: Randomize samples to plates to enable detection of batch effects; coordinate on plate layout and run order to minimize batch effects When in Doubt Be conservative: More stringent QC is better than too lenient Use biological replicates: For validation of questionable samples Seek expert input: Consult with Alamar team if needed 2.7 Complete QC Workflow # Load libraries library(NULISAseqR) library(tidyverse) # 1. Generate automated QC report ## Specify output directory out_dir &lt;- tempdir() # Or use your preferred directory ## See Chapter 1 for loading data render_QC_report( output_filename = &quot;Detectability_Study_NULISAseq_QC_report.html&quot;, output_dir = out_dir, study_name = &quot;NULISAseq QC Report - Detectability Study&quot;, assayName = &quot;Inflammation Panel 250&quot;, dataDir = data_dir, xml_files = basename(xml_files), report_type = &quot;webApp&quot; ) ## View the report browseURL(file.path(out_dir, &quot;Detectability_Study_NULISAseq_QC_report.html&quot;)) # 2. Filter low-quality samples sample_qc_warning &lt;- data$merged$qcSample %&gt;% filter(status == &quot;TRUE&quot;) ## examine sample boxplot distributions after normalization to identify samples with issues ## examine further with heatmap and pca in next Chapter # 3. Filter low-detection proteins target_passed_detect &lt;- data$merged$detectability %&gt;% filter(`plasma (n = 176)` &gt; 50) %&gt;% pull(Target) data_filtered &lt;- data$merged$Data_NPQ_long %&gt;% filter(Target %in% target_passed_detect) # 4. Create filtered dataset data_filtered_wide &lt;- data$merged$Data_NPQ[target_passed_detect,] # 5. (Optional) Update metadata to match metadata_qc &lt;- metadata %&gt;% filter(SampleName %in% sample_qc_warning$SampleName) cat(&quot;\\nQC Summary:\\n&quot;) cat(&quot;Original: &quot;, nrow(data$merged$Data_NPQ), &quot;targets,&quot;, ncol(data$merged$Data_NPQ), &quot;samples\\n&quot;) cat(&quot;After QC:&quot;, nrow(data_filtered_wide), &quot;targets,&quot;, ncol(data_filtered_wide), &quot;samples\\n&quot;) Continue to: Chapter 3: Visualization "],["visualization.html", "Chapter 3 Visualization 3.1 Why Visualize? 3.2 Heatmaps 3.3 Principal Component Analysis (PCA) 3.4 Custom Visualizations with ggplot2 3.5 Saving Plots 3.6 Visualization Best Practices 3.7 Complete Visualization Workflow", " Chapter 3 Visualization Visualizing proteomic data helps identify patterns, outliers, and biological signals. This chapter covers the main visualization methods in NULISAseqR. 3.1 Why Visualize? Data visualization helps you: Identify sample clusters and outliers Assess data quality visually Detect batch effects Explore biological patterns Communicate findings effectively 3.2 Heatmaps Heatmaps show protein expression patterns across samples and targets. Hierarchical clustering can help organize heatmaps to indicate which samples and targets are most similar to each other. The generate_heatmap() function: Standardizes data by protein (z-scores): centers and scales each protein’s values Clusters similar samples and proteins together Annotates samples with metadata (disease type, sex, age, etc.) Uses ComplexHeatmap with automatic RColorBrewer color palettes See complete function documentation and additional options, use ?generate_heatmap(). 3.2.1 Basic Heatmap heatmap1 &lt;- generate_heatmap( data = data$merged$Data_NPQ, sampleInfo = metadata, sampleName_var = &quot;SampleName&quot;, sample_subset = sample_list, row_fontsize = 4 ) 3.2.2 Heatmap with Annotations Add sample annotations to highlight key variables: heatmap2 &lt;- generate_heatmap( data = data$merged$Data_NPQ, sampleInfo = metadata, sampleName_var = &quot;SampleName&quot;, sample_subset = sample_list, annotate_sample_by = c(&quot;disease_type&quot;, &quot;sex&quot;, &quot;age&quot;), row_fontsize = 4 ) 3.2.3 Understanding the Heatmap The heatmap shows: Rows: Protein targets Columns: Samples Colors: Expression levels (red = high, blue = low) Dendrograms: Hierarchical clustering Top: Sample relationships Left: Protein relationships Annotation bars: Sample characteristics 3.2.4 Interpreting Clusters Look for: Sample clusters by biology: Samples with similar disease states clustering together Protein clusters: Co-expressed protein groups Outlier samples: Samples far from their expected group Batch effects: Clustering by plate/batch rather than biology 3.3 Principal Component Analysis (PCA) PCA reduces high-dimensional data to its main components of variation. The generate_pca() function: Standardizes data by protein (z-scores): centers and scales each protein’s values Performs PCA using PCAtools package to identify major sources of variation Creates biplot showing sample relationships in PC space Annotates samples with metadata colors and shapes Uses automatic RColorBrewer color palettes or custom colors See complete function documentation and additional options, use ?generate_pca(). 3.3.1 PCA with Multiple Visual Encodings Color by one variable, shape by another: pca2 &lt;- generate_pca( data = data$merged$Data_NPQ, plot_title = &quot;NULISAseq Detectability Study PCA&quot;, sampleInfo = metadata, sampleName_var = &quot;SampleName&quot;, sample_subset = sample_list, annotate_sample_by = &quot;disease_type&quot;, # Color shape_by = &quot;sex&quot; # Shape ) 3.3.2 Understanding PCA Plots Axes PC1 (x-axis): Captures the most variation in the data PC2 (y-axis): Captures the second most variation % variance: Shows how much variation each PC explains Interpretation Tight clusters: Samples with similar expression profiles Separation: Groups with distinct expression patterns Outliers: Samples far from the main cluster Batch effects: If clustering by technical variables (plate, batch), indicates unwanted variation What to Look For Good signs: ✓ Samples cluster by biological group ✓ PC1/PC2 explain substantial variance (&gt;20% combined) ✓ Clear separation between conditions Warning signs: ✗ Clustering by technical variables (batch, plate) ✗ Outliers far from their group ✗ No visible separation despite known biology 3.4 Custom Visualizations with ggplot2 For exploratory analysis beyond heatmaps and PCA, create custom plots with ggplot2. # setting ggplot theme # custom ggplot theme custom_theme &lt;- theme_bw() + theme( panel.background = element_rect(fill=&#39;white&#39;), plot.background = element_rect(fill=&#39;transparent&#39;, color = NA), legend.background = element_rect(fill=&#39;transparent&#39;), legend.key = element_rect(fill = &quot;transparent&quot;, color = NA) ) theme_set(custom_theme) showtext::showtext_auto() ## able to output beta symbol and other special character in pdf 3.4.1 NPQ Distribution - Histogram Check the overall distribution of NPQ values across all samples and proteins: data_long %&gt;% filter(SampleName %in% sample_list) %&gt;% ggplot(aes(x = NPQ)) + geom_histogram(bins = 50, fill = &quot;steelblue&quot;, alpha = 0.7) + labs(title = &quot;Distribution of NPQ across all targets&quot;, x = &quot;NPQ&quot;, y = &quot;Count&quot;) Check the distribution of NPQ values across all samples for each protein: data_long %&gt;% filter(SampleName %in% sample_list) %&gt;% ggplot(aes(x = NPQ)) + geom_histogram(bins = 50, fill = &quot;steelblue&quot;, alpha = 0.7) + facet_wrap(~ Target, scales = &quot;free_y&quot;) + labs(title = &quot;Distribution of NPQ Values by Target&quot;, x = &quot;NPQ&quot;, y = &quot;Count&quot;) + theme( plot.title = element_text(size = 18, face = &quot;bold&quot;), plot.subtitle = element_text(size = 16), axis.title.x = element_text(size = 15), axis.title.y = element_text(size = 15), axis.text.x = element_text(size = 12, angle = 45, hjust = 1), axis.text.y = element_text(size = 12), strip.text = element_text(size = 11) ) 3.4.2 NPQ Distribution by Group - Density Plot Compare NPQ distributions between groups to check for systematic differences: data_long %&gt;% filter(SampleName %in% sample_list) %&gt;% ggplot(aes(x = NPQ, fill = disease_type)) + geom_density(alpha = 0.5) + labs(title = &quot;NPQ Distribution by Disease Type&quot;, x = &quot;NPQ&quot;, y = &quot;Density&quot;, fill = &quot;Disease Type&quot;) 3.4.3 Single Protein Across Groups Examine how a single protein varies across conditions: # Plot a specific protein across groups protein_of_interest &lt;- &quot;IL6&quot; data_long %&gt;% filter(Target == protein_of_interest, SampleName %in% sample_list) %&gt;% ggplot(aes(x = disease_type, y = NPQ, fill = disease_type)) + geom_jitter(width = 0.2, alpha = 0.7, size = 1) + geom_boxplot(alpha = 0.3, outlier.shape = NA) + labs(title = paste(protein_of_interest, &quot;Expression&quot;), x = &quot;Disease Type&quot;, y = &quot;NPQ&quot;) + theme(legend.position = &quot;none&quot;) 3.4.4 Multiple Proteins Across Groups Compare several proteins simultaneously using facets: # Select top 6 proteins by variance protein_variance &lt;- apply(data$merged$Data_NPQ[, sample_list], 1, var, na.rm = TRUE) top_proteins &lt;- names(sort(protein_variance, decreasing = TRUE)[1:6]) # Plot multiple proteins data_long %&gt;% filter(Target %in% top_proteins, SampleName %in% sample_list) %&gt;% ggplot(aes(x = disease_type, y = NPQ, fill = disease_type)) + geom_boxplot(alpha = 0.7, outlier.shape = NA) + geom_jitter(width = 0.2, alpha = 0.3, size = 1) + facet_wrap(~Target, scales = &quot;free_y&quot;, ncol = 3) + labs(title = &quot;Top Variable Proteins Across Disease Groups&quot;, x = &quot;Disease Type&quot;, y = &quot;NPQ&quot;) + theme(legend.position = &quot;none&quot;, axis.text.x = element_text(angle = 45, hjust = 1), strip.text = element_text(size = 16, face = &quot;bold&quot;)) 3.4.5 Protein-Protein Correlation # Select two proteins to compare protein1 &lt;- &quot;IL6&quot; protein2 &lt;- &quot;TNF&quot; plot_data &lt;- data_long %&gt;% filter(Target %in% c(protein1, protein2), SampleName %in% sample_list) %&gt;% select(SampleName, Target, NPQ, disease_type) %&gt;% pivot_wider(names_from = Target, values_from = NPQ) ggplot(plot_data, aes(x = .data[[protein1]], y = .data[[protein2]], color = disease_type)) + geom_point(size = 1, alpha = 0.7) + geom_smooth(method = &quot;lm&quot;, se = FALSE, color = &quot;black&quot;, linetype = 1) + labs(title = paste(protein1, &quot;vs&quot;, protein2), x = paste(protein1, &quot;NPQ&quot;), y = paste(protein2, &quot;NPQ&quot;), color = &quot;Disease Type&quot;) 3.5 Saving Plots Both generate_heatmap() and generate_pca() have built-in options to save plots directly. Save Heatmap # Automatically saves to file generate_heatmap( data = data$merged$Data_NPQ, sampleInfo = metadata, sampleName_var = &quot;SampleName&quot;, sample_subset = sample_list, annotate_sample_by = c(&quot;disease_type&quot;, &quot;sex&quot;, &quot;age&quot;), output_dir = &quot;figures&quot;, # Where to save plot_name = &quot;expression_heatmap.pdf&quot;,# Filename (PDF, PNG, JPG, SVG) row_fontsize = 5, plot_width = 12, # Width in inches plot_height = 10 # Height in inches ) Supported formats: PDF, PNG, JPG, SVG (determined by file extension) Save PCA # Automatically saves to file generate_pca( data = data$merged$Data_NPQ, sampleInfo = metadata, sampleName_var = &quot;SampleName&quot;, sample_subset = sample_list, annotate_sample_by = &quot;disease_type&quot;, output_dir = &quot;figures&quot;, # Where to save plot_name = &quot;pca.png&quot;, # Filename (PDF, PNG, JPG, SVG) plot_title = &quot;NULISAseq Detectability Study PCA&quot;, plot_width = 8, # Width in inches plot_height = 6 # Height in inches ) Supported formats: PDF, PNG, JPG, SVG (determined by file extension) Save ggplot Objects # Create plot p &lt;- data_long %&gt;% filter(SampleName %in% sample_list) %&gt;% ggplot(aes(x = disease_type, y = NPQ, fill = disease_type)) + geom_boxplot() # Save with ggsave ggsave(&quot;figures/boxplot.pdf&quot;, p, width = 8, height = 6) ggsave(&quot;figures/boxplot.png&quot;, p, width = 8, height = 6, dpi = 300) 3.6 Visualization Best Practices Design Principles Choose appropriate color schemes (consider color-blind friendly palettes) Use clear, descriptive titles Label axes properly with units Include legends when needed Choose appropriate plot types for your data Interpretation View plots in context of experimental design Look for biological signals and technical artifacts Compare results across multiple visualization methods Document interesting patterns for follow-up Common Issues ✗ Plotting too many groups (hard to distinguish) – consider multi-panel plots ✗ Poor color choices (e.g., red/green for color-blind viewers) – use color-blind friendly palettes ✗ Overplotting (too many points overlapping) – use transparent colors by setting alpha &lt; 1 ✗ Missing axis labels or legends – be sure to add these! 3.7 Complete Visualization Workflow # Load libraries library(NULISAseqR) library(tidyverse) # Set up output directory out_dir &lt;- &quot;figures&quot; dir.create(out_dir, showWarnings = FALSE) # Filter to samples of interest sample_list &lt;- metadata %&gt;% filter(SampleMatrix == &quot;Plasma&quot;) %&gt;% pull(SampleName) # 1. Generate heatmap with annotations generate_heatmap( data = data$merged$Data_NPQ, output_dir = out_dir, plot_name = &quot;expression_heatmap.pdf&quot;, sampleInfo = metadata, sampleName_var = &quot;SampleName&quot;, sample_subset = sample_list, annotate_sample_by = c(&quot;disease_type&quot;, &quot;sex&quot;, &quot;age&quot;), row_fontsize = 5, plot_width = 12, plot_height = 10 ) # 2. Generate PCA plot generate_pca( data = data$merged$Data_NPQ, output_dir = out_dir, plot_name = &quot;pca_plot.pdf&quot;, plot_title = &quot;NULISAseq Detectability Study PCA&quot;, sampleInfo = metadata, sampleName_var = &quot;SampleName&quot;, sample_subset = sample_list, annotate_sample_by = &quot;disease_type&quot;, shape_by = &quot;sex&quot;, plot_width = 8, plot_height = 6 ) # setting ggplot theme # custom ggplot theme custom_theme &lt;- theme_bw() + theme( panel.background = element_rect(fill=&#39;white&#39;), plot.background = element_rect(fill=&#39;transparent&#39;, color = NA), legend.background = element_rect(fill=&#39;transparent&#39;), legend.key = element_rect(fill = &quot;transparent&quot;, color = NA) ) theme_set(custom_theme) showtext::showtext_auto() ## able to output beta symbol and other special character in pdf # 3. NPQ distribution histogram p_hist &lt;- data_long %&gt;% filter(SampleName %in% sample_list) %&gt;% ggplot(aes(x = NPQ)) + geom_histogram(bins = 50, fill = &quot;steelblue&quot;, alpha = 0.7) + labs(title = &quot;Distribution of NPQ Values&quot;, x = &quot;NPQ&quot;, y = &quot;Count&quot;) ggsave(file.path(out_dir, &quot;npq_histogram.pdf&quot;), p_hist, width = 7, height = 5) # 4. NPQ density by disease type p_density &lt;- data_long %&gt;% filter(SampleName %in% sample_list) %&gt;% ggplot(aes(x = NPQ, fill = disease_type)) + geom_density(alpha = 0.5) + labs(title = &quot;NPQ Distribution by Disease Type&quot;, x = &quot;NPQ&quot;, y = &quot;Density&quot;, fill = &quot;Disease Type&quot;) ggsave(file.path(out_dir, &quot;npq_density.pdf&quot;), p_density, width = 8, height = 5) # 5. Single protein boxplot protein_of_interest &lt;- &quot;IL6&quot; p_single &lt;- data_long %&gt;% filter(Target == protein_of_interest, SampleName %in% sample_list) %&gt;% ggplot(aes(x = disease_type, y = NPQ, fill = disease_type)) + geom_boxplot(alpha = 0.7, outlier.shape = NA) + geom_jitter(width = 0.2, alpha = 0.6, size = 2) + labs(title = paste(protein_of_interest, &quot;Expression Across Groups&quot;), x = &quot;Disease Type&quot;, y = &quot;NPQ&quot;) + theme(legend.position = &quot;none&quot;, axis.text.x = element_text(angle = 45, hjust = 1)) ggsave(file.path(out_dir, paste0(protein_of_interest, &quot;_boxplot.pdf&quot;)), p_single, width = 7, height = 5) # 6. Multiple proteins facet plot protein_variance &lt;- apply(data$merged$Data_NPQ[, sample_list], 1, var, na.rm = TRUE) top_proteins &lt;- names(sort(protein_variance, decreasing = TRUE)[1:6]) p_multi &lt;- data_long %&gt;% filter(Target %in% top_proteins, SampleName %in% sample_list) %&gt;% ggplot(aes(x = disease_type, y = NPQ, fill = disease_type)) + geom_boxplot(alpha = 0.7, outlier.shape = NA) + geom_jitter(width = 0.2, alpha = 0.3, size = 1) + facet_wrap(~Target, scales = &quot;free_y&quot;, ncol = 3) + labs(title = &quot;Top Variable Proteins Across Disease Groups&quot;, x = &quot;Disease Type&quot;, y = &quot;NPQ&quot;) + theme(legend.position = &quot;none&quot;, axis.text.x = element_text(angle = 45, hjust = 1), strip.text = element_text(size = 12, face = &quot;bold&quot;)) ggsave(file.path(out_dir, &quot;top_proteins_facet.pdf&quot;), p_multi, width = 10, height = 8) # 7. Protein correlation plot protein1 &lt;- &quot;IL6&quot; protein2 &lt;- &quot;TNF&quot; plot_data &lt;- data_long %&gt;% filter(Target %in% c(protein1, protein2), SampleName %in% sample_list) %&gt;% select(SampleName, Target, NPQ, disease_type) %&gt;% pivot_wider(names_from = Target, values_from = NPQ) %&gt;% na.omit() p_corr &lt;- ggplot(plot_data, aes(x = .data[[protein1]], y = .data[[protein2]], color = disease_type)) + geom_point(size = 3, alpha = 0.7) + geom_smooth(method = &quot;lm&quot;, se = TRUE, color = &quot;black&quot;, linetype = &quot;dashed&quot;, linewidth = 0.5) + labs(title = paste(protein1, &quot;vs&quot;, protein2), x = paste(protein1, &quot;NPQ&quot;), y = paste(protein2, &quot;NPQ&quot;), color = &quot;Disease Type&quot;) ggsave(file.path(out_dir, &quot;protein_correlation.pdf&quot;), p_corr, width = 7, height = 6) cat(&quot;\\n✓ All visualizations saved to:&quot;, out_dir, &quot;\\n&quot;) cat(&quot;\\nGenerated files:\\n&quot;) cat(&quot; - expression_heatmap.pdf\\n&quot;) cat(&quot; - pca_plot.pdf\\n&quot;) cat(&quot; - npq_histogram.pdf\\n&quot;) cat(&quot; - npq_density.pdf\\n&quot;) cat(&quot; - IL6_boxplot.pdf\\n&quot;) cat(&quot; - top_proteins_facet.pdf\\n&quot;) cat(&quot; - protein_correlation.pdf\\n&quot;) Continue to: Chapter 4: Differential Abundance Analysis "],["differential-abundance-analysis.html", "Chapter 4 Differential Abundance Analysis 4.1 Overview 4.2 Differential Abundance 4.3 Model Results 4.4 Finding Significant Proteins 4.5 Volcano Plots 4.6 Visualization of Significant Targets 4.7 Multiple Disease Groups 4.8 Model Considerations 4.9 Interpreting Results 4.10 Exporting Results 4.11 Complete Differential Abundance Workflow 4.12 Best Practices 4.13 Common Issues", " Chapter 4 Differential Abundance Analysis This chapter focuses on differential abundance analysis for cross-sectional studies, identifying proteins that differ significantly between groups using linear models. For studies with repeated measures for the same individual, see Chapter 5: Longitudinal Analysis. Note on terminology: We use “differential abundance” rather than “differential expression” because NULISAseq measures protein levels directly, not gene expression (mRNA). While “differential expression” is sometimes used colloquially in proteomics, “differential abundance” is the more technically accurate term for protein-level measurements. 4.1 Overview Differential abundance analysis answers the question: “Which protein abundance levels are significantly different between conditions?” The lmNULISAseq() function: Fits a linear model for each protein, with protein abundance (NPQ) as the dependent variable Tests associations between protein levels and your primary variables of interest (e.g., Disease vs. Control) Adjusts for covariates (e.g., age and sex), ensuring that differences are attributed by the effect of interest Corrects for multiple testing (Benjamini-Hochberg (BH) false discovery rate (FDR) or Bonferroni correction) See complete function documentation and additional options, use ?lmNULISAseq(). 4.2 Differential Abundance 4.2.1 Group Comparison The most basic analysis compares two groups: # Check to be sure disease is a factor variable class(metadata$disease_type) #&gt; [1] &quot;factor&quot; # Check to be sure normal group is the reference level levels(metadata$disease_type) #&gt; [1] &quot;normal&quot; &quot;inflam&quot; &quot;cancer&quot; &quot;kidney&quot; &quot;metab&quot; &quot;neuro&quot; # Set levels if needed, first group is reference level levels(metadata$disease_type) &lt;- c(&quot;normal&quot;, &quot;inflam&quot;, &quot;cancer&quot;, &quot;kidney&quot;, &quot;metab&quot;, &quot;neuro&quot;) # Compare disease vs normal (adjusting for sex and age) lmTest &lt;- lmNULISAseq( data = data$merged$Data_NPQ[, sample_list], sampleInfo = metadata %&gt;% filter(SampleName %in% sample_list), sampleName_var = &quot;SampleName&quot;, modelFormula = &quot;disease_type + sex + age&quot; ) 4.2.2 Understanding the Model The formula \"disease_type + sex + age\" means: disease_type: Variable of interest (which groups to compare) sex + age: Covariates to adjust for (remove confounding effects) The model fits: Protein Abundance ~ disease_type + sex + age 4.3 Model Results The function returns a list with: # View structure names(lmTest) #&gt; [1] &quot;modelStats&quot; #&gt; Preview of `lmTest$modelStats` Results Table (rounded to 3 digits): 4.3.1 Key Columns in Results For each comparison (e.g., “disease_typeinflam” vs reference “normal”): disease_typeinflam_coef: Effect size (log fold-change) disease_typeinflam_pval: Raw p-value disease_typeinflam_pval_FDR: FDR-adjusted p-value disease_typeinflam_pval_bonf: Bonferroni-adjusted p-value target: Target name 4.4 Finding Significant Proteins Focusing on the comparison between Inflammatory Disease vs Normal, adjusting for age and sex, we will identify proteins that are significantly differentially abundant with FDR-adjusted p value &lt; 0.05 and a log2 fold-change threshold of at least ± 0.5. 4.4.1 Filter by FDR Threshold # Define significance threshold fdr_threshold &lt;- 0.05 fc_threshold &lt;- 0.5 # Fold-change threshold (log2 scale) # Find significant proteins for Inflammatory Disease vs Normal sig_inflam &lt;- lmTest$modelStats %&gt;% filter( disease_typeinflam_pval_FDR &lt; fdr_threshold, abs(disease_typeinflam_coef) &gt; fc_threshold ) %&gt;% arrange(disease_typeinflam_pval_FDR) #&gt; Significant proteins (Inflammatory Disease vs Normal): 91 4.4.2 Higher vs Lower Abundance We can further identify significant differentially abundant proteins that are either higher or lower in the inflammatory disease group compared to normal group. # Higher in inflammatory disease higher &lt;- sig_inflam %&gt;% filter(disease_typeinflam_coef &gt; 0) %&gt;% arrange(desc(disease_typeinflam_coef)) # Lower in inflammatory disease lower &lt;- sig_inflam %&gt;% filter(disease_typeinflam_coef &lt; 0) %&gt;% arrange(disease_typeinflam_coef) cat(&quot;Higher abundance in inflammatory disease:&quot;, nrow(higher), &quot;\\n&quot;) #&gt; Higher abundance in inflammatory disease: 91 cat(&quot;Lower abundance in inflammatory disease:&quot;, nrow(lower), &quot;\\n&quot;) #&gt; Lower abundance in inflammatory disease: 0 4.5 Volcano Plots Volcano plots visualize differential abundance results effectively. To see complete function documentation and additional options, use ?volcanoPlot(). 4.5.1 Inflammatory Disease vs Normal volcanoPlot( coefs = lmTest$modelStats$disease_typeinflam_coef, p_vals = lmTest$modelStats$disease_typeinflam_pval_FDR, target_labels = lmTest$modelStats$target, title = &quot;Inflammatory Disease vs Normal&quot; ) 4.5.2 Understanding Volcano Plots X-axis: Effect size (log2 fold-change) Y-axis: Statistical significance (-log10 p-value) Significant targets: Points in upper left/right corners Higher-abundance targets: Right side / Red (positive log2 fold-change) Lower-abundance targets: Left side / Blue (negative log2 fold-change) 4.5.3 Cancer vs Normal volcanoPlot( coefs = lmTest$modelStats$disease_typecancer_coef, p_vals = lmTest$modelStats$disease_typecancer_pval_FDR, target_labels = lmTest$modelStats$target, title = &quot;Cancer vs Normal&quot; ) 4.5.4 Saving Volcano Plots # Automatically saves to file volcanoPlot( coefs = lmTest$modelStats$disease_typeinflam_coef, p_vals = lmTest$modelStats$disease_typeinflam_pval_FDR, target_labels = lmTest$modelStats$target, title = &quot;Cancer vs Normal&quot;, plot_name = &quot;figures/FDR_volcano_plot_inflam_vs_normal.pdf&quot;, # Filename (PDF, PNG, JPG, SVG) data_dir = &quot;figures&quot;, # Where to save plot_width = 5, # Width in inches plot_height = 5 # Height in inches ) volcanoPlot( coefs = lmTest$modelStats$disease_typecancer_coef, p_vals = lmTest$modelStats$disease_typecancer_pval_FDR, target_labels = lmTest$modelStats$target, title = &quot;Cancer vs Normal&quot;, plot_name = &quot;figures/FDR_volcano_plot_cancer_vs_normal.pdf&quot;, # Filename (PDF, PNG, JPG, SVG) data_dir = &quot;figures&quot;, # Where to save plot_width = 5, # Width in inches plot_height = 5 # Height in inches ) 4.6 Visualization of Significant Targets Visualize the proteins that show significant difference in abundance between Inflammatory Disease and Normal samples. 4.6.1 Inflammatory Disease vs Normal Heatmap The heatmap shows abundance patterns of higher abundance proteins in Inflammatory Disease versus Normal samples. Samples with similar abundance profiles cluster together with unsupervised clustering. inflam_samples &lt;- metadata %&gt;% filter(disease_type %in% c(&quot;normal&quot;, &quot;inflam&quot;)) %&gt;% pull(SampleName) heatmap_inflam &lt;- generate_heatmap( data = data$merged$Data_NPQ, sampleInfo = metadata, sampleName_var = &quot;SampleName&quot;, sample_subset = inflam_samples, target_subset = higher$target, row_fontsize = 7, col_fontsize = 7, annotate_sample_by = c(&quot;disease_type&quot;, &quot;sex&quot;, &quot;age&quot;) ) PCA PCA shows how well the significant proteins separate Inflammatory Disease from Normal samples. Each point represents one sample. pca_inflam &lt;- generate_pca( data = data$merged$Data_NPQ, plot_title = &quot;PCA: Inflammatory Disease vs Normal \\nSignificant DA Targets&quot;, sampleInfo = metadata, sampleName_var = &quot;SampleName&quot;, sample_subset = inflam_samples, target_subset = higher$target, annotate_sample_by = &quot;disease_type&quot;, shape_by = &quot;sex&quot; ) Boxplot: Higher-abundance Targets Boxplots show the abundance distribution of each higher abundance protein in Inflammatory Disease versus Normal samples. Higher mean NPQ in Inflammatory Disease samples confirms higher abundance. data_long %&gt;% filter(Target %in% higher$target, SampleName %in% inflam_samples) %&gt;% ggplot(aes(x = disease_type, y = NPQ, fill = disease_type)) + geom_boxplot() + facet_wrap(~ Target, scales = &quot;free_y&quot;) + labs(title = &quot;Higher-abundance Significant Targets - Inflammatory Disease vs Normal&quot;, subtitle = &quot;with FDR-adjusted p &lt; 0.05&quot;, x = &quot;Disease Type&quot;, y = &quot;NPQ&quot;, fill = &quot;Disease Type&quot;) + theme( plot.title = element_text(size = 16, face = &quot;bold&quot;), plot.subtitle = element_text(size = 13), axis.title.x = element_text(size = 14), axis.title.y = element_text(size = 14), axis.text.x = element_text(size = 12, angle = 45, hjust = 1), axis.text.y = element_text(size = 12), strip.text = element_text(size = 11), legend.title = element_text(size = 13), legend.text = element_text(size = 12) ) 4.7 Multiple Disease Groups When you have multiple disease categories, you get results for the comparison of each disease group versus normal: # All disease groups vs &quot;normal&quot; (reference level) groups &lt;- c(&quot;inflam&quot;, &quot;cancer&quot;, &quot;kidney&quot;, &quot;metab&quot;, &quot;neuro&quot;) for (group in groups) { coef_col &lt;- paste0(&quot;disease_type&quot;, group, &quot;_coef&quot;) pval_col &lt;- paste0(&quot;disease_type&quot;, group, &quot;_pval_FDR&quot;) if (coef_col %in% colnames(lmTest$modelStats)) { n_sig &lt;- sum(lmTest$modelStats[[pval_col]] &lt; 0.05, na.rm = TRUE) cat(group, &quot;vs normal:&quot;, n_sig, &quot;significant proteins\\n&quot;) } } #&gt; inflam vs normal: 104 significant proteins #&gt; cancer vs normal: 55 significant proteins #&gt; kidney vs normal: 150 significant proteins #&gt; metab vs normal: 1 significant proteins #&gt; neuro vs normal: 0 significant proteins 4.8 Model Considerations 4.8.1 Reference Level The first level of your factor is the reference: # Check reference level levels(metadata$disease_type) # First level is reference # Change reference level if needed metadata$disease_type &lt;- relevel(metadata$disease_type, ref = &quot;cancer&quot;) 4.8.2 Including Covariates Always adjust for relevant covariates: # Include covariates that might confound results lmTest &lt;- lmNULISAseq( data = data$merged$Data_NPQ[, sample_list], sampleInfo = metadata %&gt;% filter(SampleName %in% sample_list), sampleName_var = &quot;SampleName&quot;, modelFormula = &quot;disease_type + sex + age + PlateID&quot; # Added plate ID ) Common covariates: Technical: Batch, plate, run date Biological: Age, sex, BMI Clinical: Disease stage, treatment status 4.8.3 Model Formula Options # Simple comparison (no covariates) modelFormula = &quot;disease_type&quot; # With covariates modelFormula = &quot;disease_type + sex + age&quot; # With interactions modelFormula = &quot;disease_type * sex + age&quot; # Interaction term tests if disease effect differs by sex # Continuous predictor modelFormula = &quot;age + sex&quot; # Tests association with age 4.9 Interpreting Results 4.9.1 Effect Size (Coefficient) Positive coefficient: Protein is higher in test group vs reference Negative coefficient: Protein is lower in test group vs reference Magnitude: Larger value = bigger difference between groups Units are log2(fold change) Convert to fold change by calculating \\(\\text{fold change} = 2^{\\text{coefficient}}\\) 4.9.2 P-values Raw p-value: Probability of the observed or more extreme difference under the null hypothesis FDR-adjusted p-value: Accounts for multiple testing across targets by Benjamini-Hochberg (BH) false discovery rate (FDR) Bonferroni-adjusted p-value: Accounts for multiple testing across by Bonferroni correction 4.9.3 Significance Thresholds Common thresholds: FDR &lt; 0.05: Standard significance level, 5% false discovery rate FDR &lt; 0.01: More stringent, 1% false discovery rate Log2 fold-change &gt; ± 0.5: Biological relevance (often combined with FDR) 4.10 Exporting Results 4.10.1 Save Results Table # Save all results write_csv(lmTest$modelStats, &quot;results/differential_abundance_results.csv&quot;) # Save only significant proteins sig_results &lt;- lmTest$modelStats %&gt;% filter(disease_typeinflam_pval_FDR &lt; 0.05) write_csv(sig_results, &quot;results/significant_proteins_inflam.csv&quot;) 4.10.2 Create Summary Table # Count significant proteins per disease group comparison summary_table &lt;- data.frame( Disease_group = character(), Significant_Proteins = integer(), Higher_abundance = integer(), Lower_abundance = integer() ) for (group in groups) { coef_col &lt;- paste0(&quot;disease_type&quot;, group, &quot;_coef&quot;) pval_col &lt;- paste0(&quot;disease_type&quot;, group, &quot;_pval_FDR&quot;) if (coef_col %in% colnames(lmTest$modelStats)) { sig &lt;- lmTest$modelStats %&gt;% filter(.data[[pval_col]] &lt; 0.05) summary_table &lt;- rbind(summary_table, data.frame( Disease_group = paste(group, &quot;vs normal&quot;), Significant_Proteins = nrow(sig), Higher_abundance = sum(sig[[coef_col]] &gt; 0), Lower_abundance = sum(sig[[coef_col]] &lt; 0) )) } } knitr::kable(summary_table, caption = &quot;Summary of Differential Abundance Results&quot;) Table 4.1: Summary of Differential Abundance Results Disease_group Significant_Proteins Higher_abundance Lower_abundance inflam vs normal 104 104 0 cancer vs normal 55 55 0 kidney vs normal 150 150 0 metab vs normal 1 1 0 neuro vs normal 0 0 0 4.11 Complete Differential Abundance Workflow # Load libraries library(NULISAseqR) library(tidyverse) # Set up output directory out_dir &lt;- &quot;figures&quot; dir.create(out_dir, showWarnings = FALSE) # 1. Run differential abundance lmTest &lt;- lmNULISAseq( data = data$merged$Data_NPQ[, sample_list], sampleInfo = metadata %&gt;% filter(SampleName %in% sample_list), sampleName_var = &quot;SampleName&quot;, modelFormula = &quot;disease_type + sex + age&quot; ) # 2. Filter significant results # Define significance threshold fdr_threshold &lt;- 0.05 fc_threshold &lt;- 0.5 # Fold-change threshold (log2 scale) sig_inflam &lt;- lmTest$modelStats %&gt;% filter( disease_typeinflam_pval_FDR &lt; fdr_threshold, abs(disease_typeinflam_coef) &gt; fc_threshold ) %&gt;% arrange(disease_typeinflam_pval_FDR) sig_cancer &lt;- lmTest$modelStats %&gt;% filter( disease_typecancer_pval_FDR &lt; fdr_threshold, abs(disease_typecancer_coef) &gt; fc_threshold ) %&gt;% arrange(disease_typecancer_pval_FDR) # Higher-abundance in inflammatory disease higher &lt;- sig_inflam %&gt;% filter(disease_typeinflam_coef &gt; 0) %&gt;% arrange(desc(disease_typeinflam_coef)) # Lower-abundance in inflammatory disease lower &lt;- sig_inflam %&gt;% filter(disease_typeinflam_coef &lt; 0) %&gt;% arrange(disease_typeinflam_coef) # 3. Create volcano plots and save as PDF volcanoPlot( coefs = lmTest$modelStats$disease_typeinflam_coef, p_vals = lmTest$modelStats$disease_typeinflam_pval_FDR, target_labels = lmTest$modelStats$target, title = &quot;Cancer vs Normal&quot;, plot_name = &quot;FDR_volcano_plot_inflam_vs_normal.pdf&quot;, output_dir = out_dir, plot_width = 5, plot_height = 5 ) volcanoPlot( coefs = lmTest$modelStats$disease_typecancer_coef, p_vals = lmTest$modelStats$disease_typecancer_pval_FDR, target_labels = lmTest$modelStats$target, title = &quot;Cancer vs Normal&quot;, plot_name = &quot;FDR_volcano_plot_cancer_vs_normal.pdf&quot;, output_dir = out_dir, plot_width = 5, plot_height = 5 ) # 4. Create heatmap and PCA of significant targets and save as PDF ## Get inflammatory disease and normal sample name inflam_samples &lt;- metadata %&gt;% filter(disease_type %in% c(&quot;normal&quot;, &quot;inflam&quot;)) %&gt;% pull(SampleName) ## Generate heatmap with annotations heatmap_inflam &lt;- generate_heatmap( data = data$merged$Data_NPQ, sampleInfo = metadata, sampleName_var = &quot;SampleName&quot;, sample_subset = inflam_samples, target_subset = higher$target, annotate_sample_by = c(&quot;disease_type&quot;, &quot;sex&quot;, &quot;age&quot;), output_dir = &quot;figures&quot;, plot_name = &quot;FDR_heatmap_inflam_vs_normal.pdf&quot;, plot_width = 8, plot_height = 6 ) ## Generate PCA plot pca_inflam &lt;- generate_pca( data = data$merged$Data_NPQ, plot_title = &quot;PCA: Inflammatory Disease vs Normal \\nSignificant DA Targets&quot;, sampleInfo = metadata, sampleName_var = &quot;SampleName&quot;, sample_subset = inflam_samples, target_subset = higher$target, annotate_sample_by = &quot;disease_type&quot;, shape_by = &quot;sex&quot;, output_dir = &quot;figures&quot;, plot_name = &quot;FDR_pca_plot_inflam_vs_normal.pdf&quot;, plot_width = 5, plot_height = 4 ) # 5. Create boxplot of significant targets and save as PDF boxplot &lt;- data_long %&gt;% filter(Target %in% higher$target, SampleName %in% inflam_samples) %&gt;% ggplot(aes(x = disease_type, y = NPQ, fill = disease_type)) + geom_boxplot() + facet_wrap(~ Target, scales = &quot;free_y&quot;) + labs(title = &quot;Higher-abundance Significant Differential Abundance Targets - Inflammatory Disease vs Normal&quot;, subtitle = &quot;with FDR-adjusted p &lt; 0.05&quot;, x = &quot;Disease Type&quot;, y = &quot;NPQ&quot;, legend = &quot;Disease Type&quot;) + theme(strip.text = element_text(size = 8.5), axis.text.x = element_text(angle = 45, hjust = 1)) print(boxplot) ggsave(filename = &quot;FDR_boxplot_inflam_vs_normal.pdf&quot;, plot = boxplot, path = &quot;figures&quot;, width = 12, height = 9) # 6. Export results dir.create(&quot;results&quot;, showWarnings = FALSE) write_csv(lmTest$modelStats, &quot;results/all_DA_results.csv&quot;) write_csv(sig_inflam, &quot;results/sig_inflam_proteins.csv&quot;) write_csv(sig_cancer, &quot;results/sig_cancer_proteins.csv&quot;) # 7. Print summary cat(&quot;\\nDifferential Abundance Summary:\\n&quot;) cat(&quot;Inflammatory Disease vs Normal:&quot;, nrow(sig_inflam), &quot;significant proteins\\n&quot;) cat(&quot;Cancer vs Normal:&quot;, nrow(sig_cancer), &quot;significant proteins\\n&quot;) 4.12 Best Practices Model Design Include relevant covariates to adjust for confounding and account for known sources of variation (e.g., age, sex) Use appropriate reference levels Consider batch effects Interpretation Using FDR-adjusted p-values for significance, accounting for multiple testing Consider both statistical significance AND effect size Confirm key findings using visualization Reporting Document model formula used Report both FDR thresholds and any fold-change cutoffs applied Include sample sizes per group 4.13 Common Issues Problem: No significant proteins Check if groups are truly different (check sample label and metadata accuracy, explore heatmaps and PCA) Sample size might be too small Effect sizes might be small Try less stringent FDR threshold or use unadjusted p-values (exploratory only) Problem: Everything is significant Check for batch effects Verify model is appropriate Consider more stringent thresholds Problem: Results don’t match biology Check factor levels and reference group Verify metadata is correct Consider additional covariates Continue to: Chapter 5: Longitudinal Analysis "],["longitudinal-analysis.html", "Chapter 5 Longitudinal Analysis 5.1 Overview 5.2 Linear Mixed-Effects Model 5.3 Volcano Plots 5.4 Trajectory Visualization 5.5 Model Considerations 5.6 Exporting Results 5.7 Complete Longitudinal Analysis Workflow 5.8 Best Practices 5.9 Common Issues", " Chapter 5 Longitudinal Analysis This chapter focuses on longitudinal studies, identifying proteins whose levels or changes over time differ significantly between groups using linear mixed-effects models. 5.1 Overview Longitudinal analysis answers the question: “Which proteins change over time, and do these changes differ by condition or group?” Because longitudinal data involves repeated measurements on the same subjects, the observations are not independent. Linear mixed-effects models (LME) account for this dependency by including random effects (e.g., subject-specific intercepts or slopes), making them the appropriate tool for this analysis. The lmerNULISAseq() function extends the linear modeling approach to handle repeated measures: Fits a linear mixed-effects model for each protein, with NPQ as the dependent variable, incorporating both fixed and random effects Tests associations with your variables of interest, such as the time-by-group interaction, to identify proteins with different temporal patterns across groups Adjusts for covariates, ensuring that differences are attributed to the primary variables Accounts for the correlation structure within subjects due to repeated measurements Corrects for multiple testing (e.g., Benjamini-Hochberg false discovery rate (FDR), Bonferroni correction) To see complete function documentation and additional options, use ?lmerNULISAseq(). This chapter uses a COVID-19 dataset with Alamar NULISAseq Inflammation Panel: COVID patients: COVID-19 patients serum samples collected at each time interval, where time is days relative to the time of peak SARS-CoV-2 nucleocapsid protein abundance (N-protein) Control subjects: Healthy controls serum samples (single time point) Time points: T-7 to -2, T0 (peak), T2 to 7, T8 to 20 days. Time 0 (T0) represents time of peak abundance of N-protein. 5.1.1 Load and Prepare Data Read in the COVID longitudinal dataset in CSV long format: # Load COVID longitudinal data data_covid &lt;- read_csv(file.path(data_dir, &quot;Alamar_NULISAseq_COVID_NPQ_data.csv&quot;)) #&gt; Preview of COVID dataset (first 20 rows): 5.1.2 Create Metadata Create a metadata data frame with clinical and demographic information: # Create metadata with time categories metadata_covid &lt;- data_covid[, 1:9] %&gt;% select(-Panel) %&gt;% rename( SampleMatrix = SampleType ) %&gt;% distinct() %&gt;% mutate( covid_status = relevel(factor(covid_status), ref = &quot;control&quot;), SampleMatrix = str_to_title(SampleMatrix), sex = ifelse(sexF == 1, &quot;Female&quot;, &quot;Male&quot;), patientID = factor(patientID, levels = as.character(sort(as.numeric(unique(patientID))))), Time = case_when( covid_status == &quot;control&quot; ~ &quot;control&quot;, days_from_peak_N_protein == 0 ~ &quot;T0&quot;, days_from_peak_N_protein &lt; -1 ~ &quot;T-7 to -2&quot;, days_from_peak_N_protein &gt; 7 ~ &quot;T8 to 20&quot;, days_from_peak_N_protein &gt;= 1 &amp; days_from_peak_N_protein &lt;= 7 ~ &quot;T2 to 7&quot; ), Time = factor(Time, levels = c(&quot;control&quot;, &quot;T-7 to -2&quot;, &quot;T0&quot; , &quot;T2 to 7&quot;, &quot;T8 to 20&quot;)), Group = case_when( Time == &quot;T0&quot;~ &quot;mild COVID T0&quot;, Time == &quot;T-7 to -2&quot;~ &quot;mild COVID T-7 to -2&quot;, Time == &quot;T2 to 7&quot;~ &quot;mild COVID T2 to 7&quot;, Time == &quot;T8 to 20&quot;~ &quot;mild COVID T8 to 20&quot;, TRUE ~ &quot;control&quot; ), Group = factor(Group, levels = c(&quot;control&quot;, &quot;mild COVID T-7 to -2&quot;, &quot;mild COVID T0&quot; , &quot;mild COVID T2 to 7&quot;, &quot;mild COVID T8 to 20&quot;)),) %&gt;% select(-sexF) #&gt; Preview of COVID metadata table: After updating and cleaning metadata, rejoin with the main data: # Add metadata to data data_covid &lt;- data_covid %&gt;% mutate(patientID = as.factor(patientID)) %&gt;% left_join(metadata_covid) 5.1.3 Convert to Wide Format Convert NPQ data to wide format for analysis: # Convert to wide format data_covid_wide &lt;- data_covid %&gt;% select(SampleName, Target, NPQ) %&gt;% pivot_wider(names_from = SampleName, values_from = NPQ) %&gt;% column_to_rownames(var = &quot;Target&quot;) %&gt;% as.matrix() #&gt; Preview of COVID dataset in wide format (rows: Targets, columns: Samples): 5.1.4 Descriptive Statistics Generate a descriptive statistics table: # Create descriptive table library(table1) table1(~ SampleMatrix + age + sex + Time | covid_status, data = metadata_covid) control(N=16) mild_COVID(N=46) Overall(N=62) SampleMatrix Serum 16 (100%) 46 (100%) 62 (100%) age Mean (SD) 57.3 (13.6) 47.1 (17.9) 49.7 (17.4) Median [Min, Max] 60.0 [27.0, 79.0] 42.0 [24.0, 77.0] 54.0 [24.0, 79.0] sex Female 7 (43.8%) 30 (65.2%) 37 (59.7%) Male 9 (56.3%) 16 (34.8%) 25 (40.3%) Time control 16 (100%) 0 (0%) 16 (25.8%) T-7 to -2 0 (0%) 11 (23.9%) 11 (17.7%) T0 0 (0%) 9 (19.6%) 9 (14.5%) T2 to 7 0 (0%) 13 (28.3%) 13 (21.0%) T8 to 20 0 (0%) 13 (28.3%) 13 (21.0%) 5.1.5 Exploratory Visualization Before statistical analysis, visualize the data to understand overall patterns. 5.1.5.1 Heatmap # Heatmap with time point annotation h_covid &lt;- generate_heatmap( data = data_covid_wide, sampleInfo = metadata_covid, sampleName_var = &quot;SampleName&quot;, annotate_sample_by = c(&quot;Group&quot;, &quot;sex&quot;, &quot;age&quot;), column_split_by = &quot;Group&quot;, row_fontsize = 5, col_fontsize = 6 ) 5.1.5.2 PCA # PCA colored by time point p_covid &lt;- generate_pca( data = data_covid_wide, sampleInfo = metadata_covid, sampleName_var = &quot;SampleName&quot;, annotate_sample_by = &quot;Group&quot;, shape_by = &quot;sex&quot; ) 5.2 Linear Mixed-Effects Model 5.2.1 Group Effect Analysis Test whether protein levels differ across time groups (each COVID timepoint vs controls), adjusting for covariates and accounting for repeated measurements within patients. lmerTest &lt;- lmerNULISAseq( data = data_covid_wide, sampleInfo = metadata_covid, sampleName_var = &quot;SampleName&quot;, modelFormula_fixed = &quot;Group + sex + age&quot;, modelFormula_random = &quot;(1|patientID)&quot;, reduced_modelFormula_fixed = &quot;sex + age&quot; ) 5.2.2 Understanding the Model The model components: Fixed effects: Group + sex + age Group: Primary variable of interest (controls and mild COVID time groups) sex + age: Covariates to adjust for Random effects: (1|patientID) Accounts for patient-specific baseline levels Models correlation within subjects Reduced model: sex + age Nested model used for likelihood ratio test (LRT) to assess overall Group effect The model fits: NPQ ~ Group + sex + age + (1|patientID) The likelihood ratio test compares the full model against the reduced model to test whether the overall Group effect is significant. 5.2.3 Model Results The function returns a list with two main components: # View structure names(lmerTest) #&gt; [1] &quot;modelStats&quot; &quot;LRTstats&quot; 5.2.4 Likelihood Ratio Test (LRT) Statistics The LRTstats table contains results from the likelihood ratio test: #&gt; Preview of `lmerTest$LRTstats` Results Table (rounded to 3 digits): Key columns: target: Target name Chisq_stat: Chi-squared statistic from LRT Chisq_test_pval: Unadjusted p-value Chisq_test_pval_FDR: FDR-adjusted p-value Chisq_test_pval_bonf: Bonferroni-adjusted p-value Interpretation: Chi-squared statistic: Measures overall Group effect Larger values: Stronger evidence for group differences FDR &lt; 0.05: Significant Group effect (at least one mild COVID timepoint group differs from control) 5.2.5 Model Coefficients The modelStats table contains coefficient estimates for each Group comparison: #&gt; #&gt; Preview of `lmerTest$modelStats` Results Table (rounded to 3 digits): For each comparison (e.g., “Groupmild.COVID.T0” vs reference “control”): target: Target name Groupmild.COVID.T0_coef: Effect size (NPQ difference for COVID group at T0 versus control) Groupmild.COVID.T0_pval: Unadjusted p-value Groupmild.COVID.T0_pval_FDR: FDR-adjusted p-value Groupmild.COVID.T0_pval_bonf: Bonferroni-adjusted p-value 5.2.6 Overall Group Effect Identify proteins with significant Group effect using LRT: # Define significance threshold fdr_threshold &lt;- 0.05 # Find proteins with significant Group effect sig_targets_covid &lt;- lmerTest$LRTstats %&gt;% filter(Chisq_test_pval_FDR &lt; fdr_threshold) %&gt;% arrange(Chisq_test_pval_FDR) %&gt;% pull(target) cat(&quot;Significant proteins (Group effect):&quot;, length(sig_targets_covid), &quot;\\n&quot;) #&gt; Significant proteins (Group effect): 89 5.2.7 Specific Time Comparisons Examine which time points drive the Group effect: # Significant at each timepoint vs control timepoints &lt;- c(&quot;T.7.to..2&quot;, &quot;T0&quot;, &quot;T2.to.7&quot;, &quot;T8.to.20&quot;) for (tp in timepoints) { coef_col &lt;- paste0(&quot;Groupmild.COVID.&quot;, tp, &quot;_coef&quot;) pval_col &lt;- paste0(&quot;Groupmild.COVID.&quot;, tp, &quot;_pval_FDR&quot;) if (coef_col %in% colnames(lmerTest$modelStats)) { n_sig &lt;- sum(lmerTest$modelStats[[pval_col]] &lt; fdr_threshold, na.rm = TRUE) cat(&quot;mild COVID&quot;, gsub(&quot;\\\\.&quot;, &quot; &quot;, tp), &quot;vs control:&quot;, n_sig, &quot;significant proteins\\n&quot;) } } #&gt; mild COVID T 7 to 2 vs control: 49 significant proteins #&gt; mild COVID T0 vs control: 64 significant proteins #&gt; mild COVID T2 to 7 vs control: 47 significant proteins #&gt; mild COVID T8 to 20 vs control: 27 significant proteins 5.3 Volcano Plots Visualize the statistical results for the overall Group effect and specific time comparisons. 5.3.1 Overall Group Effect (LRT) volcanoPlot( coefs = lmerTest$LRTstats$Chisq_stat, p_vals = lmerTest$LRTstats$Chisq_test_pval_FDR, target_labels = lmerTest$LRTstats$target, title = &quot;Group Effect (Likelihood Ratio Test)&quot;, xlabel = &quot;Chi-Squared Statistic&quot;, ylabel = &quot;-log10(FDR adjusted p value)&quot; ) 5.3.2 Group-Specific Comparisons Create volcano plots for each COVID timepoint vs control: # T-7 to -2 vs Control volcanoPlot( coefs = lmerTest$modelStats$Groupmild.COVID.T.7.to..2_coef, p_vals = lmerTest$modelStats$Groupmild.COVID.T.7.to..2_pval_FDR, target_labels = lmerTest$modelStats$target, title = &quot;COVID Patients, Time T-7 to -2 vs Controls&quot; ) # T0 vs Control volcanoPlot( coefs = lmerTest$modelStats$Groupmild.COVID.T0_coef, p_vals = lmerTest$modelStats$Groupmild.COVID.T0_pval_FDR, target_labels = lmerTest$modelStats$target, title = &quot;COVID Patients, Time T0 vs Controls&quot; ) # T2 to 7 vs Control volcanoPlot( coefs = lmerTest$modelStats$Groupmild.COVID.T2.to.7_coef, p_vals = lmerTest$modelStats$Groupmild.COVID.T2.to.7_pval_FDR, target_labels = lmerTest$modelStats$target, title = &quot;COVID Patients, Time T2 to 7 vs Controls&quot; ) # T8 to 20 vs Control volcanoPlot( coefs = lmerTest$modelStats$Groupmild.COVID.T8.to.20_coef, p_vals = lmerTest$modelStats$Groupmild.COVID.T8.to.20_pval_FDR, target_labels = lmerTest$modelStats$target, title = &quot;COVID Patients, Time T8 to 20 vs Controls&quot; ) 5.4 Trajectory Visualization Visualize temporal patterns of significant proteins to understand how they change over time. 5.4.1 Spaghetti Plot: Discrete Time Groups Show individual patient trajectories and group means across time groups: # Prepare COVID patient data covid_data &lt;- data_covid %&gt;% filter(covid_status != &quot;control&quot;, Target %in% sig_targets_covid) # Prepare control data control_data &lt;- data_covid %&gt;% filter(covid_status == &quot;control&quot;, Target %in% sig_targets_covid) # Combine the data combined_data &lt;- bind_rows(covid_data, control_data) # Calculate mean NPQ for COVID patients by Group mean_trends &lt;- combined_data %&gt;% filter(Group != &quot;control&quot;) %&gt;% group_by(Target, Group) %&gt;% summarize(mean_NPQ = mean(NPQ, na.rm = TRUE), .groups = &quot;drop&quot;) # Calculate mean for controls control_mean &lt;- combined_data %&gt;% filter(Group == &quot;control&quot;) %&gt;% group_by(Target, Group) %&gt;% summarize(mean_NPQ = mean(NPQ, na.rm = TRUE), .groups = &quot;drop&quot;) # Create the plot ggplot() + # Control points geom_point(data = combined_data %&gt;% filter(Group == &quot;control&quot;), aes(x = Group, y = NPQ, shape = &quot;Control&quot;, fill = &quot;Control&quot;), color = &quot;blue&quot;, alpha = 0.5, size = 1) + # Individual patient trajectories (COVID only) geom_line(data = combined_data %&gt;% filter(Group != &quot;control&quot;), aes(x = Group, y = NPQ, group = patientID, color = patientID), alpha = 0.5, linewidth = 0.5) + geom_point(data = combined_data %&gt;% filter(Group != &quot;control&quot;), aes(x = Group, y = NPQ, color = patientID), alpha = 0.7, size = 1) + # Mean trend line (COVID patients only) geom_line(data = mean_trends, aes(x = Group, y = mean_NPQ, group = 1), color = &quot;black&quot;, linewidth = 1.2) + geom_point(data = mean_trends, aes(x = Group, y = mean_NPQ, shape = &quot;Mean (COVID)&quot;, fill = &quot;Mean (COVID)&quot;), color = &quot;black&quot;, size = 2.2) + # Control mean geom_point(data = control_mean, aes(x = Group, y = mean_NPQ, shape = &quot;Mean (Control)&quot;, fill = &quot;Mean (Control)&quot;), color = &quot;blue&quot;, size = 2.2) + # Manual scales for legend scale_shape_manual( name = &quot;Group&quot;, values = c(&quot;Control&quot; = 17, &quot;Mean (COVID)&quot; = 18, &quot;Mean (Control)&quot; = 18), breaks = c(&quot;Control&quot;, &quot;Mean (Control)&quot;, &quot;Mean (COVID)&quot;) ) + scale_fill_manual( name = &quot;Group&quot;, values = c(&quot;Control&quot; = &quot;blue&quot;, &quot;Mean (COVID)&quot; = &quot;black&quot;, &quot;Mean (Control)&quot; = &quot;blue&quot;), breaks = c(&quot;Control&quot;, &quot;Mean (Control)&quot;, &quot;Mean (COVID)&quot;) ) + facet_wrap(~Target, scales = &quot;free_y&quot;) + labs( title = &quot;Significant Targets Over Time&quot;, subtitle = &quot;Targets with FDR-adjusted p &lt; 0.05 for Group Effect from LRT&quot;, x = &quot;Group&quot;, y = &quot;NPQ&quot;, color = &quot;Patient ID&quot; ) + theme_minimal() + theme( axis.text.x = element_text(angle = 45, hjust = 1), legend.position = &quot;right&quot;, plot.title = element_text(size = 14, face = &quot;bold&quot;), plot.subtitle = element_text(size = 11) ) + guides( fill = guide_legend(order = 1, override.aes = list(alpha = 1)), shape = guide_legend(order = 1), color = guide_legend(order = 2, title = &quot;Patient ID&quot;) ) Interpretation: Individual lines: Each patient’s trajectory over time Black line: Mean trajectory for COVID patients Blue points: Control samples (single timepoint) Facets: Each panel shows a different significant protein 5.4.2 Spaghetti Plot: Continuous Time Show trajectories using continuous time (days from peak N-protein): # Prepare COVID patient data with continuous time covid_data_cont &lt;- data_covid %&gt;% filter(covid_status != &quot;control&quot;, Target %in% sig_targets_covid) # Prepare control data - assign specific days_from_peak value control_data_cont &lt;- data_covid %&gt;% filter(covid_status == &quot;control&quot;, Target %in% sig_targets_covid) %&gt;% mutate(days_from_peak_N_protein = -14) # Combine the data combined_data_cont &lt;- bind_rows(covid_data_cont, control_data_cont) %&gt;% mutate(is_control = ifelse(covid_status == &quot;control&quot;, TRUE, FALSE)) # Calculate mean for controls control_mean_cont &lt;- combined_data_cont %&gt;% filter(is_control) %&gt;% group_by(Target, days_from_peak_N_protein) %&gt;% summarize(mean_NPQ = mean(NPQ, na.rm = TRUE), .groups = &quot;drop&quot;) # Create breaks and labels for x-axis x_breaks &lt;- c(-14, 0, 10, 20) x_labels &lt;- c(&quot;Control&quot;, &quot;0&quot;, &quot;10&quot;, &quot;20&quot;) # Create the plot ggplot() + # Control points geom_point(data = combined_data_cont %&gt;% filter(is_control), aes(x = days_from_peak_N_protein, y = NPQ, shape = &quot;Control&quot;, fill = &quot;Control&quot;), color = &quot;blue&quot;, alpha = 0.5, size = 1) + # Individual patient trajectories (COVID only) geom_line(data = combined_data_cont %&gt;% filter(!is_control), aes(x = days_from_peak_N_protein, y = NPQ, group = patientID, color = patientID), alpha = 0.5, linewidth = 0.5) + geom_point(data = combined_data_cont %&gt;% filter(!is_control), aes(x = days_from_peak_N_protein, y = NPQ, color = patientID), alpha = 0.7, size = 1) + # Smooth trend line (COVID patients only) geom_smooth(data = combined_data_cont %&gt;% filter(!is_control), aes(x = days_from_peak_N_protein, y = NPQ, linetype = &quot;Mean (COVID)&quot;), color = &quot;black&quot;, linewidth = 1, se = TRUE, method = &quot;loess&quot;) + # Control mean geom_point(data = control_mean_cont, aes(x = days_from_peak_N_protein, y = mean_NPQ, shape = &quot;Mean (Control)&quot;, fill = &quot;Mean (Control)&quot;), color = &quot;blue&quot;, size = 1.8) + # Manual scales for legend scale_shape_manual( name = &quot;Group&quot;, values = c(&quot;Control&quot; = 17, &quot;Mean (Control)&quot; = 18), breaks = c(&quot;Control&quot;, &quot;Mean (Control)&quot;) ) + scale_fill_manual( name = &quot;Group&quot;, values = c(&quot;Control&quot; = &quot;blue&quot;, &quot;Mean (Control)&quot; = &quot;blue&quot;), breaks = c(&quot;Control&quot;, &quot;Mean (Control)&quot;) ) + scale_linetype_manual( name = &quot;Group&quot;, values = c(&quot;Mean (COVID)&quot; = &quot;solid&quot;), breaks = c(&quot;Mean (COVID)&quot;) ) + # Custom x-axis scale_x_continuous( breaks = x_breaks, labels = x_labels ) + # Add vertical line at day 0 (peak N protein) geom_vline(xintercept = 0, linetype = &quot;dashed&quot;, color = &quot;gray50&quot;, alpha = 0.5) + facet_wrap(~Target, scales = &quot;free_y&quot;) + labs( title = &quot;COVID Patients: Significant Targets Over Time&quot;, subtitle = &quot;Targets with FDR-adjusted p &lt; 0.05 for Group Effect from LRT&quot;, x = &quot;Days from Peak N Protein&quot;, y = &quot;NPQ&quot;, color = &quot;Patient ID&quot; ) + theme_minimal() + theme( axis.text.x = element_text(angle = 45, hjust = 1), legend.position = &quot;right&quot;, plot.title = element_text(size = 14, face = &quot;bold&quot;), plot.subtitle = element_text(size = 11) ) + guides( fill = guide_legend(order = 1, override.aes = list(alpha = 1)), shape = guide_legend(order = 1), linetype = guide_legend(order = 1), color = guide_legend(order = 2, title = &quot;Patient ID&quot;) ) Interpretation: X-axis: Continuous time (days from peak N-protein abundance) Shows more granular temporal patterns than discrete groups 5.5 Model Considerations 5.5.1 Random Effects Structure The random effects structure determines how you model within-subject correlation: # Random intercept only (baseline varies by subject) modelFormula_random = &quot;(1|patientID)&quot; # Random slope (time effect varies by subject) modelFormula_random = &quot;(1 + Time|patientID)&quot; # Nested random effects modelFormula_random = &quot;(1|clinic/patientID)&quot; Guidelines: Use (1|patientID) when subjects have different baselines but similar trajectories Use (1 + Time|patientID) when you want to model linear subject-specific slopes (requires sufficient data per subject, assumes a linear trend over time) More complex random effects require larger sample sizes, model may have convergence issues In most cases, subject-specific random intercepts are sufficient to capture within-subject correlation For complex time patterns (quadratic, splines), we recommend random intercepts only to ensure model stability and interpretability 5.5.2 Fixed Effects Design # Group comparison (as used in example) modelFormula_fixed = &quot;Group + sex + age&quot; # Continuous time with interaction modelFormula_fixed = &quot;Time * covid_status + sex + age&quot; # Polynomial continuous time trend with interaction modelFormula_fixed = &quot;poly(Time, 2) * covid_status + sex + age&quot; For more information on linear mixed-effects models: R documentation: ?lme4::lmer and ?lmerTest::lmer 5.5.3 Likelihood Ratio Test The LRT compares nested models: # Full model modelFormula_fixed = &quot;Group + sex + age&quot; # Reduced model (removes Group) reduced_modelFormula_fixed = &quot;sex + age&quot; # LRT tests: Does including Group improve model fit? 5.6 Exporting Results 5.6.1 Save Results Tables # Save LRT statistics write_csv(lmerTest$LRTstats, &quot;results/lmer_lrt_statistics.csv&quot;) # Save model coefficients write_csv(lmerTest$modelStats, &quot;results/lmer_model_coefficients.csv&quot;) # Save list of significant targets sig_targets_df &lt;- data.frame( target = sig_targets_covid, significant_group_effect = TRUE ) write_csv(sig_targets_df, &quot;results/significant_targets_covid.csv&quot;) 5.6.2 Save Plots # Save volcano plot for LRT volcanoPlot( coefs = lmerTest$LRTstats$Chisq_stat, p_vals = lmerTest$LRTstats$Chisq_test_pval_FDR, target_labels = lmerTest$LRTstats$target, title = &quot;Group Effect (LRT)&quot;, xlabel = &quot;Chi-Squared Statistic&quot;, plot_name = &quot;volcano_plot_lrt_group_effect.pdf&quot;, data_dir = &quot;figures&quot;, plot_width = 6, plot_height = 5 ) # Save time-specific volcano plots timepoints_save &lt;- list( list(coef = &quot;Groupmild.COVID.T0_coef&quot;, pval = &quot;Groupmild.COVID.T0_pval_FDR&quot;, title = &quot;T0 vs Control&quot;, file = &quot;volcano_T0_vs_control.pdf&quot;), list(coef = &quot;Groupmild.COVID.T.7.to..2_coef&quot;, pval = &quot;Groupmild.COVID.T.7.to..2_pval_FDR&quot;, title = &quot;T-7 to -2 vs Control&quot;, file = &quot;volcano_T-7to-2_vs_control.pdf&quot;), list(coef = &quot;Groupmild.COVID.T2.to.7_coef&quot;, pval = &quot;Groupmild.COVID.T2.to.7_pval_FDR&quot;, title = &quot;T2 to 7 vs Control&quot;, file = &quot;volcano_T2to7_vs_control.pdf&quot;), list(coef = &quot;Groupmild.COVID.T8.to.20_coef&quot;, pval = &quot;Groupmild.COVID.T8.to.20_pval_FDR&quot;, title = &quot;T8 to 20 vs Control&quot;, file = &quot;volcano_T8to20_vs_control.pdf&quot;) ) for (tp in timepoints_save) { volcanoPlot( coefs = lmerTest$modelStats[[tp$coef]], p_vals = lmerTest$modelStats[[tp$pval]], target_labels = lmerTest$modelStats$target, title = tp$title, plot_name = tp$file, data_dir = &quot;figures&quot;, plot_width = 5, plot_height = 4 ) } # Save spaghetti plot ggsave( filename = &quot;spaghetti_plot_significant_targets.pdf&quot;, plot = last_plot(), path = &quot;figures&quot;, width = 12, height = 10, device = &quot;pdf&quot; ) 5.7 Complete Longitudinal Analysis Workflow # Load libraries library(NULISAseqR) library(tidyverse) library(table1) # 1. Load and prepare data data_covid &lt;- read_csv(file.path(data_dir, &quot;Alamar_NULISAseq_COVID_NPQ_data.csv&quot;)) metadata_covid &lt;- data_covid[, 1:9] %&gt;% select(-Panel) %&gt;% rename(SampleMatrix = SampleType) %&gt;% distinct() %&gt;% mutate( covid_status = relevel(factor(covid_status), ref = &quot;control&quot;), SampleMatrix = str_to_title(SampleMatrix), sex = ifelse(sexF == 1, &quot;Female&quot;, &quot;Male&quot;), patientID = factor(patientID, levels = as.character(sort(as.numeric(unique(patientID))))), Time = case_when( covid_status == &quot;control&quot; ~ &quot;control&quot;, days_from_peak_N_protein == 0 ~ &quot;T0&quot;, days_from_peak_N_protein &lt; -1 ~ &quot;T-7 to -2&quot;, days_from_peak_N_protein &gt; 7 ~ &quot;T8 to 20&quot;, days_from_peak_N_protein &gt;= 1 &amp; days_from_peak_N_protein &lt;= 7 ~ &quot;T2 to 7&quot; ), Time = factor(Time, levels = c(&quot;control&quot;, &quot;T-7 to -2&quot;, &quot;T0&quot;, &quot;T2 to 7&quot;, &quot;T8 to 20&quot;)), Group = case_when( Time == &quot;T0&quot; ~ &quot;mild COVID T0&quot;, Time == &quot;T-7 to -2&quot; ~ &quot;mild COVID T-7 to -2&quot;, Time == &quot;T2 to 7&quot; ~ &quot;mild COVID T2 to 7&quot;, Time == &quot;T8 to 20&quot; ~ &quot;mild COVID T8 to 20&quot;, TRUE ~ &quot;control&quot; ), Group = factor(Group, levels = c(&quot;control&quot;, &quot;mild COVID T-7 to -2&quot;, &quot;mild COVID T0&quot;, &quot;mild COVID T2 to 7&quot;, &quot;mild COVID T8 to 20&quot;)) ) %&gt;% select(-sexF) data_covid &lt;- data_covid %&gt;% mutate(patientID = as.factor(patientID)) %&gt;% left_join(metadata_covid) data_covid_wide &lt;- data_covid %&gt;% select(SampleName, Target, NPQ) %&gt;% pivot_wider(names_from = SampleName, values_from = NPQ) %&gt;% column_to_rownames(var = &quot;Target&quot;) %&gt;% as.matrix() # 2. Create descriptive table table1(~ SampleMatrix + age + sex + Time | covid_status, data = metadata_covid) # 3. Generate exploratory visualizations # Set up output directory out_dir &lt;- &quot;figures&quot; dir.create(out_dir, showWarnings = FALSE) h_covid &lt;- generate_heatmap( data = data_covid_wide, sampleInfo = metadata_covid, sampleName_var = &quot;SampleName&quot;, annotate_sample_by = c(&quot;Group&quot;, &quot;sex&quot;, &quot;age&quot;), column_split_by = &quot;Group&quot;, output_dir = out_dir, plot_name = &quot;heatmap_covid_all_samples.pdf&quot;, plot_width = 10, plot_height = 8 ) p_covid &lt;- generate_pca( data = data_covid_wide, sampleInfo = metadata_covid, sampleName_var = &quot;SampleName&quot;, annotate_sample_by = &quot;Group&quot;, shape_by = &quot;sex&quot;, output_dir = out_dir, plot_name = &quot;pca_covid_all_samples.pdf&quot;, plot_width = 7, plot_height = 6 ) # 4. Fit linear mixed-effects model lmerTest &lt;- lmerNULISAseq( data = data_covid_wide, sampleInfo = metadata_covid, sampleName_var = &quot;SampleName&quot;, modelFormula_fixed = &quot;Group + sex + age&quot;, modelFormula_random = &quot;(1|patientID)&quot;, reduced_modelFormula_fixed = &quot;sex + age&quot; ) # 5. Identify significant proteins # Define significance threshold fdr_threshold &lt;- 0.05 sig_targets_covid &lt;- lmerTest$LRTstats %&gt;% filter(Chisq_test_pval_FDR &lt; fdr_threshold) %&gt;% arrange(Chisq_test_pval_FDR) %&gt;% pull(target) # 6. Create volcano plots volcanoPlot( coefs = lmerTest$LRTstats$Chisq_stat, p_vals = lmerTest$LRTstats$Chisq_test_pval_FDR, target_labels = lmerTest$LRTstats$target, title = &quot;Group Effect (LRT)&quot;, xlabel = &quot;Chi-Squared Statistic&quot;, plot_name = &quot;volcano_lrt_group_effect.pdf&quot;, output_dir = out_dir, plot_width = 6, plot_height = 5 ) ## Timepoint-specific volcano plots timepoints &lt;- c(&quot;T.7.to..2&quot;, &quot;T0&quot;, &quot;T2.to.7&quot;, &quot;T8.to.20&quot;) for (tp in timepoints) { coef_col &lt;- paste0(&quot;Groupmild.COVID.&quot;, tp, &quot;_coef&quot;) pval_col &lt;- paste0(&quot;Groupmild.COVID.&quot;, tp, &quot;_pval_FDR&quot;) volcanoPlot( coefs = lmerTest$modelStats[[coef_col]], p_vals = lmerTest$modelStats[[pval_col]], target_labels = lmerTest$modelStats$target, title = paste(&quot;COVID&quot;, gsub(&quot;\\\\.&quot;, &quot; &quot;, tp), &quot;vs Control&quot;), plot_name = paste0(&quot;volcano_&quot;, tp, &quot;_vs_control.pdf&quot;), output_dir = out_dir, plot_width = 5, plot_height = 4 ) } # 7. Create trajectory plots ## Categorical time spaghetti plot ## Prepare data for spaghetti plot covid_data &lt;- data_covid %&gt;% filter(covid_status != &quot;control&quot;, Target %in% sig_targets_covid) control_data &lt;- data_covid %&gt;% filter(covid_status == &quot;control&quot;, Target %in% sig_targets_covid) combined_data &lt;- bind_rows(covid_data, control_data) mean_trends &lt;- combined_data %&gt;% filter(Group != &quot;control&quot;) %&gt;% group_by(Target, Group) %&gt;% summarize(mean_NPQ = mean(NPQ, na.rm = TRUE), .groups = &quot;drop&quot;) control_mean &lt;- combined_data %&gt;% filter(Group == &quot;control&quot;) %&gt;% group_by(Target, Group) %&gt;% summarize(mean_NPQ = mean(NPQ, na.rm = TRUE), .groups = &quot;drop&quot;) ## Create and save spaghetti plot spaghetti_plot &lt;- ggplot() + geom_point(data = combined_data %&gt;% filter(Group == &quot;control&quot;), aes(x = Group, y = NPQ, shape = &quot;Control&quot;, fill = &quot;Control&quot;), color = &quot;blue&quot;, alpha = 0.5, size = 1) + geom_line(data = combined_data %&gt;% filter(Group != &quot;control&quot;), aes(x = Group, y = NPQ, group = patientID, color = patientID), alpha = 0.5, linewidth = 0.5) + geom_point(data = combined_data %&gt;% filter(Group != &quot;control&quot;), aes(x = Group, y = NPQ, color = patientID), alpha = 0.7, size = 1) + geom_line(data = mean_trends, aes(x = Group, y = mean_NPQ, group = 1), color = &quot;black&quot;, linewidth = 1.2) + geom_point(data = mean_trends, aes(x = Group, y = mean_NPQ, shape = &quot;Mean (COVID)&quot;, fill = &quot;Mean (COVID)&quot;), color = &quot;black&quot;, size = 2.2) + geom_point(data = control_mean, aes(x = Group, y = mean_NPQ, shape = &quot;Mean (Control)&quot;, fill = &quot;Mean (Control)&quot;), color = &quot;blue&quot;, size = 2.2) + scale_shape_manual( name = &quot;Group&quot;, values = c(&quot;Control&quot; = 17, &quot;Mean (COVID)&quot; = 18, &quot;Mean (Control)&quot; = 18), breaks = c(&quot;Control&quot;, &quot;Mean (Control)&quot;, &quot;Mean (COVID)&quot;) ) + scale_fill_manual( name = &quot;Group&quot;, values = c(&quot;Control&quot; = &quot;blue&quot;, &quot;Mean (COVID)&quot; = &quot;black&quot;, &quot;Mean (Control)&quot; = &quot;blue&quot;), breaks = c(&quot;Control&quot;, &quot;Mean (Control)&quot;, &quot;Mean (COVID)&quot;) ) + facet_wrap(~Target, scales = &quot;free_y&quot;) + labs( title = &quot;Significant Targets Over Time&quot;, subtitle = &quot;Targets with FDR-adjusted p &lt; 0.05 for Group Effect from LRT&quot;, x = &quot;Group&quot;, y = &quot;NPQ&quot;, color = &quot;Patient ID&quot; ) + theme_minimal() + theme( axis.text.x = element_text(angle = 45, hjust = 1), legend.position = &quot;right&quot; ) + guides( fill = guide_legend(order = 1, override.aes = list(alpha = 1)), shape = guide_legend(order = 1), color = guide_legend(order = 2, title = &quot;Patient ID&quot;) ) ggsave( filename = &quot;spaghetti_plot_significant_targets.pdf&quot;, plot = spaghetti_plot, path = &quot;figures&quot;, width = 12, height = 10 ) ## Continuous time spaghetti plot ## Prepare data for spaghetti plot covid_data_cont &lt;- data_covid %&gt;% filter(covid_status != &quot;control&quot;, Target %in% sig_targets_covid) control_data_cont &lt;- data_covid %&gt;% filter(covid_status == &quot;control&quot;, Target %in% sig_targets_covid) %&gt;% mutate(days_from_peak_N_protein = -14) combined_data_cont &lt;- bind_rows(covid_data_cont, control_data_cont) %&gt;% mutate(is_control = ifelse(covid_status == &quot;control&quot;, TRUE, FALSE)) ## Calculate mean for controls control_mean_cont &lt;- combined_data_cont %&gt;% filter(is_control) %&gt;% group_by(Target, days_from_peak_N_protein) %&gt;% summarize(mean_NPQ = mean(NPQ, na.rm = TRUE), .groups = &quot;drop&quot;) ## Create breaks and labels for x-axis x_breaks &lt;- c(-14, 0, 10, 20) x_labels &lt;- c(&quot;Control&quot;, &quot;0&quot;, &quot;10&quot;, &quot;20&quot;) ## Create the plot spaghetti_plot2 &lt;- ggplot() + # Control points geom_point(data = combined_data_cont %&gt;% filter(is_control), aes(x = days_from_peak_N_protein, y = NPQ, shape = &quot;Control&quot;, fill = &quot;Control&quot;), color = &quot;blue&quot;, alpha = 0.5, size = 1) + # Individual patient trajectories (COVID only) geom_line(data = combined_data_cont %&gt;% filter(!is_control), aes(x = days_from_peak_N_protein, y = NPQ, group = patientID, color = patientID), alpha = 0.5, linewidth = 0.5) + geom_point(data = combined_data_cont %&gt;% filter(!is_control), aes(x = days_from_peak_N_protein, y = NPQ, color = patientID), alpha = 0.7, size = 1) + # Smooth trend line (COVID patients only) geom_smooth(data = combined_data_cont %&gt;% filter(!is_control), aes(x = days_from_peak_N_protein, y = NPQ, linetype = &quot;Mean (COVID)&quot;), color = &quot;black&quot;, linewidth = 1, se = TRUE, method = &quot;loess&quot;) + # Control mean geom_point(data = control_mean_cont, aes(x = days_from_peak_N_protein, y = mean_NPQ, shape = &quot;Mean (Control)&quot;, fill = &quot;Mean (Control)&quot;), color = &quot;blue&quot;, size = 1.8) + # Manual scales for legend scale_shape_manual( name = &quot;Group&quot;, values = c(&quot;Control&quot; = 17, &quot;Mean (Control)&quot; = 18), breaks = c(&quot;Control&quot;, &quot;Mean (Control)&quot;) ) + scale_fill_manual( name = &quot;Group&quot;, values = c(&quot;Control&quot; = &quot;blue&quot;, &quot;Mean (Control)&quot; = &quot;blue&quot;), breaks = c(&quot;Control&quot;, &quot;Mean (Control)&quot;) ) + scale_linetype_manual( name = &quot;Group&quot;, values = c(&quot;Mean (COVID)&quot; = &quot;solid&quot;), breaks = c(&quot;Mean (COVID)&quot;) ) + # Custom x-axis scale_x_continuous( breaks = x_breaks, labels = x_labels ) + # Add vertical line at day 0 (peak N protein) geom_vline(xintercept = 0, linetype = &quot;dashed&quot;, color = &quot;gray50&quot;, alpha = 0.5) + facet_wrap(~Target, scales = &quot;free_y&quot;) + labs( title = &quot;COVID Patients: Significant Targets Over Time&quot;, subtitle = &quot;Targets with FDR-adjusted p &lt; 0.05 for Group Effect from LRT&quot;, x = &quot;Days from Peak N Protein&quot;, y = &quot;NPQ&quot;, color = &quot;Patient ID&quot; ) + theme_minimal() + theme( axis.text.x = element_text(angle = 45, hjust = 1), legend.position = &quot;right&quot;, plot.title = element_text(size = 14, face = &quot;bold&quot;), plot.subtitle = element_text(size = 11) ) + guides( fill = guide_legend(order = 1, override.aes = list(alpha = 1)), shape = guide_legend(order = 1), linetype = guide_legend(order = 1), color = guide_legend(order = 2, title = &quot;Patient ID&quot;) ) ggsave( filename = &quot;spaghetti_plot_continuous_time_significant_targets.pdf&quot;, plot = spaghetti_plot2, path = &quot;figures&quot;, width = 12, height = 10 ) # 8. Export results dir.create(&quot;results&quot;, showWarnings = FALSE) write_csv(lmerTest$LRTstats, &quot;results/lmer_lrt_statistics.csv&quot;) write_csv(lmerTest$modelStats, &quot;results/lmer_model_coefficients.csv&quot;) write_csv( data.frame(target = sig_targets_covid, significant = TRUE), &quot;results/significant_targets_list.csv&quot; ) # 9. Print summary cat(&quot;\\nLongitudinal Analysis Summary:\\n&quot;) cat(&quot;Total proteins tested:&quot;, nrow(lmerTest$LRTstats), &quot;\\n&quot;) cat(&quot;Significant proteins (Group effect):&quot;, length(sig_targets_covid), &quot;\\n\\n&quot;) for (tp in timepoints) { pval_col &lt;- paste0(&quot;Groupmild.COVID.&quot;, tp, &quot;_pval_FDR&quot;) n_sig &lt;- sum(lmerTest$modelStats[[pval_col]] &lt; 0.05, na.rm = TRUE) cat(&quot;Significant at&quot;, gsub(&quot;\\\\.&quot;, &quot; &quot;, tp), &quot;:&quot;, n_sig, &quot;proteins\\n&quot;) } 5.8 Best Practices Model Design Choose appropriate random effects structure based on your data Include relevant covariates (age, sex, batch, etc.) Ensure adequate sample size per subject for complex random effects Assumptions Check for outliers and influential observations Verify normality of residuals (QQ plots) Assess homoscedasticity Interpretation Use FDR-adjusted p-values to control false discovery rate Consider both statistical significance and biological relevance (e.g., effect size) Visualize trajectories to understand temporal patterns Validate key findings with independent methods or cohorts Reporting Document model formulas (fixed and random effects) Report sample sizes (subjects and observations) Describe significance thresholds 5.9 Common Issues Problem: Model convergence failures Simplify random effects structure Center and scale continuous predictors Check for collinearity among predictors Increase iteration limits (see ?lmer) Problem: No significant proteins Check if trajectories actually differ (visualize) Sample size may be too small Effect sizes may be small Consider less stringent thresholds (exploratory only) Problem: Too many significant proteins Check for batch effects or technical artifacts Verify model is appropriately specified Consider more stringent FDR threshold Problem: Results don’t match trajectories Verify factor levels and reference groups Check that patientID is correctly coded Ensure metadata matches sample names Continue to: Chapter 6: Outcome Modeling "],["outcome-modeling.html", "Chapter 6 Outcome Modeling 6.1 Overview 6.2 Example 1: Exploring Age Associations (Continuous Outcome) 6.3 Example 2: Modeling Disease Status (Binary Outcome) 6.4 Comparing Approaches 6.5 Exporting Results 6.6 Complete Outcome Modeling Workflow 6.7 Best Practices", " Chapter 6 Outcome Modeling This chapter covers covariate-adjusted regression models that test associations between individual protein abundance levels and outcomes, including both continuous and binary responses. In contrast to differential abundance analysis covered in Chapters 4 and 5, where protein abundance (NPQ) was modeled as the outcome, in this setting single-protein NPQ serves as the primary predictor of interest, and outcomes such as disease status or a continuous clinical score is the dependent variable. Note on terminology: These are univariable regression models (one protein at a time), not multivariable predictive or machine learning approaches. We use “outcome modeling” to describe fitting statistical models that quantify protein-outcome relationships while adjusting for relevant covariates. 6.1 Overview While differential abundance asks “What proteins differ between groups?”, predictive modeling explores “Which proteins are associated with an outcome, and how well does protein abundance explain or predict it?” In this context, “prediction” does not necessarily imply clinical forecasting. It refers more generally to building statistical models that quantify the relationship between protein abundance and a phenotype or outcome. These models use protein abundance level as a predictor to identify proteins associated with biological variation or group classification. NULISAseqR provides four functions for outcome modeling: Fixed Effects Models: lmNULISAseq_predict(): For continuous outcomes (linear regression) glmNULISAseq_predict(): For binary or count outcomes (generalized linear models, including logistic, Poisson, etc.) Mixed Effects Models: lmerNULISAseq_predict(): For continuous outcomes with repeated measures or hierarchical data (linear mixed-effects models) glmerNULISAseq_predict(): For binary or count outcomes with repeated measures or hierarchical data (generalized linear mixed-effects models) In this chapter, we will focus on the fixed effects models: lmNULISAseq_predict() for continuous outcomes and glmNULISAseq_predict() for binary outcomes. 6.2 Example 1: Exploring Age Associations (Continuous Outcome) Age is a great continuous outcome for regression modeling because it is objectively measured, precisely recorded, and biologically meaningful — many protein abundance patterns naturally vary with aging. 6.2.1 Why Model Age? Identify proteins associated with aging Explore potential biological age biomarkers Understand how protein abundance relates to age Validate that your proteomic data captures true biological signal 6.2.2 Age Distribution in the Dataset # Check age distribution in the Detectability Study dataset used in differential abundance analysis summary(metadata$age) #&gt; Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s #&gt; 22.00 42.75 55.00 54.66 65.25 86.00 19 hist(metadata$age, main = &quot;Age Distribution&quot;, xlab = &quot;Age (years)&quot;) The dataset contains a few pooled plasma samples with missing age data. We will exclude these samples from the age association analysis. # Exclude samples with missing age metadata_age &lt;- metadata %&gt;% filter(!is.na(age)) sample_list_age &lt;- metadata_age$SampleName cat(&quot;Samples with valid age:&quot;, nrow(metadata_age), &quot;\\n&quot;) #&gt; Samples with valid age: 148 6.2.3 Building the Age Regression Model Fit the regression model using lmNULISAseq_predict(): # Fit linear models with each protein predicting age lmpt_age &lt;- lmNULISAseq_predict( data = data$merged$Data_NPQ[, sample_list_age], sampleInfo = metadata_age, sampleName_var = &quot;SampleName&quot;, response_var = &quot;age&quot;, modelFormula = &quot;disease_type + sex&quot; # Adjust for disease_type and sex as covariates ) 6.2.4 Understanding the Age Model For each protein, the model is: age ~ NPQ + disease_type + sex This tests: “Is this protein associated with age, while accounting for disease type and sex?” The coefficient shows the estimated change in age per unit increase (doubling) in protein abundance (NPQ). 6.2.5 Examining Age Association Results # View structure names(lmpt_age) #&gt; [1] &quot;modelStats&quot; #&gt; Preview of Age Association Results (rounded to 3 digits): Key Columns in Results target: Protein name target_coef: Estimated change in years of age per unit increase in NPQ target_pval_unadj: Unadjusted p-value (is this protein significantly associated with age?) target_pval_FDR: FDR-adjusted p-value target_pval_bonf: Bonferroni-adjusted p-value 6.2.6 Finding Age-Associated Proteins We will identify proteins that are significantly associated with age with FDR-adjusted p value &lt; 0.05. # Find proteins significantly associated with age age_proteins &lt;- lmpt_age$modelStats %&gt;% filter(target_pval_FDR &lt; 0.05) %&gt;% arrange(target_pval_FDR) %&gt;% select(target, target_coef, target_pval_FDR) cat(&quot;Number of proteins significantly associated with age:&quot;, nrow(age_proteins), &quot;\\n\\n&quot;) #&gt; Number of proteins significantly associated with age: 8 #&gt; Age-Associated Proteins: We can further identify proteins that are either significantly increased or decreased with age. # Proteins that increase with age (positive coefficients) age_increase &lt;- age_proteins %&gt;% filter(target_coef &gt; 0) %&gt;% arrange(desc(abs(target_coef))) # Proteins that decrease with age (negative coefficients) age_decrease &lt;- age_proteins %&gt;% filter(target_coef &lt; 0) %&gt;% arrange(desc(abs(target_coef))) cat(&quot;Number of proteins significantly increase with age:&quot;, nrow(age_increase), &quot;\\n\\n&quot;) #&gt; Number of proteins significantly increase with age: 8 cat(&quot;Number of proteins significantly decrease with age:&quot;, nrow(age_decrease), &quot;\\n\\n&quot;) #&gt; Number of proteins significantly decrease with age: 0 Interpretation: GFAP has target_coef = 5.76, this means that every 1-unit increase in NPQ (2-fold increase in GFAP) is associated with an average age increase of 5.76 years GDF15 has target_coef = 4.25, this means that every 1-unit increase in NPQ (2-fold increase in GDF15) is associated with an average age increase of 4.25 years CXCL14 has target_coef = 3.47, this means that every 1-unit increase in NPQ (2-fold increase in CXCL14) is associated with an average age increase of 3.47 years CHI3L1 has target_coef = 3.33, this means that every 1-unit increase in NPQ (2-fold increase in CHI3L1) is associated with an average age increase of 3.33 years 6.2.7 Volcano Plots volcanoPlot( coefs = lmpt_age$modelStats$target_coef, p_vals = lmpt_age$modelStats$target_pval_FDR, target_labels = lmpt_age$modelStats$target, title = &quot;Age-Associated Proteins&quot;, xlab = &quot;Coefficient (Years of age per unit NPQ)&quot;, ) 6.2.8 Age-Associated Proteins Scatterplots # Create labels with available statistics stat_labels &lt;- lmpt_age$modelStats %&gt;% filter(target %in% age_proteins$target) %&gt;% select(target, target_coef, target_pval_FDR) %&gt;% mutate(label = paste0( &quot;β = &quot;, round(target_coef, 2), &quot;\\n&quot;, &quot;FDR = &quot;, format(target_pval_FDR, digits = 2, scientific = TRUE) )) plot_data_age &lt;- data_long %&gt;% filter(Target %in% age_proteins$target, SampleName %in% sample_list_age) %&gt;% left_join(stat_labels, by = c(&quot;Target&quot; = &quot;target&quot;)) # Plot age-associated proteins ggplot(plot_data_age, aes(x = NPQ, y = age)) + geom_point(aes(color = sex), alpha = 0.6, size = 1) + geom_smooth(method = &quot;lm&quot;, se = TRUE, color = &quot;blue&quot;, linewidth = 1) + geom_text(aes(label = label), x = Inf, y = -Inf, hjust = 1.1, vjust = -0.1, size = 4, color = &quot;black&quot;) + facet_wrap(~ Target, scales = &quot;free_x&quot;) + theme_minimal() + labs(title = &quot;Age-Associated Proteins&quot;, x = &quot;NPQ&quot;, y = &quot;Age (years)&quot;, color = &quot;Sex&quot;) + theme( strip.text = element_text(size = 13, face = &quot;bold&quot;), plot.title = element_text(size = 16, face = &quot;bold&quot;), axis.title.x = element_text(size = 14), axis.title.y = element_text(size = 14), axis.text.x = element_text(size = 12), axis.text.y = element_text(size = 12), legend.title = element_text(size = 13), legend.text = element_text(size = 12) ) 6.3 Example 2: Modeling Disease Status (Binary Outcome) Now we will use logistic regression to model the association between protein abundance and disease status (inflammatory disease vs normal), adjusting for age and sex. 6.3.1 Disease Status as Binary Outcome Question: Which proteins are associated with inflammatory disease after accounting for age and sex? Unlike differential abundance which compares group mean NPQ levels, logistic regression models the relationship between continuous protein abundance and a binary outcome (disease present/absent) while adjusting for other factors. 6.3.2 Preparing the Disease Data # Subset metadata for inflammatory disease and normal samples only metadata_disease &lt;- metadata %&gt;% filter(disease_type %in% c(&quot;normal&quot;, &quot;inflam&quot;)) %&gt;% mutate(disease_binary = ifelse(disease_type == &quot;inflam&quot;, 1, 0)) # Check outcome distribution cat(&quot;Sample distribution:\\n&quot;) #&gt; Sample distribution: table(metadata_disease$disease_type, metadata_disease$disease_binary) #&gt; #&gt; 0 1 #&gt; normal 79 0 #&gt; inflam 0 21 #&gt; cancer 0 0 #&gt; kidney 0 0 #&gt; metab 0 0 #&gt; neuro 0 0 # Get sample list for these groups disease_sample_list &lt;- metadata_disease$SampleName 6.3.3 Building the Disease Association Model # Fit logistic regression models for ALL proteins glmt_disease &lt;- glmNULISAseq_predict( data = data$merged$Data_NPQ[, disease_sample_list], sampleInfo = metadata_disease, sampleName_var = &quot;SampleName&quot;, response_var = &quot;disease_binary&quot;, modelFormula = &quot;sex + age&quot; # Adjust for sex and age as covariates ) 6.3.4 Understanding the Disease Model For each protein, the model is: log(odds of inflammatory disease) ~ NPQ + sex + age This tests: “Is this protein associated with disease status (inflammatory disease vs normal) while accounting for sex and age?” 6.3.5 Examining Disease Association Results # View structure names(glmt_disease) #&gt; [1] &quot;modelStats&quot; #&gt; Preview of Disease Association Results (rounded to 3 digits): Key Columns in Results target: Protein name target_coef: Log odds ratio (raw coefficient) target_OR: Odds ratio = exp(target_coef) target_se: Standard error of the coefficient target_zval: Z-value (Wald statistic) target_pval_unadj: Unadjusted p-value (Wald test) target_pval_FDR: FDR-adjusted p-value 6.3.6 Finding Disease-Associated Proteins We will identify proteins that are significantly associated with the odds of inflammatory disease with FDR-adjusted p value &lt; 0.05. # Find proteins significantly associated with disease status disease_proteins &lt;- glmt_disease$modelStats %&gt;% filter(target_pval_FDR &lt; 0.05) %&gt;% arrange(target_pval_FDR) %&gt;% select(target, target_coef, target_OR, target_pval_FDR) cat(&quot;Proteins significantly associated with disease status (FDR &lt; 0.05):&quot;, nrow(disease_proteins), &quot;\\n&quot;) #&gt; Proteins significantly associated with disease status (FDR &lt; 0.05): 105 6.3.7 Interpreting Odds Ratios # Strong positive associations with inflammatory disease (OR &gt; 1) inflam_associated &lt;- disease_proteins %&gt;% filter(target_OR &gt; 1) %&gt;% arrange(desc(target_OR)) cat(&quot;Number of proteins with significantly POSITIVE association with inflammatory disease:&quot;, nrow(inflam_associated), &quot;\\n\\n&quot;) #&gt; Number of proteins with significantly POSITIVE association with inflammatory disease: 105 # Strong negative associations with inflammatory disease (OR &lt; 1) normal_associated &lt;- disease_proteins %&gt;% filter(target_OR &lt; 1) %&gt;% arrange(target_OR) cat(&quot;Number of proteins with significantly NEGATIVE association with inflammatory disease:&quot;, nrow(normal_associated), &quot;\\n\\n&quot;) #&gt; Number of proteins with significantly NEGATIVE association with inflammatory disease: 0 Odds Ratio Interpretation: OR = 1: No association with disease status OR = 2: Each 1-unit increase in protein abundance (NPQ) is associated with 2 times higher odds of inflammatory disease OR = 0.5: Each 1-unit increase in protein abundance is associated with half the odds of inflammatory disease OR &gt; 2: Strong positive association (higher protein → greater odds of inflammatory disease) OR &lt; 0.5: Strong negative association (higher protein → lower odds of inflammatory disease) 6.3.8 Disease-Associated Proteins Volcano Plots volcanoPlot( coefs = glmt_disease$modelStats$target_coef, p_vals = glmt_disease$modelStats$target_pval_FDR, target_labels = glmt_disease$modelStats$target, title = &quot;Inflammation-Associated Proteins&quot;, xlab = expression(&quot;log(Odds Ratio)&quot;) ) 6.3.9 Visualizing Disease Associations # Plot top 6 disease-predictive proteins top_6_disease &lt;- disease_proteins$target[1:6] # Box plots data_long %&gt;% filter(Target %in% top_6_disease, SampleName %in% inflam_samples) %&gt;% ggplot(aes(x = disease_type, y = NPQ, fill = disease_type)) + geom_boxplot(alpha = 0.7, outlier.shape = NA) + geom_jitter(width = 0.2, alpha = 0.4, size = 1.5) + facet_wrap(~ Target, scales = &quot;free_y&quot;, ncol = 3) + scale_fill_manual(values = c(&quot;normal&quot; = &quot;#4DAF4A&quot;, &quot;inflam&quot; = &quot;#E41A1C&quot;)) + labs(title = &quot;Top Disease-Predictive Proteins&quot;, x = &quot;Disease Status&quot;, y = &quot;Protein Abundance (NPQ)&quot;, fill = &quot;Status&quot;) + theme( strip.text = element_text(size = 12, face = &quot;bold&quot;), legend.position = &quot;bottom&quot; ) # Logistic curve visualization for top 6 proteins data_long %&gt;% filter(Target %in% top_6_disease, SampleName %in% inflam_samples) %&gt;% left_join( metadata_disease %&gt;% select(SampleName, disease_binary), by = &quot;SampleName&quot; ) %&gt;% ggplot(aes(x = NPQ, y = disease_binary)) + geom_point(alpha = 0.5, size = 2) + geom_smooth(method = &quot;glm&quot;, method.args = list(family = &quot;binomial&quot;), se = TRUE, color = &quot;red&quot;, linewidth = 1) + facet_wrap(~ Target, scales = &quot;free_x&quot;, ncol = 3) + theme_minimal() + labs(title = &quot;Logistic Regression Curves for Disease Prediction&quot;, x = &quot;NPQ&quot;, y = &quot;Probability of Inflammation&quot;) + theme( strip.text = element_text(size = 12, face = &quot;bold&quot;) ) 6.3.10 ROC Curves for Disease-Associated Proteins library(pROC) # Prepare data for ROC analysis roc_data &lt;- data_long %&gt;% filter(Target %in% top_6_disease, SampleName %in% disease_sample_list) %&gt;% left_join(metadata_disease %&gt;% select(SampleName, disease_binary), by = &quot;SampleName&quot;) # Calculate ROC curves and AUC for each protein roc_plot_data &lt;- do.call(rbind, lapply(top_6_disease, function(protein) { # Filter data for current protein protein_data &lt;- roc_data %&gt;% filter(Target == protein) # Calculate ROC roc_obj &lt;- roc(protein_data$disease_binary, protein_data$NPQ, quiet = TRUE) # Extract ROC data and AUC data.frame( Target = protein, Sensitivity = roc_obj$sensitivities, Specificity = roc_obj$specificities, AUC = round(as.numeric(auc(roc_obj)), 3) ) })) # Create annotation data annotation_data &lt;- unique(roc_plot_data[, c(&quot;Target&quot;, &quot;AUC&quot;)]) annotation_data$label &lt;- paste0(&quot;AUC = &quot;, annotation_data$AUC) # Create ROC curve plot ggplot(roc_plot_data, aes(x = 1 - Specificity, y = Sensitivity)) + geom_line(color = &quot;#E41A1C&quot;, linewidth = 1) + geom_abline(slope = 1, intercept = 0, linetype = &quot;dashed&quot;, color = &quot;gray50&quot;) + geom_text(data = annotation_data, aes(x = 0.7, y = 0.15, label = label), size = 3.5, hjust = 0.1) + facet_wrap(~ Target, ncol = 3) + theme_minimal() + labs(title = &quot;ROC Curves for Top Disease-Associated Proteins&quot;, x = &quot;1 - Specificity (False Positive Rate)&quot;, y = &quot;Sensitivity (True Positive Rate)&quot;) + theme( strip.text = element_text(size = 13, face = &quot;bold&quot;), plot.title = element_text(size = 14, face = &quot;bold&quot;), axis.title = element_text(size = 12), axis.text = element_text(size = 10) ) + coord_equal() 6.4 Comparing Approaches 6.4.1 When to Use Each Function Differential Abundance (lmNULISAseq) Goal: Find proteins that show difference in mean abundance levels between groups Protein abundances (NPQ) are outcomes, groups are predictors Example: “Which proteins show different levels in inflammatory disease vs normal?” Continuous Outcome (lmNULISAseq_predict) Goal: Identify proteins associated with a continuous outcome such as age or clinical score Proteins are predictors, continuous variable is outcome Example: “Which proteins can explain the most variation in age or disease severity score?” Binary Outcome (glmNULISAseq_predict) Goal: Identify proteins associated with a binary outcome Proteins are predictors, binary variable is outcome Example: “Which proteins are most discriminative when classifying subjects into binary disease categories?” 6.5 Exporting Results Save your results for downstream analysis or reporting: # Save age association results write_csv(lmpt_age$modelStats, &quot;results/age_association_all_proteins.csv&quot;) write_csv(age_proteins, &quot;results/age_associated_proteins_significant.csv&quot;) # Save disease association results write_csv(glmt_disease$modelStats, &quot;results/disease_association_all_proteins.csv&quot;) write_csv(disease_proteins, &quot;results/disease_associated_proteins_significant.csv&quot;) 6.6 Complete Outcome Modeling Workflow Here’s a complete workflow example that you can adapt for your own data: # Load libraries library(NULISAseqR) library(tidyverse) library(pROC) # 1. Continuous Outcome: Age Association ## Check age distribution in the Detectability Study dataset used in differential abundance analysis summary(metadata$age) hist(metadata$age, main = &quot;Age Distribution&quot;, xlab = &quot;Age (years)&quot;) # Exclude samples with missing age metadata_age &lt;- metadata %&gt;% filter(!is.na(age)) sample_list_age &lt;- metadata_age$SampleName ## Fit linear models lmpt_age &lt;- lmNULISAseq_predict( data = data$merged$Data_NPQ[, sample_list_age], sampleInfo = metadata_age, sampleName_var = &quot;SampleName&quot;, response_var = &quot;age&quot;, modelFormula = &quot;disease_type + sex&quot; ) ## Identify significant age-associated proteins age_proteins &lt;- lmpt_age$modelStats %&gt;% filter(target_pval_FDR &lt; 0.05) %&gt;% arrange(target_pval_FDR) cat(&quot;Proteins associated with age:&quot;, nrow(age_proteins), &quot;\\n\\n&quot;) ## Volcano plot for age-associated proteins volcanoPlot( coefs = lmpt_age$modelStats$target_coef, p_vals = lmpt_age$modelStats$target_pval_FDR, target_labels = lmpt_age$modelStats$target, title = &quot;Age-Associated Proteins&quot;, xlab = &quot;Coefficient (Years of age per unit NPQ)&quot;, ) ## Plot age-associated proteins stat_labels &lt;- lmpt_age$modelStats %&gt;% filter(target %in% age_proteins$target) %&gt;% select(target, target_coef, target_pval_FDR) %&gt;% mutate(label = paste0( &quot;β = &quot;, round(target_coef, 2), &quot;\\n&quot;, &quot;FDR = &quot;, format(target_pval_FDR, digits = 2, scientific = TRUE) )) plot_data_age &lt;- data_long %&gt;% filter(Target %in% age_proteins$target, SampleName %in% sample_list_age) %&gt;% left_join(stat_labels, by = c(&quot;Target&quot; = &quot;target&quot;)) # Plot age-associated proteins ggplot(plot_data_age, aes(x = NPQ, y = age)) + geom_point(aes(color = sex), alpha = 0.6, size = 1) + geom_smooth(method = &quot;lm&quot;, se = TRUE, color = &quot;blue&quot;, linewidth = 1) + geom_text(aes(label = label), x = Inf, y = -Inf, hjust = 1.1, vjust = -0.1, size = 4, color = &quot;black&quot;) + facet_wrap(~ Target, scales = &quot;free_x&quot;) + theme_minimal() + labs(title = &quot;Age-Associated Proteins&quot;, x = &quot;NPQ&quot;, y = &quot;Age (years)&quot;, color = &quot;Sex&quot;) + theme( strip.text = element_text(size = 13, face = &quot;bold&quot;), plot.title = element_text(size = 16, face = &quot;bold&quot;), axis.title.x = element_text(size = 14), axis.title.y = element_text(size = 14), axis.text.x = element_text(size = 12), axis.text.y = element_text(size = 12), legend.title = element_text(size = 13), legend.text = element_text(size = 12) ) # 2. Binary Outcome: Disease Status ## Prepare binary outcome metadata_disease &lt;- metadata %&gt;% filter(disease_type %in% c(&quot;normal&quot;, &quot;inflam&quot;)) %&gt;% mutate(disease_binary = ifelse(disease_type == &quot;inflam&quot;, 1, 0)) disease_sample_list &lt;- metadata_disease$SampleName ## Fit logistic regression models glmt_disease &lt;- glmNULISAseq_predict( data = data$merged$Data_NPQ[, disease_sample_list], sampleInfo = metadata_disease, sampleName_var = &quot;SampleName&quot;, response_var = &quot;disease_binary&quot;, modelFormula = &quot;sex + age&quot; ) ## Identify significant associations disease_proteins &lt;- glmt_disease$modelStats %&gt;% filter(target_pval_FDR &lt; 0.05) %&gt;% arrange(target_pval_FDR) cat(&quot;Proteins associated with disease:&quot;, nrow(disease_proteins), &quot;\\n\\n&quot;) ## Identify proteins with positive associations with inflammatory disease (OR &gt; 1) inflam_associated &lt;- disease_proteins %&gt;% filter(target_OR &gt; 1) %&gt;% arrange(desc(target_OR)) cat(&quot;Number of proteins with significantly POSITIVE association with inflammatory disease:&quot;, nrow(inflam_associated), &quot;\\n\\n&quot;) # Identify proteins with negative associations with inflammatory disease (OR &lt; 1) normal_associated &lt;- disease_proteins %&gt;% filter(target_OR &lt; 1) %&gt;% arrange(target_OR) cat(&quot;Number of proteins with significantly NEGATIVE association with inflammatory disease:&quot;, nrow(normal_associated), &quot;\\n\\n&quot;) ## Volcano plot for disease-associated proteins volcanoPlot( coefs = glmt_disease$modelStats$target_coef, p_vals = glmt_disease$modelStats$target_pval_FDR, target_labels = glmt_disease$modelStats$target, title = &quot;Inflammation-Associated Proteins&quot;, xlab = expression(&quot;log&quot;[2] * &quot;(Odds Ratio)&quot;) ) # 3. Visualize GLM predictions for top proteins ## Top 6 disease-predictive proteins top_6_disease &lt;- disease_proteins$target[1:6] ## Boxplots visualization for top 6 proteins data_long %&gt;% filter(Target %in% top_6_disease, SampleName %in% inflam_samples) %&gt;% ggplot(aes(x = disease_type, y = NPQ, fill = disease_type)) + geom_boxplot(alpha = 0.7, outlier.shape = NA) + geom_jitter(width = 0.2, alpha = 0.4, size = 1.5) + facet_wrap(~ Target, scales = &quot;free_y&quot;, ncol = 3) + scale_fill_manual(values = c(&quot;normal&quot; = &quot;#4DAF4A&quot;, &quot;inflam&quot; = &quot;#E41A1C&quot;)) + labs(title = &quot;Top Disease-Predictive Proteins&quot;, x = &quot;Disease Status&quot;, y = &quot;Protein Abundance (NPQ)&quot;, fill = &quot;Status&quot;) + theme( strip.text = element_text(face = &quot;bold&quot;), legend.position = &quot;bottom&quot; ) ## Logistic curve visualization for top 6 proteins data_long %&gt;% filter(Target %in% top_6_disease, SampleName %in% inflam_samples) %&gt;% left_join( metadata_disease %&gt;% select(SampleName, disease_binary), by = &quot;SampleName&quot; ) %&gt;% ggplot(aes(x = NPQ, y = disease_binary)) + geom_point(alpha = 0.5, size = 2) + geom_smooth(method = &quot;glm&quot;, method.args = list(family = &quot;binomial&quot;), se = TRUE, color = &quot;red&quot;, linewidth = 1) + facet_wrap(~ Target, scales = &quot;free_x&quot;, ncol = 3) + theme_minimal() + labs(title = &quot;Logistic Regression Curves for Disease Prediction&quot;, x = &quot;NPQ&quot;, y = &quot;Probability of Inflammation&quot;) + theme( strip.text = element_text(size = 10, face = &quot;bold&quot;) ) ## ROC Curves for top 6 proteins # Prepare data for ROC analysis roc_data &lt;- data_long %&gt;% filter(Target %in% top_6_disease, SampleName %in% disease_sample_list) %&gt;% left_join(metadata_disease %&gt;% select(SampleName, disease_binary), by = &quot;SampleName&quot;) roc_plot_data &lt;- do.call(rbind, lapply(top_6_disease, function(protein) { # Filter data for current protein protein_data &lt;- roc_data %&gt;% filter(Target == protein) # Calculate ROC roc_obj &lt;- roc(protein_data$disease_binary, protein_data$NPQ, quiet = TRUE) # Extract ROC data and AUC data.frame( Target = protein, Sensitivity = roc_obj$sensitivities, Specificity = roc_obj$specificities, AUC = round(as.numeric(auc(roc_obj)), 3) ) })) annotation_data &lt;- unique(roc_plot_data[, c(&quot;Target&quot;, &quot;AUC&quot;)]) annotation_data$label &lt;- paste0(&quot;AUC = &quot;, annotation_data$AUC) ## Plot ROC curves ggplot(roc_plot_data, aes(x = 1 - Specificity, y = Sensitivity)) + geom_line(color = &quot;#E41A1C&quot;, linewidth = 1) + geom_abline(slope = 1, intercept = 0, linetype = &quot;dashed&quot;, color = &quot;gray50&quot;) + geom_text(data = annotation_data, aes(x = 0.7, y = 0.15, label = label), size = 3.5, hjust = 0.1) + facet_wrap(~ Target, ncol = 3) + theme_minimal() + labs(title = &quot;ROC Curves for Top Disease-Associated Proteins&quot;, x = &quot;1 - Specificity (False Positive Rate)&quot;, y = &quot;Sensitivity (True Positive Rate)&quot;) + theme( strip.text = element_text(size = 13, face = &quot;bold&quot;), plot.title = element_text(size = 14, face = &quot;bold&quot;), axis.title = element_text(size = 12), axis.text = element_text(size = 10) ) + coord_equal() # 4. Exports all results dir.create(&quot;results&quot;, showWarnings = FALSE) write_csv(age_proteins, &quot;results/age_associated_proteins.csv&quot;) write_csv(disease_proteins, &quot;results/disease_associated_proteins.csv&quot;) cat(&quot;Results exported successfully!\\n\\n&quot;) # 6. Summary cat(&quot;Age-associated proteins:&quot;, nrow(age_proteins), &quot;\\n&quot;) cat(&quot;Disease-associated proteins:&quot;, nrow(disease_proteins), &quot;\\n&quot;) 6.7 Best Practices Model Design Covariate Selection Include biologically relevant covariates (e.g., age, sex) Include covariates that capture technical variation when needed (e.g., batch) Avoid overfitting: don’t include too many covariates relative to sample size Check for multicollinearity (i.e., correlation) between covariates Model Considerations For continuous outcomes: Check for non-linear relationships (consider polynomial terms if needed) For binary outcomes: Ensure adequate events per variable (typically ≥10 events per covariate) Test for interactions if biologically plausible (e.g., protein × age interaction) Interpretation Statistical Significance vs. Biological Relevance FDR &lt; 0.05 indicates false-discovery rate corrected statistical significance Effect size matters: small p-values don’t always mean biological importance For age: Consider whether coefficient magnitude is biologically meaningful For disease: OR &gt; 2 or OR &lt; 0.5 typically indicate strong associations Model Assessment For linear models: Check residual plots for normality and homoscedasticity For logistic models: Large coefficients or OR near 0/infinity may indicate separation issues Compare multiple proteins: consistency across related proteins strengthens confidence Understanding Differences Between Methods Differential abundance and logistic regression ask different questions - both provide valuable insights Proteins significant in both analyses are typically the most robust findings Method-specific findings warrant further investigation but may be true biological signals or in some cases driven by outliers Validation Within-Dataset Validation Examine sensitivity to covariate specification Check robustness across different subgroups External Validation Validate findings in independent datasets when possible Compare with published literature Reporting Essential Information to Report Model formula with all covariates Sample sizes (total and by group) Number of proteins tested and significant Multiple testing correction method (FDR, Bonferroni) Transparent Reporting Report both significant and non-significant results for key proteins of interest Acknowledge limitations (sample size, covariates not adjusted for, etc.) Clearly distinguish exploratory from confirmatory analyses Make data and code available when possible Visualization Guidelines Show raw data points when possible (not just summary statistics) Include uncertainty estimates (SE, confidence intervals) Use consistent color schemes across figures Clearly label axes and provide informative legends Continue to: Chapter 7: Case Study: Identifying Proteomic Signatures in SLE and RA "],["case-study-1.html", "Chapter 7 Case Study: Identifying Proteomic Signatures in Lupus and Rheumatoid Arthritis 7.1 Overview 7.2 Data Preparation 7.3 Apply Detectability Threshold 7.4 Global Data Visualization 7.5 Statistical Testing 7.6 Systemic Lupus Erythematosus (SLE) Analysis 7.7 Rheumatoid Arthritis (RA) Analysis 7.8 Comparing Disease Signatures 7.9 Next Steps 7.10 Complete Workflow Example Code", " Chapter 7 Case Study: Identifying Proteomic Signatures in Lupus and Rheumatoid Arthritis 7.1 Overview Differential abundance analysis is a powerful tool for proteomic studies, enabling researchers to identify proteins that are differentially abundant between experimental conditions. In this chapter, we demonstrate a complete differential abundance workflow using the NULISAseq Inflammation Panel to compare inflammatory diseases against healthy controls. We’ll analyze a dataset containing samples from patients with: Systemic Lupus Erythematosus (SLE): An autoimmune disease where the immune system attacks its own tissues, causing widespread inflammation and tissue damage Rheumatoid Arthritis (RA): A chronic inflammatory disorder primarily affecting joints, but potentially involving other organ systems Normal controls: Healthy individuals without inflammatory disease This workflow will cover data import, target detectability filtering, visualization of target abundance, statistical testing, and interpretation of disease-specific protein signatures. 7.2 Data Preparation 7.2.1 Load Required Libraries library(NULISAseqR) library(tidyverse) 7.2.2 Import Data We begin by importing the NULISAseq data file: data_dir &lt;- system.file(&quot;extdata&quot;, package = &quot;NULISAseqR&quot;) data.a &lt;- importNULISAseq(files = file.path(data_dir, &quot;Inflammation_250_RQ_demo_2025-05-20-Lab-A.xml&quot;)) #&gt; Using single IC to normalize data. Preview NPQ Long Data Frame #&gt; Preview of NPQ long data frame (first 20 rows): Preview NPQ Wide Data Matrix #&gt; Preview of NPQ matrix (first 10 proteins × 10 samples, rounded to 3 digits): 7.2.3 Prepare Sample Metadata Next, we extract and prepare the sample metadata, filtering for experimental samples and setting the reference level for the Disease variable: metadata.a &lt;- data.a$merged$samples %&gt;% filter(sampleType == &quot;Sample&quot;) %&gt;% mutate(Disease = relevel(Disease, ref = &quot;normal&quot;)) # Sample counts per group n_normal &lt;- sum(metadata.a$Disease == &quot;normal&quot;) n_sle &lt;- sum(metadata.a$Disease == &quot;lupusSle&quot;) n_ra &lt;- sum(metadata.a$Disease == &quot;rheumatoidArthritis&quot;) # Display sample distribution table(metadata.a$Disease) #&gt; #&gt; normal lupusSle rheumatoidArthritis #&gt; 19 12 12 The relevel() function is important here as it sets “normal” as the reference group for all subsequent statistical comparisons. This means our differential abundance results will show changes in diseased samples relative to healthy controls. Preview Metadata Data Frame #&gt; Preview of metadata data frame: 7.3 Apply Detectability Threshold Preview Detectability Table The detectability table is stored in data.a$merged$detectability. #&gt; Preview of detectability table: To ensure robust statistical analysis, we can filter proteins based on the detectability across samples. We typically use a 50% detectability threshold for plasma samples, meaning a target must be detected in at least 50% of samples to be included: detectability_threshold &lt;- 0.5 targets_passed &lt;- data.a$merged$detectability %&gt;% filter(`plasma (n = 43)` &gt; 50) %&gt;% pull(Target) # Identify excluded targets excluded_targets &lt;- setdiff(rownames(data.a$merged$Data_NPQ), targets_passed) cat(&quot;Number of targets excluded:&quot;, length(excluded_targets), &quot;\\n&quot;) #&gt; Number of targets excluded: 5 cat(&quot;Targets excluded:&quot;, paste(excluded_targets, collapse = &quot;, &quot;), &quot;\\n&quot;) #&gt; Targets excluded: CNTF, CTSS, IFNW1, IL11, IL32 7.4 Global Data Visualization Before performing differential abundance analysis, we will examine the overall structure of the data using unsupervised visualization methods. These methods are unsupervised in the sense that we do not deliberately segregate data by disease class. Rather, we observe how samples are sorted according to their similarity in protein abundance patterns while we annotate samples by disease class. 7.4.1 Prepare Metadata for Visualization First, we clean up the metadata labels for better plot readability: metadata_rename &lt;- metadata.a %&gt;% mutate(Disease = case_when( Disease == &quot;lupusSle&quot; ~ &quot;SLE&quot;, Disease == &quot;rheumatoidArthritis&quot; ~ &quot;RA&quot;, TRUE ~ &quot;Normal&quot; ), `Sample Matrix` = tolower(SAMPLE_MATRIX) ) 7.4.2 Hierarchical Clustering Heatmap The heatmap provides a global view of protein abundance patterns across all samples and identifies natural groupings: h &lt;- generate_heatmap(data = data.a$merged$Data_NPQ, sampleInfo = metadata_rename, sampleName_var = &quot;sampleName&quot;, sample_subset = metadata_rename$sampleName, target_subset = targets_passed, annotate_sample_by = c(&quot;Disease&quot;, &quot;Sample Matrix&quot;, &quot;Lab&quot;)) Interpretation: The heatmap shows hierarchical clustering of both samples (columns) and proteins (rows). Look for: Clustering of samples by disease type (indicated by the annotation bars) Groups of proteins with similar abundance patterns Elevated levels of inflammatory markers in disease groups relative to controls 7.4.3 Principal Component Analysis PCA shows the clustering of samples by groups in reduced dimensional space, highlighting variance in the dataset: p &lt;- generate_pca(data = data.a$merged$Data_NPQ, sampleInfo = metadata_rename, sampleName_var = &quot;sampleName&quot;, sample_subset = metadata_rename$sampleName, target_subset = targets_passed, annotate_sample_by = &quot;Disease&quot;) Interpretation: In the PCA plot: Each point represents a sample Distance between points reflects similarity in protein abundance patterns Good separation between disease groups suggests distinct proteomic signatures PC1 and PC2 percentages indicate how much variation each component explains 7.5 Statistical Testing Next we perform linear modeling to identify proteins that are significantly different in mean abundance between disease groups and controls: lmTest_da &lt;- lmNULISAseq(data = data.a$merged$Data_NPQ[targets_passed, metadata.a$sampleName], sampleInfo = metadata.a, sampleName_var = &quot;sampleName&quot;, modelFormula = &quot;Disease&quot;) The lmNULISAseq() function fits a linear model for each protein with NPQ as outcome and disease group as predictor. Model Results The model results are stored in lmTest_da$modelStats. #&gt; Preview of `lmTest_da$modelStats` Results Table (rounded to 3 digits): For comparing SLE to Normal: target: Target name DiseaselupusSle_coef: Difference in mean NPQ (log2 fold change) between SLE and Normal DiseaselupusSle_pval: Unadjusted p-value DiseaselupusSle_pval_FDR: FDR-adjusted p-value DiseaselupusSle_pval_bonf: Bonferroni-adjusted p-value 7.6 Systemic Lupus Erythematosus (SLE) Analysis 7.6.1 Background Systemic Lupus Erythematosus is characterized by chronic inflammation affecting multiple organ systems. The immune dysregulation in SLE involves abnormal B and T cell activation, autoantibody production, and inflammatory cytokine release. The proteomic signature of SLE typically shows: Elevated inflammatory cytokines and chemokines Increased acute phase proteins Markers of immune activation Proteins involved in tissue damage and repair 7.6.2 Volcano Plot The volcano plot visualizes both the magnitude (fold change) and statistical significance of protein changes: volcanoPlot(coefs = lmTest_da$modelStats$DiseaselupusSle_coef, p_vals = lmTest_da$modelStats$DiseaselupusSle_pval_FDR, target_labels = lmTest_da$modelStats$target, title = paste0(&quot;Systemic Lupus Erythematosus (SLE) (n=&quot;, n_sle, &quot;) \\n vs Normal (n=&quot;, n_normal, &quot;)&quot;)) Interpretation: X-axis (coefficient): Log2 fold change; positive values indicate elevated levels in SLE Y-axis (-log10 p-value): Statistical significance; higher values = more significant Colored points: Proteins passing the FDR &lt; 0.05 threshold Upper left/right corners: Most significantly changed proteins 7.6.3 Visualizations Now we examine only the samples and proteins relevant to the SLE comparison: # Select SLE and normal samples sle_samples &lt;- metadata.a %&gt;% filter(Disease %in% c(&quot;normal&quot;, &quot;lupusSle&quot;)) %&gt;% pull(sampleName) # Identify significantly differential proteins sig_targets_sle &lt;- lmTest_da$modelStats %&gt;% filter(DiseaselupusSle_pval_FDR &lt; 0.05) %&gt;% pull(target) cat(&quot;Number of significant targets in SLE:&quot;, length(sig_targets_sle), &quot;\\n&quot;) #&gt; Number of significant targets in SLE: 102 7.6.3.1 SLE-Specific Heatmap h_sle &lt;- generate_heatmap(data = data.a$merged$Data_NPQ, sampleInfo = metadata_rename, sampleName_var = &quot;sampleName&quot;, sample_subset = sle_samples, target_subset = sig_targets_sle, annotate_sample_by = c(&quot;Disease&quot;, &quot;Sample Matrix&quot;, &quot;Lab&quot;), row_fontsize = 6, col_fontsize = 6) This heatmap focuses exclusively on proteins we found to be significantly altered in SLE, making disease-specific patterns more apparent. 7.6.3.2 SLE-Specific PCA p_sle &lt;- generate_pca(data = data.a$merged$Data_NPQ, sampleInfo = metadata_rename, sampleName_var = &quot;sampleName&quot;, sample_subset = sle_samples, target_subset = sig_targets_sle, annotate_sample_by = &quot;Disease&quot;) Using only significantly differential proteins often enhances separation between groups in PCA. 7.6.4 Directional Analysis We can separate elevated and reduced proteins to understand the nature of proteomic changes: # Elevated proteins (higher in SLE) sig_targets_sle_up &lt;- lmTest_da$modelStats %&gt;% filter(DiseaselupusSle_pval_FDR &lt; 0.05, DiseaselupusSle_coef &gt; 0) %&gt;% pull(target) # Reduced proteins (lower in SLE) sig_targets_sle_down &lt;- lmTest_da$modelStats %&gt;% filter(DiseaselupusSle_pval_FDR &lt; 0.05, DiseaselupusSle_coef &lt; 0) %&gt;% pull(target) cat(&quot;Elevated targets:&quot;, length(sig_targets_sle_up), &quot;\\n&quot;) #&gt; Elevated targets: 100 cat(&quot;Reduced targets:&quot;, length(sig_targets_sle_down), &quot;\\n&quot;) #&gt; Reduced targets: 2 Prepare Long Format Data We clean up the covariate names in the long data frame for better boxplot readability: data.long &lt;- data.a$merged$Data_NPQ_long %&gt;% mutate( `Disease Type` = case_when( Disease == &quot;lupusSle&quot; ~ &quot;SLE&quot;, Disease == &quot;rheumatoidArthritis&quot; ~ &quot;RA&quot;, TRUE ~ &quot;Normal&quot; )) 7.6.4.1 Elevated Proteins in SLE data.long %&gt;% filter(Target %in% sig_targets_sle_up, SampleName %in% sle_samples) %&gt;% ggplot(aes(x = `Disease Type`, y = NPQ, fill = `Disease Type`)) + geom_boxplot() + facet_wrap(~ Target, scales = &quot;free_y&quot;) + labs(title = paste0(&quot;Elevated Significant Differential Abundance Targets - SLE (n=&quot;, n_sle, &quot;) vs Normal (n=&quot;, n_normal, &quot;)&quot;), subtitle = &quot;with FDR-adjusted p &lt; 0.05&quot;) + theme( plot.title = element_text(size = 16, face = &quot;bold&quot;), plot.subtitle = element_text(size = 13), axis.title.x = element_text(size = 14), axis.title.y = element_text(size = 14), axis.text.x = element_text(size = 12, angle = 45, hjust = 1), axis.text.y = element_text(size = 12), strip.text = element_text(size = 11), legend.title = element_text(size = 13), legend.text = element_text(size = 12) ) Interpretation: Elevation of these proteins in SLE reflects multiple aspects of autoimmune pathology: Immune cell activation and co-stimulation: Elevated CD40, CD80, CD83, CTLA4, and PD-1 indicate activated T cells and antigen-presenting cells Pro-inflammatory cytokine signaling: Increased IL-1β, IL-6R, IL-12, IL-18, and TNF family members drive systemic inflammation Chemokine-mediated cell trafficking: CCL and CXCL chemokines (e.g., CXCL10, CCL2) recruit immune cells to sites of inflammation Type I interferon response: BST2 and other interferon-stimulated genes reflect the characteristic interferon signature of lupus Tissue damage markers: MMP8, MMP9, and S100A12 indicate ongoing tissue degradation and neutrophil activation Immune checkpoint dysregulation: Elevated LAG3, PDCD1, and CTLA4 suggest attempted but inadequate negative regulation 7.6.4.2 Reduced Proteins in SLE data.long %&gt;% filter(Target %in% sig_targets_sle_down, SampleName %in% sle_samples) %&gt;% ggplot(aes(x = `Disease Type`, y = NPQ, fill = `Disease Type`)) + geom_boxplot() + facet_wrap(~ Target, scales = &quot;free_y&quot;) + labs(title = paste0(&quot;Reduced Significant Differential Abundance Targets - \\nSLE (n=&quot;, n_sle, &quot;) vs Normal (n=&quot;, n_normal, &quot;)&quot;), subtitle = &quot;with FDR-adjusted p &lt; 0.05&quot;) + theme(strip.text = element_text(size = 13)) Interpretation: Decreased abundance of IL5RA and TNFSF10 in SLE samples may indicate: Altered immune regulation: TNFSF10 (TRAIL) promotes apoptosis of autoreactive cells; reduced levels may impair clearance of self-reactive lymphocytes Dysregulated cytokine signaling: IL5RA reduced levels suggests disrupted eosinophil and type 2 immune responses Chronic inflammation effects: Prolonged autoimmune activation can suppress certain immune regulatory pathways Loss of tolerance mechanisms: Reduced pro-apoptotic signaling may contribute to persistence of autoreactive immune cells 7.7 Rheumatoid Arthritis (RA) Analysis 7.7.1 Background Rheumatoid Arthritis is a chronic inflammatory disorder that primarily affects synovial joints but can have systemic manifestations. The pathophysiology involves: Autoimmune targeting of joint tissues Synovial inflammation and proliferation Cartilage and bone destruction Systemic inflammation The proteomic profile of RA often shows markers of: Joint inflammation and damage Systemic inflammatory response Matrix degradation Immune activation 7.7.2 Volcano Plot volcanoPlot(coefs = lmTest_da$modelStats$DiseaserheumatoidArthritis_coef, p_vals = lmTest_da$modelStats$DiseaserheumatoidArthritis_pval_FDR, target_labels = lmTest_da$modelStats$target, title = paste0(&quot;Rheumatoid Arthritis (RA) (n=&quot;, n_ra, &quot;) \\n vs Normal (n=&quot;, n_normal, &quot;)&quot;)) Compare this volcano plot to the SLE plot above. Are there: Proteins significantly changed in both conditions (shared inflammatory pathways)? Disease-specific signatures unique to RA or SLE? Similar magnitude of changes between the two diseases? 7.7.3 Visualizations # Select RA and normal samples ra_samples &lt;- metadata.a %&gt;% filter(Disease %in% c(&quot;normal&quot;, &quot;rheumatoidArthritis&quot;)) %&gt;% pull(sampleName) # Identify significantly differential proteins sig_targets_ra &lt;- lmTest_da$modelStats %&gt;% filter(DiseaserheumatoidArthritis_pval_FDR &lt; 0.05) %&gt;% pull(target) cat(&quot;Number of significant targets in RA:&quot;, length(sig_targets_ra), &quot;\\n&quot;) #&gt; Number of significant targets in RA: 96 7.7.3.1 RA-Specific Heatmap h_ra &lt;- generate_heatmap(data = data.a$merged$Data_NPQ, sampleInfo = metadata_rename, sampleName_var = &quot;sampleName&quot;, sample_subset = ra_samples, target_subset = sig_targets_ra, annotate_sample_by = c(&quot;Disease&quot;, &quot;Sample Matrix&quot;, &quot;Lab&quot;), row_fontsize = 6, col_fontsize = 6) 7.7.3.2 RA-Specific PCA p_ra &lt;- generate_pca(data = data.a$merged$Data_NPQ, sampleInfo = metadata_rename, sampleName_var = &quot;sampleName&quot;, sample_subset = ra_samples, target_subset = sig_targets_ra, annotate_sample_by = &quot;Disease&quot;) 7.7.4 Directional Analysis # Elevated proteins (higher in RA) sig_targets_ra_up &lt;- lmTest_da$modelStats %&gt;% filter(DiseaserheumatoidArthritis_pval_FDR &lt; 0.05, DiseaserheumatoidArthritis_coef &gt; 0) %&gt;% pull(target) # Reduced proteins (lower in RA) sig_targets_ra_down &lt;- lmTest_da$modelStats %&gt;% filter(DiseaserheumatoidArthritis_pval_FDR &lt; 0.05, DiseaserheumatoidArthritis_coef &lt; 0) %&gt;% pull(target) cat(&quot;Elevated targets:&quot;, length(sig_targets_ra_up), &quot;\\n&quot;) #&gt; Elevated targets: 95 cat(&quot;Reduced targets:&quot;, length(sig_targets_ra_down), &quot;\\n&quot;) #&gt; Reduced targets: 1 7.7.4.1 Elevated Proteins in RA data.long %&gt;% filter(Target %in% sig_targets_ra_up, SampleName %in% ra_samples) %&gt;% ggplot(aes(x = `Disease Type`, y = NPQ, fill = `Disease Type`)) + geom_boxplot() + facet_wrap(~ Target, scales = &quot;free_y&quot;) + labs(title = paste0(&quot;Elevated Significant Differential Abundance Targets - RA (n=&quot;, n_ra, &quot;) vs Normal (n=&quot;, n_normal, &quot;)&quot;), subtitle = &quot;with FDR-adjusted p &lt; 0.05&quot;) + theme( plot.title = element_text(size = 16, face = &quot;bold&quot;), plot.subtitle = element_text(size = 13), axis.title.x = element_text(size = 14), axis.title.y = element_text(size = 14), axis.text.x = element_text(size = 12, angle = 45, hjust = 1), axis.text.y = element_text(size = 12), strip.text = element_text(size = 11), legend.title = element_text(size = 13), legend.text = element_text(size = 12) ) Interpretation: Elevated proteins in RA reflect multiple aspects of autoimmune joint inflammation: Immune cell activation and co-stimulation: Elevated CD40, CD80, CD83, CTLA4, and PD-1 indicate activated T cells and antigen-presenting cells Pro-inflammatory cytokine signaling: Increased IL-1β, TNF, IL-18, IL-6ST, and TNF receptor family members drive chronic inflammation Chemokine-mediated cell trafficking: CCL and CXCL chemokines (e.g., CCL2, CXCL13) recruit immune cells to inflamed synovial tissue Joint destruction markers: Matrix metalloproteinases (MMP8, MMP9, MMP12) and cartilage degradation protein CHI3L1 indicate ongoing tissue damage Neutrophil activation: S100A12, MPO, and LCN2 reflect neutrophil infiltration characteristic of RA synovitis Angiogenesis and tissue remodeling: VEGFC, HGF, and growth factors support pannus formation and joint destruction Immune checkpoint dysregulation: Elevated LAG3, PDCD1, CTLA4, and PD-L2 suggest attempted but inadequate immune regulation 7.7.4.2 Reduced Proteins in RA data.long %&gt;% filter(Target %in% sig_targets_ra_down, SampleName %in% ra_samples) %&gt;% ggplot(aes(x = `Disease Type`, y = NPQ, fill = `Disease Type`)) + geom_boxplot() + facet_wrap(~ Target, scales = &quot;free_y&quot;) + labs(title = paste0(&quot;Reduced Significant Differential Abundance Targets - \\nRA (n=&quot;, n_ra, &quot;) vs Normal (n=&quot;, n_normal, &quot;)&quot;), subtitle = &quot;with FDR-adjusted p &lt; 0.05&quot;) + theme(strip.text = element_text(size = 13)) Interpretation: Reduced TNFSF10 (TRAIL) abundance in RA may reflect: Impaired apoptosis regulation: TRAIL promotes death of activated immune cells; reduced levels may allow persistence of autoreactive lymphocytes in synovial tissue Loss of immune tolerance: Decreased pro-apoptotic signaling contributes to accumulation of inflammatory cells in joints Synovial hyperplasia: Reduced TRAIL may fail to limit proliferation of synovial fibroblasts, contributing to pannus formation 7.8 Comparing Disease Signatures 7.8.1 Overlap Analysis To understand shared versus disease-specific biology, we can examine the overlap of significant proteins: # Proteins significant in both diseases shared_targets &lt;- intersect(sig_targets_sle, sig_targets_ra) # Disease-specific proteins sle_specific &lt;- setdiff(sig_targets_sle, sig_targets_ra) ra_specific &lt;- setdiff(sig_targets_ra, sig_targets_sle) cat(&quot;Shared significant targets:&quot;, length(shared_targets), &quot;\\n&quot;) #&gt; Shared significant targets: 73 cat(&quot;SLE-specific targets:&quot;, length(sle_specific), &quot;\\n&quot;) #&gt; SLE-specific targets: 29 cat(&quot;RA-specific targets:&quot;, length(ra_specific), &quot;\\n&quot;) #&gt; RA-specific targets: 23 # Display shared and specific targets # Create a data frame with comma-separated strings and counts overlap_table &lt;- data.frame( &quot;Category&quot; = c(&quot;Shared (SLE and RA)&quot;, &quot;SLE-Specific&quot;, &quot;RA-Specific&quot;), &quot;Count&quot; = c(length(shared_targets), length(sle_specific), length(ra_specific)), &quot;Targets&quot; = c( paste(shared_targets, collapse = &quot;, &quot;), paste(sle_specific, collapse = &quot;, &quot;), paste(ra_specific, collapse = &quot;, &quot;) ), check.names = FALSE ) Biological Interpretation: Shared targets highlight core autoimmune inflammatory mechanisms common to both SLE and RA, including cytokine signaling, immune cell activation, and tissue remodeling pathways SLE-specific targets may reflect systemic immune dysregulation, interferon signaling, and multi-organ involvement characteristic of lupus RA-specific targets likely represent joint-specific processes such as synovial inflammation, cartilage degradation, and localized tissue destruction Directional concordance: Most shared proteins show directional concordance (elevated in both diseases), indicating similar inflammatory activation patterns 7.8.2 Differential Abundance Summary Table summary &lt;- data.frame( Condition = c(&quot;SLE vs Normal&quot;, &quot;RA vs Normal&quot;), Total_Significant = c(length(sig_targets_sle), length(sig_targets_ra)), Elevated = c(length(sig_targets_sle_up), length(sig_targets_ra_up)), Reduced = c(length(sig_targets_sle_down), length(sig_targets_ra_down)) ) knitr::kable(summary, caption = &quot;Summary of Differential Abundance Results&quot;) Table 7.1: Summary of Differential Abundance Results Condition Total_Significant Elevated Reduced SLE vs Normal 102 100 2 RA vs Normal 96 95 1 7.9 Next Steps After identifying differentially abundant proteins, typical follow-up analyses include: Pathway enrichment analysis: Identify biological pathways over-represented in significant proteins Protein network analysis: Understand functional relationships between differential proteins Biomarker evaluation: Assess individual proteins or combinations for diagnostic potential Correlation with clinical variables: Link protein changes to disease severity or outcomes Validation studies: Confirm findings in independent cohorts or using orthogonal methods 7.10 Complete Workflow Example Code # ============================================================================ # COMPLETE DIFFERENTIAL ABUNDANCE WORKFLOW: SLE and RA Analysis # ============================================================================ # 1. Load libraries and import data library(NULISAseqR) library(tidyverse) data_dir &lt;- system.file(&quot;extdata&quot;, package = &quot;NULISAseqR&quot;) data.a &lt;- importNULISAseq(files = file.path(data_dir,&quot;Inflammation_250_RQ_demo_2025-05-20-Lab-A.xml&quot;)) # 2. Prepare metadata metadata.a &lt;- data.a$merged$samples %&gt;% filter(sampleType == &quot;Sample&quot;) %&gt;% mutate(Disease = relevel(Disease, ref = &quot;normal&quot;)) metadata_rename &lt;- metadata.a %&gt;% mutate(Disease = case_when( Disease == &quot;lupusSle&quot; ~ &quot;SLE&quot;, Disease == &quot;rheumatoidArthritis&quot; ~ &quot;RA&quot;, TRUE ~ &quot;Normal&quot; ), `Sample Matrix` = tolower(SAMPLE_MATRIX)) # Sample counts per group n_normal &lt;- sum(metadata.a$Disease == &quot;normal&quot;) n_sle &lt;- sum(metadata.a$Disease == &quot;lupusSle&quot;) n_ra &lt;- sum(metadata.a$Disease == &quot;rheumatoidArthritis&quot;) # Display sample distribution table(metadata.a$Disease) # 3. Target detectability filtering detectability_threshold &lt;- 0.5 targets_passed &lt;- data.a$merged$detectability %&gt;% filter(`plasma (n = 43)` &gt; 50) %&gt;% pull(Target) cat(&quot;Number of targets passing QC:&quot;, length(targets_passed), &quot;\\n&quot;) # 4. Run differential abundance analysis lmTest_da &lt;- lmNULISAseq( data = data.a$merged$Data_NPQ[targets_passed, metadata.a$sampleName], sampleInfo = metadata.a, sampleName_var = &quot;sampleName&quot;, modelFormula = &quot;Disease&quot; ) # Create output directories dir.create(&quot;figures&quot;, showWarnings = FALSE) dir.create(&quot;results&quot;, showWarnings = FALSE) # ============================================================================ # SLE ANALYSIS # ============================================================================ # 5a. Filter significant SLE results sig_targets_sle &lt;- lmTest_da$modelStats %&gt;% filter(DiseaselupusSle_pval_FDR &lt; 0.05) %&gt;% pull(target) sig_targets_sle_up &lt;- lmTest_da$modelStats %&gt;% filter(DiseaselupusSle_pval_FDR &lt; 0.05, DiseaselupusSle_coef &gt; 0) %&gt;% pull(target) sig_targets_sle_down &lt;- lmTest_da$modelStats %&gt;% filter(DiseaselupusSle_pval_FDR &lt; 0.05, DiseaselupusSle_coef &lt; 0) %&gt;% pull(target) # 6a. Get SLE and normal samples sle_samples &lt;- metadata.a %&gt;% filter(Disease %in% c(&quot;normal&quot;, &quot;lupusSle&quot;)) %&gt;% pull(sampleName) # 7a. Create SLE volcano plot and save as PDF volcanoPlot( coefs = lmTest_da$modelStats$DiseaselupusSle_coef, p_vals = lmTest_da$modelStats$DiseaselupusSle_pval_FDR, target_labels = lmTest_da$modelStats$target, title = paste0(&quot;Systemic Lupus Erythematosus (SLE) (n=&quot;, n_sle, &quot;) \\n vs Normal (n=&quot;, n_normal, &quot;)&quot;), plot_name = &quot;volcano_plot_sle_vs_normal.pdf&quot;, output_dir = &quot;figures&quot;, plot_width = 6, plot_height = 5 ) # 8a. Create SLE heatmap and save as PDF h_sle &lt;- generate_heatmap( data = data.a$merged$Data_NPQ, sampleInfo = metadata_rename, sampleName_var = &quot;sampleName&quot;, sample_subset = sle_samples, target_subset = sig_targets_sle, annotate_sample_by = c(&quot;Disease&quot;, &quot;Sample Matrix&quot;, &quot;Lab&quot;), output_dir = &quot;figures&quot;, plot_name = &quot;heatmap_sle_vs_normal.pdf&quot;, plot_width = 8, plot_height = 6 ) # 9a. Create SLE PCA and save as PDF p_sle &lt;- generate_pca( data = data.a$merged$Data_NPQ, plot_title = &quot;PCA: SLE vs Normal\\nSignificant DA Targets&quot;, sampleInfo = metadata_rename, sampleName_var = &quot;sampleName&quot;, sample_subset = sle_samples, target_subset = sig_targets_sle, annotate_sample_by = &quot;Disease&quot;, output_dir = &quot;figures&quot;, plot_name = &quot;pca_plot_sle_vs_normal.pdf&quot;, plot_width = 5, plot_height = 4 ) # 10a. Prepare long format data for boxplots data.long &lt;- data.a$merged$Data_NPQ_long %&gt;% mutate( `Disease Type` = case_when( Disease == &quot;lupusSle&quot; ~ &quot;SLE&quot;, Disease == &quot;rheumatoidArthritis&quot; ~ &quot;RA&quot;, TRUE ~ &quot;Normal&quot; )) # 11a. Create elevated SLE boxplots and save as PDF boxplot_sle_up &lt;- data.long %&gt;% filter(Target %in% sig_targets_sle_up, SampleName %in% sle_samples) %&gt;% ggplot(aes(x = `Disease Type`, y = NPQ, fill = `Disease Type`)) + geom_boxplot() + facet_wrap(~ Target, scales = &quot;free_y&quot;) + labs(title = paste0(&quot;Elevated Significant Differential Abundance Targets - SLE (n=&quot;, n_sle, &quot;) vs Normal (n=&quot;, n_normal, &quot;)&quot;), subtitle = &quot;with FDR-adjusted p &lt; 0.05&quot;) + theme_minimal() + theme(strip.text = element_text(size = 11), axis.text.x = element_text(angle = 45, hjust = 1)) ggsave( filename = &quot;boxplot_sle_elevated.pdf&quot;, plot = boxplot_sle_up, device = &quot;pdf&quot;, path = &quot;figures&quot;, width = 12, height = 10 ) # 12a. Create reduced SLE boxplots and save as PDF boxplot_sle_down &lt;- data.long %&gt;% filter(Target %in% sig_targets_sle_down, SampleName %in% sle_samples) %&gt;% ggplot(aes(x = `Disease Type`, y = NPQ, fill = `Disease Type`)) + geom_boxplot() + facet_wrap(~ Target, scales = &quot;free_y&quot;) + labs(title = paste0(&quot;Reduced Significant Differential Abundance Targets - \\nSLE (n=&quot;, n_sle, &quot;) vs Normal (n=&quot;, n_normal, &quot;)&quot;), subtitle = &quot;with FDR-adjusted p &lt; 0.05&quot;) + theme_minimal() + theme(strip.text = element_text(size = 11)) ggsave( filename = &quot;boxplot_sle_reduced.pdf&quot;, plot = boxplot_sle_down, device = &quot;pdf&quot;, path = &quot;figures&quot;, width = 4, height = 3 ) # ============================================================================ # RA ANALYSIS # ============================================================================ # 5b. Filter significant RA results sig_targets_ra &lt;- lmTest_da$modelStats %&gt;% filter(DiseaserheumatoidArthritis_pval_FDR &lt; 0.05) %&gt;% pull(target) sig_targets_ra_up &lt;- lmTest_da$modelStats %&gt;% filter(DiseaserheumatoidArthritis_pval_FDR &lt; 0.05, DiseaserheumatoidArthritis_coef &gt; 0) %&gt;% pull(target) sig_targets_ra_down &lt;- lmTest_da$modelStats %&gt;% filter(DiseaserheumatoidArthritis_pval_FDR &lt; 0.05, DiseaserheumatoidArthritis_coef &lt; 0) %&gt;% pull(target) # 6b. Get RA and normal samples ra_samples &lt;- metadata.a %&gt;% filter(Disease %in% c(&quot;normal&quot;, &quot;rheumatoidArthritis&quot;)) %&gt;% pull(sampleName) # 7b. Create RA volcano plot and save as PDF volcanoPlot( coefs = lmTest_da$modelStats$DiseaserheumatoidArthritis_coef, p_vals = lmTest_da$modelStats$DiseaserheumatoidArthritis_pval_FDR, target_labels = lmTest_da$modelStats$target, title = paste0(&quot;Rheumatoid Arthritis (RA) (n=&quot;, n_ra, &quot;) \\n vs Normal (n=&quot;, n_normal, &quot;)&quot;), plot_name = &quot;volcano_plot_ra_vs_normal.pdf&quot;, output_dir = &quot;figures&quot;, plot_width = 6, plot_height = 5 ) # 8b. Create RA heatmap and save as PDF h_ra &lt;- generate_heatmap( data = data.a$merged$Data_NPQ, sampleInfo = metadata_rename, sampleName_var = &quot;sampleName&quot;, sample_subset = ra_samples, target_subset = sig_targets_ra, annotate_sample_by = c(&quot;Disease&quot;, &quot;Sample Matrix&quot;, &quot;Lab&quot;), output_dir = &quot;figures&quot;, plot_name = &quot;heatmap_ra_vs_normal.pdf&quot;, plot_width = 8, plot_height = 6 ) # 9b. Create RA PCA and save as PDF p_ra &lt;- generate_pca( data = data.a$merged$Data_NPQ, plot_title = &quot;PCA: RA vs Normal\\nSignificant DA Targets&quot;, sampleInfo = metadata_rename, sampleName_var = &quot;sampleName&quot;, sample_subset = ra_samples, target_subset = sig_targets_ra, annotate_sample_by = &quot;Disease&quot;, output_dir = &quot;figures&quot;, plot_name = &quot;pca_plot_ra_vs_normal.pdf&quot;, plot_width = 5, plot_height = 4 ) # 10b. Create elevated RA boxplots and save as PDF boxplot_ra_up &lt;- data.long %&gt;% filter(Target %in% sig_targets_ra_up, SampleName %in% ra_samples) %&gt;% ggplot(aes(x = `Disease Type`, y = NPQ, fill = `Disease Type`)) + geom_boxplot() + facet_wrap(~ Target, scales = &quot;free_y&quot;) + labs(title = paste0(&quot;Elevated Significant Differential Abundance Targets - RA (n=&quot;, n_ra, &quot;) vs Normal (n=&quot;, n_normal, &quot;)&quot;), subtitle = &quot;with FDR-adjusted p &lt; 0.05&quot;) + theme_minimal() + theme(strip.text = element_text(size = 11)) ggsave( filename = &quot;boxplot_ra_elevated.pdf&quot;, plot = boxplot_ra_up, device = &quot;pdf&quot;, path = &quot;figures&quot;, width = 12, height = 10 ) # 11b. Create reduced RA boxplots and save as PDF boxplot_ra_down &lt;- data.long %&gt;% filter(Target %in% sig_targets_ra_down, SampleName %in% ra_samples) %&gt;% ggplot(aes(x = `Disease Type`, y = NPQ, fill = `Disease Type`)) + geom_boxplot() + facet_wrap(~ Target, scales = &quot;free_y&quot;) + labs(title = paste0(&quot;Reduced Significant Differential Abundance Targets - \\nRA (n=&quot;, n_ra, &quot;) vs Normal (n=&quot;, n_normal, &quot;)&quot;), subtitle = &quot;with FDR-adjusted p &lt; 0.05&quot;) + theme_minimal() + theme(strip.text = element_text(size = 11), axis.text.x = element_text(angle = 45, hjust = 1)) ggsave( filename = &quot;boxplot_ra_reduced.pdf&quot;, plot = boxplot_ra_down, device = &quot;pdf&quot;, path = &quot;figures&quot;, width = 4, height = 3 ) # ============================================================================ # COMPARATIVE ANALYSIS AND EXPORT # ============================================================================ # 13. Analyze overlap between diseases shared_targets &lt;- intersect(sig_targets_sle, sig_targets_ra) sle_specific &lt;- setdiff(sig_targets_sle, sig_targets_ra) ra_specific &lt;- setdiff(sig_targets_ra, sig_targets_sle) # 14. Export all results to CSV write_csv(lmTest_da$modelStats, &quot;results/all_da_results.csv&quot;) # Export SLE results write_csv( lmTest_da$modelStats %&gt;% filter(target %in% sig_targets_sle), &quot;results/sig_sle_proteins.csv&quot; ) # Export RA results write_csv( lmTest_da$modelStats %&gt;% filter(target %in% sig_targets_ra), &quot;results/sig_ra_proteins.csv&quot; ) # Export overlap results write_csv( data.frame(target = shared_targets), &quot;results/shared_sle_ra_proteins.csv&quot; ) # 15. Print comprehensive summary cat(&quot;\\n========================================\\n&quot;) cat(&quot;DIFFERENTIAL ABUNDANCE SUMMARY\\n&quot;) cat(&quot;========================================\\n\\n&quot;) cat(&quot;Quality Control:\\n&quot;) cat(&quot; Targets passing detectability threshold:&quot;, length(targets_passed), &quot;\\n\\n&quot;) cat(&quot;SLE vs Normal:\\n&quot;) cat(&quot; Total significant proteins:&quot;, length(sig_targets_sle), &quot;\\n&quot;) cat(&quot; Elevated:&quot;, length(sig_targets_sle_up), &quot;\\n&quot;) cat(&quot; Reduced:&quot;, length(sig_targets_sle_down), &quot;\\n\\n&quot;) cat(&quot;RA vs Normal:\\n&quot;) cat(&quot; Total significant proteins:&quot;, length(sig_targets_ra), &quot;\\n&quot;) cat(&quot; Elevated:&quot;, length(sig_targets_ra_up), &quot;\\n&quot;) cat(&quot; Reduced:&quot;, length(sig_targets_ra_down), &quot;\\n\\n&quot;) cat(&quot;Disease Comparison:\\n&quot;) cat(&quot; Shared significant targets:&quot;, length(shared_targets), &quot;\\n&quot;) cat(&quot; SLE-specific targets:&quot;, length(sle_specific), &quot;\\n&quot;) cat(&quot; RA-specific targets:&quot;, length(ra_specific), &quot;\\n\\n&quot;) cat(&quot;Output files created in:\\n&quot;) cat(&quot; - figures/ (all plots as PDFs)\\n&quot;) cat(&quot; - results/ (all statistical results as CSVs)\\n&quot;) cat(&quot;========================================\\n&quot;) "],["additional-resources.html", "Additional Resources NULISAseq Resources NULISA Analysis Software (NAS) Technical Documentation R Programming Resources Data Visualization Resources Citing This Book and Packages", " Additional Resources This chapter provides curated resources to help you get the most out of NULISAseq data analysis, including package documentation, R programming tutorials, visualization tools, and technical references. NULISAseq Resources Package Documentation The NULISAseqR package includes comprehensive documentation accessible directly from R: # Overall package documentation ?NULISAseqR # Function-specific help ?importNULISAseq # Data import ?lmNULISAseq # Linear modeling ?lmerNULISAseq # Linear mixed effect modeling ?lmNULISAseq_predict # Single-protein predictive modeling with lm ?glmNULISAseq # Generalized linear modeling ?generate_heatmap # Heatmap visualization ?generate_pca # PCA visualization ?volcanoPlot # Volcano plot visualization ?render_QC_report # QC report generation GitHub Repository NULISAseqR on GitHub The GitHub repository includes: Latest package source code Example datasets and workflows Issue tracker for bug reports and feature requests Support and Issues Report bugs: GitHub Issues Request features: Open an issue on GitHub with the “enhancement” label Ask questions: Use GitHub Discussions or contact Alamar Biosciences support NULISA Analysis Software (NAS) NULISA Analysis Software (NAS) is Alamar Biosciences’ proprietary web-based platform for processing and analyzing NULISAseq data. NAS provides an intuitive interface for: Automated data processing: XML data file to NULISA Protein Quantification (NPQ) units and absolute quantification units (for multiplex AQ assays) Quality control: Comprehensive QC metrics and visualization Interactive analysis: Real-time exploration of protein expression data Report generation: Automated QC and differential abundance analysis reports Data export: Download processed data in various formats NAS streamlines the initial data processing workflow, allowing researchers to quickly assess data quality, visualize data, and perform statistical analysis. Web Platform: NULISA Analysis Software (NAS) NAS Overview Video: NULISA Analysis Software (NAS) Training Access Required: Contact Alamar Biosciences support team to request an account Support: For NAS technical support or questions, contact Alamar Biosciences support Technical Documentation NULISAseq Technology Technical Notes View Technical Notes Information Sheet - NULISAseqTM Lot and Batch Definitions Definitions of lot and batch structures, validation data, and experimental design considerations for NULISAseq assays Tech Note - Performing relative quantitation of high-plex NULISAseq data NULISA data normalization, NPQ calculations, and statistical approaches used for relative quantification in multiplex NULISAseqTM assays Tech Note - NULISATM multiplex normalization &amp; quality control NPQ calculation steps, plate-level quality control metrics and additional normalization strategies for NULISAseqTM multiplex assays Tech Note - Capturing 12 logs dynamic range using NULISAseq Describes the assay tuning method incorporated by Alamar into NULISAseqTM panels to achieve broad dynamic range Tech Note - Determining the Absolute Concentration of High-Plex NULISAseq Protein Targets Calibration methodology, sample processing steps, and validation results for absolute quantification analysis using the NULISAseqTM Inflammation Panel AQ R Programming Resources Installing R and RStudio Required Software: R (the language): Download from CRAN Windows: Direct link macOS: Direct link Linux: Instructions RStudio (the IDE): Download from Posit Installation Order: Install R first, then RStudio. R and RStudio Resources and Tutorials R for Data Science by Hadley Wickham and Garrett Grolemund Comprehensive introduction to the tidyverse Data import, wrangling, visualization, and modeling Free online book with exercises Hands-On Programming with R by Garrett Grolemund Beginner-friendly introduction to R programming Learn by building R projects Covers R basics, data structures, and functions RStudio Education Curated learning resources Cheat sheets for R packages Interactive tutorials Quick Reference Guides R Cheat Sheets Base R Data transformation (dplyr) Data visualization (ggplot2) R Markdown And many more Tidyverse Resources The tidyverse is essential for data manipulation and analysis in this book: Tidyverse Website Package documentation Learning resources Blog with tips and updates dplyr Documentation Data manipulation verbs Working with grouped data Joining datasets tidyr Documentation Reshaping data (pivot_longer, pivot_wider) Handling missing values Nesting and unnesting data Data Visualization Resources ggplot2 ggplot2 is the primary visualization package used throughout this book. ggplot2 Official Documentation Complete reference for all geoms and functions Articles on faceting, scales, themes, and extensions ggplot2: Elegant Graphics for Data Analysis by Hadley Wickham Comprehensive guide to ggplot2 Theory and practice of the grammar of graphics Advanced customization techniques R Graphics Cookbook by Winston Chang Recipe-style solutions for common plotting tasks Quick reference for plot types and customizations ggplot2 Extensions Gallery Showcase of ggplot2 extension packages Specialized plot types and themes ComplexHeatmap ComplexHeatmap is a powerful package for creating sophisticated heatmaps, extensively used in proteomics visualization. ComplexHeatmap Complete Reference Comprehensive guide to all features Examples for every visualization type Advanced customization options ComplexHeatmap Bioconductor Page Installation instructions Official documentation Vignettes and examples PCAtools PCAtools provides enhanced PCA visualization and analysis capabilities. PCAtools Alamar Biosciences fork of PCAtools by Kevin Blighe and Aaron Lun includes NULISAseq-specific features. View on GitHub # Install version devtools::install_github(&quot;Alamar-Biosciences/PCAtools&quot;) Original package PCAtools Bioconductor Page Comprehensive PCA analysis functions Scree plots, biplots, and loading plots Statistical tests for optimal PC selection Citing This Book and Packages Citing This Book Alamar Biosciences Bioinformatics Team. (2026). NULISAseq Data Analysis Guide. R package vignette for NULISAseqR. Available at: https://vignettes.nulisaseqr.alamarbio.com Citing R and Packages # Cite R citation() # Cite specific packages citation(&quot;NULISAseqR&quot;) citation(&quot;ggplot2&quot;) citation(&quot;ComplexHeatmap&quot;) citation(&quot;PCAtools&quot;) # Generate citation list for all loaded packages knitr::write_bib( c(.packages(), &quot;bookdown&quot;, &quot;knitr&quot;, &quot;rmarkdown&quot;), file = &quot;packages.bib&quot; ) Key Citations NULISAseq Platform and Tools NULISAseqR Package: Alamar Biosciences. (2026). NULISAseqR: Analysis Tools for NULISAseq Proteomic Data. R package. https://github.com/Alamar-Biosciences/NULISAseqR Alamar Biosciences: Alamar Biosciences. (2026). NULISA Platform and Proteomic Solutions. https://alamarbio.com/ Nature Communication article on NULISAseq Technology: Feng, W., Beer, J.C., Hao, Q. et al. NULISA: a proteomic liquid biopsy platform with attomolar sensitivity and high multiplexing. Nat Commun 14, 7238 (2023). https://doi.org/10.1038/s41467-023-42834-x NULISATM Platform Video: Alamar Biosciences (2023). The NULISA™ Platform by Alamar Biosciences. YouTube. https://www.youtube.com/watch?v=24nVyCoJv4w NULISA Analysis Software Training Video: Alamar Biosciences (2023). The NULISA Analysis Software (NAS) Training by Alamar Biosciences. YouTube. https://www.youtube.com/watch?v=sS8oB8suRBk R and Packages R Statistical Software: R Core Team (2024). R: A language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria. https://www.R-project.org/ tidyverse: Wickham H, Averick M, Bryan J, Chang W, McGowan LD, François R, Grolemund G, Hayes A, Henry L, Hester J, Kuhn M, Pedersen TL, Miller E, Bache SM, Müller K, Ooms J, Robinson D, Seidel DP, Spinu V, Takahashi K, Vaughan D, Wilke C, Woo K, Yutani H (2019). “Welcome to the tidyverse.” Journal of Open Source Software, 4(43), 1686. https://doi.org/10.21105/joss.01686 bookdown: Xie, Y. (2016). bookdown: Authoring Books and Technical Documents with R Markdown. Chapman and Hall/CRC. ISBN 978-1138700109. https://bookdown.org/yihui/bookdown/ ggplot2: Wickham, H. (2016). ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York. ComplexHeatmap: Gu, Z., Eils, R., Schlesner, M. (2016). “Complex heatmaps reveal patterns and correlations in multidimensional genomic data.” Bioinformatics 32(18), 2847-2849. PCAtools: Blighe, K., Lun, A. (2022). PCAtools: Everything Principal Components Analysis. https://github.com/kevinblighe/PCAtools Happy analyzing! 🚀 We hope this book and these resources help you gain meaningful insights from your NULISAseq data. If you have questions or feedback, please reach out through the GitHub repository or contact Alamar Biosciences support at support@alamarbio.com. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
